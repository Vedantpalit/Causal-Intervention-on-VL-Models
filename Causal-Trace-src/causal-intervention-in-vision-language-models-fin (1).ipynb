{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"846906dc64b74f92bc915117f054603d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d62bd13fa19943bea7a0ead2ac68ec6e","IPY_MODEL_4a2e047c337947dd8e54b5f28b1bf467","IPY_MODEL_78691dad7b434fb3a08e57f25849239a"],"layout":"IPY_MODEL_c390db62c6504f1c8a8c793232bc7f24"}},"d62bd13fa19943bea7a0ead2ac68ec6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_768df9c2b3114e43a10c9bc034fa4845","placeholder":"​","style":"IPY_MODEL_46a0c2bd8b4647ec828fa17487bcf386","value":"Downloading (…)lve/main/config.json: 100%"}},"4a2e047c337947dd8e54b5f28b1bf467":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2883bd3e567c4b2991e5ed3df160a7bb","max":4559,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6817221f7284175b4cc9a56ab615238","value":4559}},"78691dad7b434fb3a08e57f25849239a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bcbbceb10ed4537882e055aecdeb46a","placeholder":"​","style":"IPY_MODEL_38ab7e2c9f0c49de87d82aa3d0a88068","value":" 4.56k/4.56k [00:00&lt;00:00, 275kB/s]"}},"c390db62c6504f1c8a8c793232bc7f24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"768df9c2b3114e43a10c9bc034fa4845":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46a0c2bd8b4647ec828fa17487bcf386":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2883bd3e567c4b2991e5ed3df160a7bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6817221f7284175b4cc9a56ab615238":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3bcbbceb10ed4537882e055aecdeb46a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38ab7e2c9f0c49de87d82aa3d0a88068":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb36e9f62a3245cb85a5e4950af8a9c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e234d6c2317e4079b58d41d9b7b457b4","IPY_MODEL_833e835821dd46d3b464870add09f651","IPY_MODEL_4466491af63e48ee8a65bf394098aed5"],"layout":"IPY_MODEL_770a9809acbf41cba0d547bf9fd98838"}},"e234d6c2317e4079b58d41d9b7b457b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3267fc003a364a2cbb6d7548c60a92ca","placeholder":"​","style":"IPY_MODEL_7a667016a9da48219481d452e7de507f","value":"Downloading pytorch_model.bin: 100%"}},"833e835821dd46d3b464870add09f651":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5342257105c44a62a01eaffcec149890","max":1538966629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61bd6e2e28cb415d9b9049896761d0cf","value":1538966629}},"4466491af63e48ee8a65bf394098aed5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bda78ec24884ceb9fb84d1c3ba62137","placeholder":"​","style":"IPY_MODEL_fe117fcef3494d2ab274621e4176aeac","value":" 1.54G/1.54G [00:09&lt;00:00, 114MB/s]"}},"770a9809acbf41cba0d547bf9fd98838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3267fc003a364a2cbb6d7548c60a92ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a667016a9da48219481d452e7de507f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5342257105c44a62a01eaffcec149890":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61bd6e2e28cb415d9b9049896761d0cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9bda78ec24884ceb9fb84d1c3ba62137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe117fcef3494d2ab274621e4176aeac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd5237ba06a340f192447b3b7296fd30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f9c49ce5ef94909a93b0549743344ac","IPY_MODEL_85b52ad1a41842cfbdf14e5ad467084a","IPY_MODEL_b93ed0c09d4d4059862221e1f725b57f"],"layout":"IPY_MODEL_f5be4f8157094ff3b23bce4c1f318d8b"}},"1f9c49ce5ef94909a93b0549743344ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8b2d562175a44169934aa92dcf6df85","placeholder":"​","style":"IPY_MODEL_3a936a728e2141b8bd036d175585e013","value":"Downloading (…)rocessor_config.json: 100%"}},"85b52ad1a41842cfbdf14e5ad467084a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dd85d8c9a81448a8e2ac86a08649186","max":445,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa39dd3091f04c09a698dcbba3c5abe7","value":445}},"b93ed0c09d4d4059862221e1f725b57f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9119e3d7edb41498b3afed7a7c3db3d","placeholder":"​","style":"IPY_MODEL_256ac2f48263409aab28766b205514f0","value":" 445/445 [00:00&lt;00:00, 7.06kB/s]"}},"f5be4f8157094ff3b23bce4c1f318d8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8b2d562175a44169934aa92dcf6df85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a936a728e2141b8bd036d175585e013":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4dd85d8c9a81448a8e2ac86a08649186":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa39dd3091f04c09a698dcbba3c5abe7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9119e3d7edb41498b3afed7a7c3db3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"256ac2f48263409aab28766b205514f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"895e4b837989458cb528924e6ba21ab3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20911761131a46f6af6ace8fa88f3b67","IPY_MODEL_000155be91ec4a68a98fffcf7dc7cced","IPY_MODEL_f45f0e2258984af8a20d7230c98eeb28"],"layout":"IPY_MODEL_4e5fc94865454ab98d6d68825edbd0a1"}},"20911761131a46f6af6ace8fa88f3b67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dde3a6db3c6945bd88fdf81752c729db","placeholder":"​","style":"IPY_MODEL_a941938ab8e147eda21799bc2ad17870","value":"Downloading (…)okenizer_config.json: 100%"}},"000155be91ec4a68a98fffcf7dc7cced":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7349a91298d44e75b90b1dd03dfc8ad1","max":592,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55a6894419ca41e18306c8a52e9c7c93","value":592}},"f45f0e2258984af8a20d7230c98eeb28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_daaf5fc89747453c908dce14578f95bb","placeholder":"​","style":"IPY_MODEL_1562c0e1ffd54469936001932d835c0e","value":" 592/592 [00:00&lt;00:00, 7.83kB/s]"}},"4e5fc94865454ab98d6d68825edbd0a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dde3a6db3c6945bd88fdf81752c729db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a941938ab8e147eda21799bc2ad17870":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7349a91298d44e75b90b1dd03dfc8ad1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55a6894419ca41e18306c8a52e9c7c93":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"daaf5fc89747453c908dce14578f95bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1562c0e1ffd54469936001932d835c0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5526f1babfb46f5b3384d0ac6c8e462":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8c0344e18414846ade02b9f0ddbe42e","IPY_MODEL_3120bd31dbc74249ad2a40a978cbbdd1","IPY_MODEL_9815bad9aadb46fd839b29fc675d5b58"],"layout":"IPY_MODEL_12bb34d50def44109335cc02154fcfb6"}},"c8c0344e18414846ade02b9f0ddbe42e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4469fb9cc5794834a56e934d8ddc5928","placeholder":"​","style":"IPY_MODEL_123b65c720f64f478ffc8b25720eeab4","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"3120bd31dbc74249ad2a40a978cbbdd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da61e7e210eb48d5bd766cef42ede4ba","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa9579d44a59442d9e34bcfd4bc36cd8","value":231508}},"9815bad9aadb46fd839b29fc675d5b58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d3bb86fe24f44daa582b0307e7669bd","placeholder":"​","style":"IPY_MODEL_505b1431519c4f25923973224d28a414","value":" 232k/232k [00:00&lt;00:00, 1.43MB/s]"}},"12bb34d50def44109335cc02154fcfb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4469fb9cc5794834a56e934d8ddc5928":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"123b65c720f64f478ffc8b25720eeab4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da61e7e210eb48d5bd766cef42ede4ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa9579d44a59442d9e34bcfd4bc36cd8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d3bb86fe24f44daa582b0307e7669bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"505b1431519c4f25923973224d28a414":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d87236f2a71e40ad919dfc1502f73d67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa377208317243efb53ebec5ced96d82","IPY_MODEL_94cfd9760fc8405ebc70320ae31cb338","IPY_MODEL_4b7bb7e0a9d64b57855efb40b44b90be"],"layout":"IPY_MODEL_774a50005e684b34932c09dd9f4777c2"}},"fa377208317243efb53ebec5ced96d82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c494b0bfd40c430998e2003f456091fa","placeholder":"​","style":"IPY_MODEL_02c98dfbf1b147f8a806a2ec54978754","value":"Downloading (…)/main/tokenizer.json: 100%"}},"94cfd9760fc8405ebc70320ae31cb338":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0877e0a04314335bad426e1f5a47d1a","max":711396,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2dc8a40b7d8456a8b58f7a88d0d6599","value":711396}},"4b7bb7e0a9d64b57855efb40b44b90be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61ee918c72794dd6908acd152ea49968","placeholder":"​","style":"IPY_MODEL_a9665f5bc4f44ec29e97064783d7c708","value":" 711k/711k [00:00&lt;00:00, 9.56MB/s]"}},"774a50005e684b34932c09dd9f4777c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c494b0bfd40c430998e2003f456091fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02c98dfbf1b147f8a806a2ec54978754":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0877e0a04314335bad426e1f5a47d1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2dc8a40b7d8456a8b58f7a88d0d6599":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61ee918c72794dd6908acd152ea49968":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9665f5bc4f44ec29e97064783d7c708":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"418bd67a6c8e481fa0369fae9a04c3c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba7923416659439ea92cfa9da0795b30","IPY_MODEL_6692be45a5214907bc8852587335f70c","IPY_MODEL_d4a90910a9b64079923824e3424cf8af"],"layout":"IPY_MODEL_9170139b54a244518da6c383a336e141"}},"ba7923416659439ea92cfa9da0795b30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75fea4d5cb6741bdad03ff060a4b5210","placeholder":"​","style":"IPY_MODEL_f54172cf443b477797c39057b45868df","value":"Downloading (…)cial_tokens_map.json: 100%"}},"6692be45a5214907bc8852587335f70c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f44ba42ee80467fa48f32ce55e21878","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dfabd4f541e543b483f11f853fb6fca7","value":125}},"d4a90910a9b64079923824e3424cf8af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a3b4736ff734650a5dc7e87aa76a8ae","placeholder":"​","style":"IPY_MODEL_18dbac9eb3da48dc96e0c103804e7de2","value":" 125/125 [00:00&lt;00:00, 1.95kB/s]"}},"9170139b54a244518da6c383a336e141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75fea4d5cb6741bdad03ff060a4b5210":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f54172cf443b477797c39057b45868df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f44ba42ee80467fa48f32ce55e21878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfabd4f541e543b483f11f853fb6fca7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a3b4736ff734650a5dc7e87aa76a8ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18dbac9eb3da48dc96e0c103804e7de2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#Utilities","metadata":{"id":"dXtHYmPQgwWp"}},{"cell_type":"code","source":"import contextlib\nimport copy\nimport inspect\nfrom collections import OrderedDict\nimport torch\nimport requests","metadata":{"id":"DOkPIcefzV-T","execution":{"iopub.status.busy":"2023-08-21T14:26:01.947356Z","iopub.execute_input":"2023-08-21T14:26:01.947718Z","iopub.status.idle":"2023-08-21T14:26:05.475058Z","shell.execute_reply.started":"2023-08-21T14:26:01.947691Z","shell.execute_reply":"2023-08-21T14:26:05.474086Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def get_module(model, name):\n    \"\"\"\n    Finds the named module within the given model.\n    \"\"\"\n    for n, m in model.named_modules():\n        if n == name:\n            return m\n    raise LookupError(name)\n\ndef replace_module(model, name, new_module):\n    \"\"\"\n    Replaces the named module within the given model.\n    \"\"\"\n    if \".\" in name:\n        parent_name, attr_name = name.rsplit(\".\", 1)\n        model = get_module(model, parent_name)\n    # original_module = getattr(model, attr_name)\n    setattr(model, attr_name, new_module)\n\nclass StopForward(Exception):\n    \"\"\"\n    If the only output needed from running a network is the retained\n    submodule then Trace(submodule, stop=True) will stop execution\n    immediately after the retained submodule by raising the StopForward()\n    exception.  When Trace is used as context manager, it catches that\n    exception and can be used as follows:\n\n    with Trace(net, layername, stop=True) as tr:\n        net(inp) # Only runs the network up to layername\n    print(tr.output)\n    \"\"\"\n\n    pass\n\ndef recursive_copy(x, clone=None, detach=None, retain_grad=None):\n    \"\"\"\n    Copies a reference to a tensor, or an object that contains tensors,\n    optionally detaching and cloning the tensor(s).  If retain_grad is\n    true, the original tensors are marked to have grads retained.\n    \"\"\"\n    if not clone and not detach and not retain_grad:\n        return x\n    if isinstance(x, torch.Tensor):\n        if retain_grad:\n            if not x.requires_grad:\n                x.requires_grad = True\n            x.retain_grad()\n        elif detach:\n            x = x.detach()\n        if clone:\n            x = x.clone()\n        return x\n    # Only dicts, lists, and tuples (and subclasses) can be copied.\n    if isinstance(x, dict):\n        return type(x)({k: recursive_copy(v) for k, v in x.items()})\n    elif isinstance(x, (list, tuple)):\n        return type(x)([recursive_copy(v) for v in x])\n    else:\n        assert False, f\"Unknown type {type(x)} cannot be broken into tensors.\"\n\ndef invoke_with_optional_args(fn, *args, **kwargs):\n    \"\"\"\n    Invokes a function with only the arguments that it\n    is written to accept, giving priority to arguments\n    that match by-name, using the following rules.\n    (1) arguments with matching names are passed by name.\n    (2) remaining non-name-matched args are passed by order.\n    (3) extra caller arguments that the function cannot\n        accept are not passed.\n    (4) extra required function arguments that the caller\n        cannot provide cause a TypeError to be raised.\n    Ordinary python calling conventions are helpful for\n    supporting a function that might be revised to accept\n    extra arguments in a newer version, without requiring the\n    caller to pass those new arguments.  This function helps\n    support function callers that might be revised to supply\n    extra arguments, without requiring the callee to accept\n    those new arguments.\n    \"\"\"\n    argspec = inspect.getfullargspec(fn)\n    pass_args = []\n    used_kw = set()\n    unmatched_pos = []\n    used_pos = 0\n    defaulted_pos = len(argspec.args) - (\n        0 if not argspec.defaults else len(argspec.defaults)\n    )\n    # Pass positional args that match name first, then by position.\n    for i, n in enumerate(argspec.args):\n        if n in kwargs:\n            pass_args.append(kwargs[n])\n            used_kw.add(n)\n        elif used_pos < len(args):\n            pass_args.append(args[used_pos])\n            used_pos += 1\n        else:\n            unmatched_pos.append(len(pass_args))\n            pass_args.append(\n                None if i < defaulted_pos else argspec.defaults[i - defaulted_pos]\n            )\n    # Fill unmatched positional args with unmatched keyword args in order.\n    if len(unmatched_pos):\n        for k, v in kwargs.items():\n            if k in used_kw or k in argspec.kwonlyargs:\n                continue\n            pass_args[unmatched_pos[0]] = v\n            used_kw.add(k)\n            unmatched_pos = unmatched_pos[1:]\n            if len(unmatched_pos) == 0:\n                break\n        else:\n            if unmatched_pos[0] < defaulted_pos:\n                unpassed = \", \".join(\n                    argspec.args[u] for u in unmatched_pos if u < defaulted_pos\n                )\n                raise TypeError(f\"{fn.__name__}() cannot be passed {unpassed}.\")\n    # Pass remaining kw args if they can be accepted.\n    pass_kw = {\n        k: v\n        for k, v in kwargs.items()\n        if k not in used_kw and (k in argspec.kwonlyargs or argspec.varargs is not None)\n    }\n    # Pass remaining positional args if they can be accepted.\n    if argspec.varargs is not None:\n        pass_args += list(args[used_pos:])\n    return fn(*pass_args, **pass_kw)\n\n\n\ndef set_requires_grad(requires_grad, *models):\n    \"\"\"\n    Sets requires_grad true or false for all parameters within the\n    models passed.\n    \"\"\"\n    for model in models:\n        if isinstance(model, torch.nn.Module):\n            for param in model.parameters():\n                param.requires_grad = requires_grad\n        elif isinstance(model, (torch.nn.Parameter, torch.Tensor)):\n            model.requires_grad = requires_grad\n        else:\n            assert False, \"unknown type %r\" % type(model)\n","metadata":{"id":"ffzJfBeGzi1u","execution":{"iopub.status.busy":"2023-08-21T14:26:08.401364Z","iopub.execute_input":"2023-08-21T14:26:08.402455Z","iopub.status.idle":"2023-08-21T14:26:08.432144Z","shell.execute_reply.started":"2023-08-21T14:26:08.402413Z","shell.execute_reply":"2023-08-21T14:26:08.431011Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Trace(contextlib.AbstractContextManager):\n    \"\"\"\n    To retain the output of the named layer during the computation of\n    the given network:\n\n        with Trace(net, 'layer.name') as ret:\n            _ = net(inp)\n            representation = ret.output\n\n    A layer module can be passed directly without a layer name, and\n    its output will be retained.  By default, a direct reference to\n    the output object is returned, but options can control this:\n\n        clone=True  - retains a copy of the output, which can be\n            useful if you want to see the output before it might\n            be modified by the network in-place later.\n        detach=True - retains a detached reference or copy.  (By\n            default the value would be left attached to the graph.)\n        retain_grad=True - request gradient to be retained on the\n            output.  After backward(), ret.output.grad is populated.\n\n        retain_input=True - also retains the input.\n        retain_output=False - can disable retaining the output.\n        edit_output=fn - calls the function to modify the output\n            of the layer before passing it the rest of the model.\n            fn can optionally accept (output, layer) arguments\n            for the original output and the layer name.\n        stop=True - throws a StopForward exception after the layer\n            is run, which allows running just a portion of a model.\n    \"\"\"\n\n    def __init__(\n        self,\n        module,\n        layer=None,\n        retain_output=True,\n        retain_input=False,\n        clone=False,\n        detach=False,\n        retain_grad=False,\n        edit_output=None,\n        stop=False,\n    ):\n        \"\"\"\n        Method to replace a forward method with a closure that\n        intercepts the call, and tracks the hook so that it can be reverted.\n        \"\"\"\n        retainer = self\n        self.layer = layer\n        if layer is not None:\n            module = get_module(module, layer)\n\n        def retain_hook(m, inputs, output):\n            if retain_input:\n                retainer.input = recursive_copy(\n                    inputs[0] if len(inputs) == 1 else inputs,\n                    clone=clone,\n                    detach=detach,\n                    retain_grad=False,\n                )  # retain_grad applies to output only.\n            if edit_output:\n                output = invoke_with_optional_args(\n                    edit_output, output=output, layer=self.layer\n                )\n            if retain_output:\n                retainer.output = recursive_copy(\n                    output, clone=clone, detach=detach, retain_grad=retain_grad\n                )\n                # When retain_grad is set, also insert a trivial\n                # copy operation.  That allows in-place operations\n                # to follow without error.\n                if retain_grad:\n                    output = recursive_copy(retainer.output, clone=True, detach=False)\n            if stop:\n                raise StopForward()\n            return output\n\n        self.registered_hook = module.register_forward_hook(retain_hook)\n        self.stop = stop\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, traceback):\n        self.close()\n        if self.stop and issubclass(type, StopForward):\n            return True\n\n    def close(self):\n        self.registered_hook.remove()\n\n","metadata":{"id":"ww9ZayOd9AK3","execution":{"iopub.status.busy":"2023-08-21T14:26:13.381570Z","iopub.execute_input":"2023-08-21T14:26:13.382046Z","iopub.status.idle":"2023-08-21T14:26:13.408062Z","shell.execute_reply.started":"2023-08-21T14:26:13.382002Z","shell.execute_reply":"2023-08-21T14:26:13.407057Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class TraceDict(OrderedDict, contextlib.AbstractContextManager):\n    \"\"\"\n    To retain the output of multiple named layers during the computation\n    of the given network:\n\n        with TraceDict(net, ['layer1.name1', 'layer2.name2']) as ret:\n            _ = net(inp)\n            representation = ret['layer1.name1'].output\n\n    If edit_output is provided, it should be a function that takes\n    two arguments: output, and the layer name; and then it returns the\n    modified output.\n\n    Other arguments are the same as Trace.  If stop is True, then the\n    execution of the network will be stopped after the last layer\n    listed (even if it would not have been the last to be executed).\n    \"\"\"\n\n    def __init__(\n        self,\n        model,\n        layers=None,\n        retain_output=True,\n        retain_input=False,\n        clone=False,\n        detach=False,\n        retain_grad=False,\n        edit_output=None,\n        stop=False,\n    ):\n        self.stop = stop\n\n        def flag_last_unseen(it):\n            try:\n                it = iter(it)\n                prev = next(it)\n                seen = set([prev])\n            except StopIteration:\n                return\n            for item in it:\n                if item not in seen:\n                    yield False, prev\n                    seen.add(item)\n                    prev = item\n            yield True, prev\n\n        for is_last, layer in flag_last_unseen(layers):\n            self[layer] = Trace(\n                module=model,\n                layer=layer,\n                retain_output=retain_output,\n                retain_input=retain_input,\n                clone=clone,\n                detach=detach,\n                retain_grad=retain_grad,\n                edit_output=edit_output,\n                stop=stop and is_last,\n            )\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, traceback):\n        self.close()\n        if self.stop and issubclass(type, StopForward):\n            return True\n\n    def close(self):\n        for layer, trace in reversed(self.items()):\n            trace.close()","metadata":{"id":"7p-Ce9Vagu0g","execution":{"iopub.status.busy":"2023-08-21T14:26:17.068601Z","iopub.execute_input":"2023-08-21T14:26:17.069691Z","iopub.status.idle":"2023-08-21T14:26:17.080476Z","shell.execute_reply.started":"2023-08-21T14:26:17.069649Z","shell.execute_reply":"2023-08-21T14:26:17.079578Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#Main","metadata":{"id":"wKrG9--ug0NO"}},{"cell_type":"code","source":"!pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAWOrNpWb7Fp","outputId":"359f9cf4-6b10-4e0f-fb66-3ad8c9647ce3","execution":{"iopub.status.busy":"2023-08-21T11:18:33.973531Z","iopub.execute_input":"2023-08-21T11:18:33.973898Z","iopub.status.idle":"2023-08-21T11:18:47.094722Z","shell.execute_reply.started":"2023-08-21T11:18:33.973867Z","shell.execute_reply":"2023-08-21T11:18:47.093485Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install stanza\n!pip install datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkl05QQWfvJJ","outputId":"bd00a0a3-4d50-4eb7-890d-4c1b643c3b92","execution":{"iopub.status.busy":"2023-07-19T19:01:41.360454Z","iopub.execute_input":"2023-07-19T19:01:41.360824Z","iopub.status.idle":"2023-07-19T19:02:06.724927Z","shell.execute_reply.started":"2023-07-19T19:01:41.360774Z","shell.execute_reply":"2023-07-19T19:02:06.723632Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting stanza\n  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (from stanza) (2.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from stanza) (1.23.5)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from stanza) (3.20.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from stanza) (2.28.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from stanza) (1.16.0)\nRequirement already satisfied: torch>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from stanza) (2.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from stanza) (4.64.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\nInstalling collected packages: stanza\nSuccessfully installed stanza-1.5.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.28.2)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.64.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.15.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os, re, json\nimport torch, numpy\nfrom collections import defaultdict\nimport numpy as np\nimport torch\nfrom sklearn.decomposition import PCA\nimport matplotlib\nfrom matplotlib import pyplot as plt\nimport itertools\nimport nltk\nimport random\n# from sentence_transformers import SentenceTransformer\nfrom tqdm.notebook import tqdm\n#import stanza\n#import datasets\nimport scipy\nimport csv\nimport pandas as pd\nfrom PIL import Image\nfrom typing import Any, Optional, Tuple, Union,OrderedDict","metadata":{"id":"r2fGwjUubrdI","execution":{"iopub.status.busy":"2023-08-21T14:26:22.791622Z","iopub.execute_input":"2023-08-21T14:26:22.792497Z","iopub.status.idle":"2023-08-21T14:26:24.207655Z","shell.execute_reply.started":"2023-08-21T14:26:22.792452Z","shell.execute_reply":"2023-08-21T14:26:24.206733Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"jXAeGLtebW98","execution":{"iopub.status.busy":"2023-08-21T14:26:25.827589Z","iopub.execute_input":"2023-08-21T14:26:25.828261Z","iopub.status.idle":"2023-08-21T14:26:25.899657Z","shell.execute_reply.started":"2023-08-21T14:26:25.828231Z","shell.execute_reply":"2023-08-21T14:26:25.898149Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import BlipForQuestionAnswering,BlipProcessor\nmodel= BlipForQuestionAnswering.from_pretrained('Salesforce/blip-vqa-base')\nprocessor=BlipProcessor.from_pretrained('Salesforce/blip-vqa-base')\n\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["846906dc64b74f92bc915117f054603d","d62bd13fa19943bea7a0ead2ac68ec6e","4a2e047c337947dd8e54b5f28b1bf467","78691dad7b434fb3a08e57f25849239a","c390db62c6504f1c8a8c793232bc7f24","768df9c2b3114e43a10c9bc034fa4845","46a0c2bd8b4647ec828fa17487bcf386","2883bd3e567c4b2991e5ed3df160a7bb","c6817221f7284175b4cc9a56ab615238","3bcbbceb10ed4537882e055aecdeb46a","38ab7e2c9f0c49de87d82aa3d0a88068","cb36e9f62a3245cb85a5e4950af8a9c4","e234d6c2317e4079b58d41d9b7b457b4","833e835821dd46d3b464870add09f651","4466491af63e48ee8a65bf394098aed5","770a9809acbf41cba0d547bf9fd98838","3267fc003a364a2cbb6d7548c60a92ca","7a667016a9da48219481d452e7de507f","5342257105c44a62a01eaffcec149890","61bd6e2e28cb415d9b9049896761d0cf","9bda78ec24884ceb9fb84d1c3ba62137","fe117fcef3494d2ab274621e4176aeac","fd5237ba06a340f192447b3b7296fd30","1f9c49ce5ef94909a93b0549743344ac","85b52ad1a41842cfbdf14e5ad467084a","b93ed0c09d4d4059862221e1f725b57f","f5be4f8157094ff3b23bce4c1f318d8b","c8b2d562175a44169934aa92dcf6df85","3a936a728e2141b8bd036d175585e013","4dd85d8c9a81448a8e2ac86a08649186","fa39dd3091f04c09a698dcbba3c5abe7","d9119e3d7edb41498b3afed7a7c3db3d","256ac2f48263409aab28766b205514f0","895e4b837989458cb528924e6ba21ab3","20911761131a46f6af6ace8fa88f3b67","000155be91ec4a68a98fffcf7dc7cced","f45f0e2258984af8a20d7230c98eeb28","4e5fc94865454ab98d6d68825edbd0a1","dde3a6db3c6945bd88fdf81752c729db","a941938ab8e147eda21799bc2ad17870","7349a91298d44e75b90b1dd03dfc8ad1","55a6894419ca41e18306c8a52e9c7c93","daaf5fc89747453c908dce14578f95bb","1562c0e1ffd54469936001932d835c0e","e5526f1babfb46f5b3384d0ac6c8e462","c8c0344e18414846ade02b9f0ddbe42e","3120bd31dbc74249ad2a40a978cbbdd1","9815bad9aadb46fd839b29fc675d5b58","12bb34d50def44109335cc02154fcfb6","4469fb9cc5794834a56e934d8ddc5928","123b65c720f64f478ffc8b25720eeab4","da61e7e210eb48d5bd766cef42ede4ba","fa9579d44a59442d9e34bcfd4bc36cd8","4d3bb86fe24f44daa582b0307e7669bd","505b1431519c4f25923973224d28a414","d87236f2a71e40ad919dfc1502f73d67","fa377208317243efb53ebec5ced96d82","94cfd9760fc8405ebc70320ae31cb338","4b7bb7e0a9d64b57855efb40b44b90be","774a50005e684b34932c09dd9f4777c2","c494b0bfd40c430998e2003f456091fa","02c98dfbf1b147f8a806a2ec54978754","c0877e0a04314335bad426e1f5a47d1a","c2dc8a40b7d8456a8b58f7a88d0d6599","61ee918c72794dd6908acd152ea49968","a9665f5bc4f44ec29e97064783d7c708","418bd67a6c8e481fa0369fae9a04c3c3","ba7923416659439ea92cfa9da0795b30","6692be45a5214907bc8852587335f70c","d4a90910a9b64079923824e3424cf8af","9170139b54a244518da6c383a336e141","75fea4d5cb6741bdad03ff060a4b5210","f54172cf443b477797c39057b45868df","8f44ba42ee80467fa48f32ce55e21878","dfabd4f541e543b483f11f853fb6fca7","4a3b4736ff734650a5dc7e87aa76a8ae","18dbac9eb3da48dc96e0c103804e7de2"]},"id":"pGO1D03-b9cs","outputId":"4141facd-286b-44ee-bd31-6ebdf59ae300","execution":{"iopub.status.busy":"2023-08-21T14:26:27.900599Z","iopub.execute_input":"2023-08-21T14:26:27.901353Z","iopub.status.idle":"2023-08-21T14:27:00.476603Z","shell.execute_reply.started":"2023-08-21T14:26:27.901322Z","shell.execute_reply":"2023-08-21T14:27:00.475614Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9365c25642e14cde80465c184b47016c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61b0a391b993448693c2be89181eff68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)rocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af777ed471ed4c6b8a2eec954ddaf01d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d98bddc2a4064844a930a70f8a05fad3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"408db13d304d498f8d69fb8469d25066"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ae6907409b14784b0e303a32da5f6f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dfa9772829f4d63a5b5fbbfddfc753d"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"BlipForQuestionAnswering(\n  (vision_model): BlipVisionModel(\n    (embeddings): BlipVisionEmbeddings(\n      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (encoder): BlipEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x BlipEncoderLayer(\n          (self_attn): BlipAttention(\n            (dropout): Dropout(p=0.0, inplace=False)\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (projection): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): BlipMLP(\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (text_encoder): BlipTextModel(\n    (embeddings): BlipTextEmbeddings(\n      (word_embeddings): Embedding(30524, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): BlipTextEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BlipTextLayer(\n          (attention): BlipTextAttention(\n            (self): BlipTextSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): BlipTextSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (crossattention): BlipTextAttention(\n            (self): BlipTextSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): BlipTextSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): BlipTextIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BlipTextOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (text_decoder): BlipTextLMHeadModel(\n    (bert): BlipTextModel(\n      (embeddings): BlipTextEmbeddings(\n        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (encoder): BlipTextEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BlipTextLayer(\n            (attention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (crossattention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (intermediate): BlipTextIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BlipTextOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (cls): BlipTextOnlyMLMHead(\n      (predictions): BlipTextLMPredictionHead(\n        (transform): BlipTextPredictionHeadTransform(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (transform_act_fn): GELUActivation()\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model_name='Salesforce/blip-vqa-base'","metadata":{"id":"zRntPp3PeEKe","execution":{"iopub.status.busy":"2023-08-21T14:27:06.040254Z","iopub.execute_input":"2023-08-21T14:27:06.040633Z","iopub.status.idle":"2023-08-21T14:27:06.045447Z","shell.execute_reply.started":"2023-08-21T14:27:06.040604Z","shell.execute_reply":"2023-08-21T14:27:06.044155Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ModelandProcessor:\n  def __init__(\n        self,\n        model_name=None,\n        model=None,\n        processor=None,\n        low_cpu_mem_usage=False,\n        torch_dtype=None,\n    ):\n        if  processor is None:\n            assert model_name is not None\n            processor = BlipProcessor.from_pretrained(model_name)\n        if model is None:\n            assert model_name is not None\n            model = BlipForQuestionAnswering.from_pretrained(\n                model_name, low_cpu_mem_usage=low_cpu_mem_usage, torch_dtype=torch_dtype\n            )\n            set_requires_grad(False, model)\n            model.eval().cuda()\n        self.processor = processor\n        self.model = model\n        self.layer_names = [\n            n\n            for n, m in model.named_modules()\n            if (re.match(r\"^(vision_model|text_encoder|text_decoder.bert|text_decoder.cls)\\.(embeddings|encoder.layers|encoder.layer|predictions)\\.(\\d+$)\", n))\n        ]\n        self.num_layers = (len(self.layer_names)//3)\n\n  def __repr__(self):\n        return (\n            f\"ModelAndTokenizer(model: {type(self.model).__name__} \"\n            f\"[{self.num_layers} layers], \"\n            f\"tokenizer: {type(self.tokenizer).__name__})\"\n        )\n","metadata":{"id":"JFc-lGt3JdDP","execution":{"iopub.status.busy":"2023-08-21T14:27:07.954960Z","iopub.execute_input":"2023-08-21T14:27:07.955318Z","iopub.status.idle":"2023-08-21T14:27:07.965364Z","shell.execute_reply.started":"2023-08-21T14:27:07.955289Z","shell.execute_reply":"2023-08-21T14:27:07.964125Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"mt=ModelandProcessor(model_name,model,processor)","metadata":{"id":"G5IWRTJ5gGQk","execution":{"iopub.status.busy":"2023-08-21T14:27:11.567661Z","iopub.execute_input":"2023-08-21T14:27:11.568100Z","iopub.status.idle":"2023-08-21T14:27:11.580363Z","shell.execute_reply.started":"2023-08-21T14:27:11.568070Z","shell.execute_reply":"2023-08-21T14:27:11.579020Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"(mt.num_layers)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKgHieKjg-Bn","outputId":"b01deeb5-8d23-4cb8-e3ce-e309069dec1a","execution":{"iopub.status.busy":"2023-08-21T12:25:42.019562Z","iopub.execute_input":"2023-08-21T12:25:42.019936Z","iopub.status.idle":"2023-08-21T12:25:42.026467Z","shell.execute_reply.started":"2023-08-21T12:25:42.019904Z","shell.execute_reply":"2023-08-21T12:25:42.025420Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"12"},"metadata":{}}]},{"cell_type":"code","source":"def layername(model, num,block_name, kind=None):\n  if block_name==\"text_encoder\":\n    if hasattr(model,\"model_text_enc\"):\n        if kind == \"embed\":\n            return \"model_text_enc.embeddings\"\n        return f'model_text_enc.encoder.layer.{num}{\"\" if kind is None else \".\" + kind}'\n  elif block_name==\"text_decoder\":\n    if hasattr(model,\"model_text_dec\"):\n        if kind == \"embed\":\n            return f'model_text_dec.bert.embeddings'\n        elif kind==\"cls.decoder\":\n            return f'text_decoder.cls.predictions.decoder'\n        return f'model_text_dec.bert.encoder.layer.{num}{\"\" if kind is None else \".\" + kind}'\n    assert False, \"unknown transformer structure\"","metadata":{"id":"MyuS_oNSc8Fl","execution":{"iopub.status.busy":"2023-08-21T14:27:13.448623Z","iopub.execute_input":"2023-08-21T14:27:13.449031Z","iopub.status.idle":"2023-08-21T14:27:13.456152Z","shell.execute_reply.started":"2023-08-21T14:27:13.449001Z","shell.execute_reply":"2023-08-21T14:27:13.454883Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class ModelOutput(OrderedDict):\n    \"\"\"\n    Base class for all model outputs as dataclass. Has a `__getitem__` that allows indexing by integer or slice (like a\n    tuple) or strings (like a dictionary) that will ignore the `None` attributes. Otherwise behaves like a regular\n    python dictionary.\n\n    <Tip warning={true}>\n\n    You can't unpack a `ModelOutput` directly. Use the [`~utils.ModelOutput.to_tuple`] method to convert it to a tuple\n    before.\n\n    </Tip>\n    \"\"\"\n\n    def __post_init__(self):\n        class_fields = fields(self)\n\n        # Safety and consistency checks\n        if not len(class_fields):\n            raise ValueError(f\"{self.__class__.__name__} has no fields.\")\n        if not all(field.default is None for field in class_fields[1:]):\n            raise ValueError(f\"{self.__class__.__name__} should not have more than one required field.\")\n\n        first_field = getattr(self, class_fields[0].name)\n        other_fields_are_none = all(getattr(self, field.name) is None for field in class_fields[1:])\n\n        if other_fields_are_none and not is_tensor(first_field):\n            if isinstance(first_field, dict):\n                iterator = first_field.items()\n                first_field_iterator = True\n            else:\n                try:\n                    iterator = iter(first_field)\n                    first_field_iterator = True\n                except TypeError:\n                    first_field_iterator = False\n\n            # if we provided an iterator as first field and the iterator is a (key, value) iterator\n            # set the associated fields\n            if first_field_iterator:\n                for idx, element in enumerate(iterator):\n                    if (\n                        not isinstance(element, (list, tuple))\n                        or not len(element) == 2\n                        or not isinstance(element[0], str)\n                    ):\n                        if idx == 0:\n                            # If we do not have an iterator of key/values, set it as attribute\n                            self[class_fields[0].name] = first_field\n                        else:\n                            # If we have a mixed iterator, raise an error\n                            raise ValueError(\n                                f\"Cannot set key/value for {element}. It needs to be a tuple (key, value).\"\n                            )\n                        break\n                    setattr(self, element[0], element[1])\n                    if element[1] is not None:\n                        self[element[0]] = element[1]\n            elif first_field is not None:\n                self[class_fields[0].name] = first_field\n        else:\n            for field in class_fields:\n                v = getattr(self, field.name)\n                if v is not None:\n                    self[field.name] = v\n\n    def __delitem__(self, *args, **kwargs):\n        raise Exception(f\"You cannot use ``__delitem__`` on a {self.__class__.__name__} instance.\")\n\n    def setdefault(self, *args, **kwargs):\n        raise Exception(f\"You cannot use ``setdefault`` on a {self.__class__.__name__} instance.\")\n\n    def pop(self, *args, **kwargs):\n        raise Exception(f\"You cannot use ``pop`` on a {self.__class__.__name__} instance.\")\n\n    def update(self, *args, **kwargs):\n        raise Exception(f\"You cannot use ``update`` on a {self.__class__.__name__} instance.\")\n\n    def __getitem__(self, k):\n        if isinstance(k, str):\n            inner_dict = dict(self.items())\n            return inner_dict[k]\n        else:\n            return self.to_tuple()[k]\n\n    def __setattr__(self, name, value):\n        if name in self.keys() and value is not None:\n            # Don't call self.__setitem__ to avoid recursion errors\n            super().__setitem__(name, value)\n        super().__setattr__(name, value)\n\n    def __setitem__(self, key, value):\n        # Will raise a KeyException if needed\n        super().__setitem__(key, value)\n        # Don't call self.__setattr__ to avoid recursion errors\n        super().__setattr__(key, value)\n\n    def to_tuple(self) -> Tuple[Any]:\n        \"\"\"\n        Convert self to a tuple containing all the attributes/keys that are not `None`.\n        \"\"\"\n        return tuple(self[k] for k in self.keys())","metadata":{"id":"Ps1tubNklWFe","execution":{"iopub.status.busy":"2023-08-21T14:27:16.209932Z","iopub.execute_input":"2023-08-21T14:27:16.210310Z","iopub.status.idle":"2023-08-21T14:27:16.228966Z","shell.execute_reply.started":"2023-08-21T14:27:16.210280Z","shell.execute_reply":"2023-08-21T14:27:16.227764Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class BlipVQAOutput(ModelOutput):\n    \"\"\"\n    Adapted from the base class for vision model's outputs that also contains image embeddings of the pooling of the\n    last hidden states. This class also adds the loss term from the text decoder.\n\n    Args:\n        loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided):\n            Languge modeling loss from the text decoder.\n        image_embeds (`torch.FloatTensor` of shape `(batch_size, output_dim)` *optional* returned when model is initialized with `with_projection=True`):\n            The image embeddings obtained by applying the projection layer to the pooler_output.\n        last_hidden_state (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):\n            Sequence of hidden-states at the output of the last layer of the model.\n        hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n            Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n            one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n\n            Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n        attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n            sequence_length)`.\n\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n            heads.\n    \"\"\"\n    decoder_logits:Optional[Tuple[torch.FloatTensor]] = None\n    image_embeds: Optional[torch.FloatTensor] = None\n    vision_last_hidden_state: torch.FloatTensor=None\n    encoder_last_hidden_state: torch.FloatTensor = None\n    encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n    decoder_last_hidden_state: torch.FloatTensor = None\n    decoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n\n\n","metadata":{"id":"Q9Myryuw9nJi","execution":{"iopub.status.busy":"2023-08-21T14:27:20.025649Z","iopub.execute_input":"2023-08-21T14:27:20.026053Z","iopub.status.idle":"2023-08-21T14:27:20.034046Z","shell.execute_reply.started":"2023-08-21T14:27:20.026025Z","shell.execute_reply":"2023-08-21T14:27:20.032885Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class customblip_temp(torch.nn.Module):\n  def __init__(self,model):\n        super(customblip_temp, self).__init__()\n        self.model_vis = model.vision_model\n        self.model_text_enc = model.text_encoder\n        self.model_text_dec = model.text_decoder\n        self.decoder_pad_token_id = model.decoder_pad_token_id\n        self.decoder_start_token_id = model.decoder_start_token_id\n        self.eos_token_id=model.config.text_config.sep_token_id,\n        self.pad_token_id=model.config.text_config.pad_token_id\n        self.output_attentions=model.config.output_attentions\n        self.use_return_dict=model.config.use_return_dict\n        self.output_hidden_states=model.config.output_hidden_states\n\n  def image_embed(\n      self,\n        list_pixel_values: torch.FloatTensor,\n        output_attentions: Optional[bool] = None,\n        output_hidden_states: Optional[bool] = None,\n    ):\n    image_embeds_tensor=torch.zeros(size=(len(list_pixel_values),577,768))\n    for i in range(len(list_pixel_values)):\n      vision_outputs = self.model_vis(\n              pixel_values=list_pixel_values[i],\n              output_attentions=output_attentions,\n              output_hidden_states=output_hidden_states,\n          )\n      image_embeds = vision_outputs[0]\n      image_embeds_tensor[i,:,:]=image_embeds[0]\n\n    return image_embeds_tensor\n  def forward(\n        self,\n        input_ids: torch.LongTensor,\n        image_embeds: Optional[torch.FloatTensor]=None,\n        attention_mask: Optional[torch.LongTensor] = None,\n        output_attentions: Optional[bool] = None,\n        output_hidden_states: Optional[bool] = None,\n        return_dict: Optional[bool] = None,\n    ) -> Union[Tuple, BlipVQAOutput]:\n\n        return_dict = return_dict if return_dict is not None else self.use_return_dict\n        output_attentions = output_attentions if output_attentions is not None else self.output_attentions\n        output_hidden_states = (\n            output_hidden_states if output_hidden_states is not None else self.output_hidden_states\n        )\n\n        if image_embeds!=None:\n          image_embeds=image_embeds.to(device)\n          image_embeds_w=image_embeds\n          image_attention_mask = torch.ones(image_embeds_w.size()[:-1], dtype=torch.long)\n\n        input_ids=input_ids.to(device)\n        question_embeds = self.model_text_enc(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            encoder_hidden_states=image_embeds_w,\n            encoder_attention_mask=image_attention_mask,\n            output_hidden_states=True,\n        )\n\n        question_embeds_w = question_embeds[0] if not return_dict else question_embeds.last_hidden_state\n\n        bos_ids = torch.full(\n            (question_embeds_w.size(0), 1), fill_value=self.decoder_start_token_id, device=(device)\n        )\n\n        answer_output = self.model_text_dec(\n            input_ids=bos_ids,\n            encoder_hidden_states=question_embeds_w,\n            encoder_attention_mask=attention_mask,\n            output_hidden_states=True,\n            reduction=\"mean\"\n        )\n\n\n        return BlipVQAOutput(\n            decoder_logits=answer_output.logits,\n            image_embeds=image_embeds_w,\n            encoder_last_hidden_state=question_embeds.last_hidden_state,\n            encoder_hidden_states=question_embeds.hidden_states,\n            decoder_hidden_states=answer_output.hidden_states,\n        )","metadata":{"id":"8y9ImDlj8st_","execution":{"iopub.status.busy":"2023-08-21T14:27:23.220222Z","iopub.execute_input":"2023-08-21T14:27:23.220617Z","iopub.status.idle":"2023-08-21T14:27:23.237080Z","shell.execute_reply.started":"2023-08-21T14:27:23.220588Z","shell.execute_reply":"2023-08-21T14:27:23.235962Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"new_model=customblip_temp(model)","metadata":{"id":"RLBBM7Rcj5lb","execution":{"iopub.status.busy":"2023-08-21T14:27:26.937421Z","iopub.execute_input":"2023-08-21T14:27:26.937796Z","iopub.status.idle":"2023-08-21T14:27:26.942423Z","shell.execute_reply.started":"2023-08-21T14:27:26.937765Z","shell.execute_reply":"2023-08-21T14:27:26.941424Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"new_model.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPa5RXThyEuR","outputId":"6a8a0aec-c6e1-4779-ae31-424ccb727fdc","execution":{"iopub.status.busy":"2023-08-21T14:27:28.652972Z","iopub.execute_input":"2023-08-21T14:27:28.653346Z","iopub.status.idle":"2023-08-21T14:27:28.680695Z","shell.execute_reply.started":"2023-08-21T14:27:28.653316Z","shell.execute_reply":"2023-08-21T14:27:28.679723Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"customblip_temp(\n  (model_vis): BlipVisionModel(\n    (embeddings): BlipVisionEmbeddings(\n      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (encoder): BlipEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x BlipEncoderLayer(\n          (self_attn): BlipAttention(\n            (dropout): Dropout(p=0.0, inplace=False)\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (projection): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): BlipMLP(\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (model_text_enc): BlipTextModel(\n    (embeddings): BlipTextEmbeddings(\n      (word_embeddings): Embedding(30524, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): BlipTextEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BlipTextLayer(\n          (attention): BlipTextAttention(\n            (self): BlipTextSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): BlipTextSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (crossattention): BlipTextAttention(\n            (self): BlipTextSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): BlipTextSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): BlipTextIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BlipTextOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (model_text_dec): BlipTextLMHeadModel(\n    (bert): BlipTextModel(\n      (embeddings): BlipTextEmbeddings(\n        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (encoder): BlipTextEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BlipTextLayer(\n            (attention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (crossattention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (intermediate): BlipTextIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BlipTextOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (cls): BlipTextOnlyMLMHead(\n      (predictions): BlipTextLMPredictionHead(\n        (transform): BlipTextPredictionHeadTransform(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (transform_act_fn): GELUActivation()\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def make_inputs(ModelandProcessor,new_model,image,question, device=device):\n  d_temp={}\n  model=ModelandProcessor.model\n  processor=ModelandProcessor.processor\n\n  input_ids = processor(text=question, return_tensors='pt').input_ids.to(device)\n  #input_ids = (torch.tensor(input_ids).unsqueeze(0)).to(device)\n\n  pixel_values=processor(images=image,return_tensors=\"pt\")\n  pixel_values_1=pixel_values.pixel_values.to(device)\n  pixel_values_2=pixel_values.pixel_values.to(device)\n  l=[pixel_values_1,pixel_values_2]\n\n  image_embeds=new_model.image_embed(list_pixel_values=l)\n  image_embeds.to(device)\n\n  tup=(image_embeds,input_ids)\n  return tup\n\n","metadata":{"id":"po0Tjaq7Zq74","execution":{"iopub.status.busy":"2023-08-21T14:27:32.460358Z","iopub.execute_input":"2023-08-21T14:27:32.460715Z","iopub.status.idle":"2023-08-21T14:27:32.468851Z","shell.execute_reply.started":"2023-08-21T14:27:32.460687Z","shell.execute_reply":"2023-08-21T14:27:32.467786Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def predict_from_input(new_model,tup):\n    image_embeds,input_ids=tup\n    output=new_model.forward(image_embeds=image_embeds.to(device),input_ids=input_ids.to(device))\n\n\n    #attention_mask=processor(text=text_input, add_special_tokens=False).attention_mask\n\n    return output","metadata":{"id":"8Q0QZQLjtbYV","execution":{"iopub.status.busy":"2023-08-21T14:27:35.631480Z","iopub.execute_input":"2023-08-21T14:27:35.631889Z","iopub.status.idle":"2023-08-21T14:27:35.637370Z","shell.execute_reply.started":"2023-08-21T14:27:35.631859Z","shell.execute_reply":"2023-08-21T14:27:35.636278Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def result_gen(output, return_p=False):\n    out=output['decoder_logits']\n    probs = torch.softmax(out[:, -1], dim=1)\n    p, preds = torch.max(probs, dim=1)\n    return preds, p","metadata":{"id":"g6lZyfxrnEVA","execution":{"iopub.status.busy":"2023-08-21T14:27:40.317151Z","iopub.execute_input":"2023-08-21T14:27:40.317532Z","iopub.status.idle":"2023-08-21T14:27:40.322907Z","shell.execute_reply.started":"2023-08-21T14:27:40.317504Z","shell.execute_reply":"2023-08-21T14:27:40.321822Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def decoding(mt,pred_prob):\n  preds=pred_prob[0]\n  ans=[]\n  for i in range(preds.size(0)):\n    single_pred=preds[i]\n    decoded_answer=processor.decode(single_pred, skip_special_tokens=True)\n    ans.append(decoded_answer)\n  return ans[0]\n\n","metadata":{"id":"tacMbhkasyZq","execution":{"iopub.status.busy":"2023-08-21T14:27:42.458436Z","iopub.execute_input":"2023-08-21T14:27:42.458828Z","iopub.status.idle":"2023-08-21T14:27:42.464475Z","shell.execute_reply.started":"2023-08-21T14:27:42.458799Z","shell.execute_reply":"2023-08-21T14:27:42.463065Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def prng(shape: tuple, uniform_noise: bool = True) -> np.ndarray:\n      rs = np.random.RandomState(1)\n      if uniform_noise:\n        return rs.uniform(-1, 1, shape)\n      else:\n        return rs.randn(*shape)","metadata":{"id":"Pq3Nun1Du5kW","execution":{"iopub.status.busy":"2023-08-21T14:27:51.575757Z","iopub.execute_input":"2023-08-21T14:27:51.576124Z","iopub.status.idle":"2023-08-21T14:27:51.582232Z","shell.execute_reply.started":"2023-08-21T14:27:51.576096Z","shell.execute_reply":"2023-08-21T14:27:51.581170Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def noisy_embedding(image_embed_tensor,noise=5,percentage_dimensions=1):\n  eps=torch.normal(mean=1,std=noise,size=(image_embed_tensor[1].shape))\n  image_embed_tensor[1]=image_embed_tensor[1]*eps\n  image_embed_tensor.to(device)\n  return(image_embed_tensor)\n","metadata":{"id":"CvivHrZHoJ8x","execution":{"iopub.status.busy":"2023-08-21T14:27:53.706219Z","iopub.execute_input":"2023-08-21T14:27:53.706586Z","iopub.status.idle":"2023-08-21T14:27:53.712043Z","shell.execute_reply.started":"2023-08-21T14:27:53.706558Z","shell.execute_reply":"2023-08-21T14:27:53.711065Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def trace_with_patch(\n    mt,new_model,  # The model\n    image,\n    question,  # A set of inputs # A list of (token index, layername) triples to restore\n    pred_ans,\n    patching_layers,  # Answer probabilities to collect\n    replace=False,  # True to replace with instead of add noise\n    trace_layers=None,  # List of traced outputs to return\n):\n    \"\"\"\n    Runs a single causal trace.  Given a model and a batch input where\n    the batch size is at least two, runs the batch in inference, corrupting\n    a the set of runs [1...n] while also restoring a set of hidden states to\n    the values from an uncorrupted run [0] in the batch.\n\n    The convention used by this function is that the zeroth element of the\n    batch is the uncorrupted run, and the subsequent elements of the batch\n    are the corrupted runs.  The argument tokens_to_mix specifies an\n    be corrupted by adding Gaussian noise to the embedding for the batch\n    inputs other than the first element in the batch.  Alternately,\n    subsequent runs could be corrupted by simply providing different\n    input tokens via the passed input batch.\n\n    Then when running, a specified set of hidden states will be uncorrupted\n    by restoring their values to the same vector that they had in the\n    zeroth uncorrupted run.  This set of hidden states is listed in\n    states_to_patch, by listing [(token_index, layername), ...] pairs.\n    To trace the effect of just a single state, this can be just a single\n    token/layer pair.  To trace the effect of restoring a set of states,\n    any number of token indices and layers can be listed.\n    \"\"\"\n\n    #rs = numpy.random.RandomState(1)  # For reproducibility, use pseudorandom noise\n    image_embed_tensor,input_ids=make_inputs(mt,new_model,image=image,question=question)\n    new_image_embed_tensor=noisy_embedding(image_embed_tensor)\n\n    patch_spec = defaultdict(list)\n    for t, l in patching_layers:\n        patch_spec[l].append(t)\n\n    #clean_image_attention_mask = torch.ones(clean_inp.size()[:-1], dtype=torch.long)\n    #corrup_image_attention_mask=torch.ones(corrupt_inp.size()[:-1], dtype=torch.long)\n    def untuple(x):\n        return x[0] if isinstance(x, tuple) else x\n\n    def patch_rep(x,layer):\n      if layer not in patch_spec:\n        return x\n      else:\n        if untuple(x).size(0)==1:\n          return x\n        else:\n          for t in patch_spec[layer]:\n              h=untuple(x)\n              h[1:, t,:] = h[0,t,:]\n          return x\n\n\n    # With the patching rules defined, run the patched model in inference.\n    #additional_layers = [] if trace_layers is None else trace_layers\n    with torch.no_grad(), TraceDict(\n        new_model,\n        list(patch_spec.keys()),\n        edit_output=patch_rep,\n    ) as td:\n        outputs_exp = new_model.forward(image_embeds=new_image_embed_tensor,input_ids=input_ids)\n\n\n\n\n    # We report softmax probabilities for the answers_t token predictions of interest.\n    probs = torch.softmax(outputs_exp.decoder_logits[1:, -1, :], dim=1).mean(dim=0)[pred_ans]\n    # If tracing all layers, collect all activations together to return.\n    #if trace_layers is not None:\n        #all_traced = torch.stack(\n         #   [untuple(td[layer].output).detach().cpu() for layer in trace_layers], dim=2\n        #)\n\n    return probs\n","metadata":{"id":"PxSrPNOG3qLr","execution":{"iopub.status.busy":"2023-08-21T14:27:56.227074Z","iopub.execute_input":"2023-08-21T14:27:56.227568Z","iopub.status.idle":"2023-08-21T14:27:56.244221Z","shell.execute_reply.started":"2023-08-21T14:27:56.227526Z","shell.execute_reply":"2023-08-21T14:27:56.243234Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def trace_important_states(\n    mt,new_model,start,\n    num_layers,block_name,\n    image,question,\n    pred_ans,num=None,\n    replace=False,\n):\n    table = []\n    image_embed_tensor,input_ids=make_inputs(mt,new_model,image=image,question=question)\n    if num==None:\n      num=input_ids.shape[1]\n    for tnum in range(num):\n        row = []\n        for layer in range(start,num_layers):\n            r = trace_with_patch(\n                mt,new_model,  # The model\n                image,\n                question,  # A set of inputs # A list of (token index, layername) triples to restore\n                pred_ans,\n                [(tnum, layername(new_model, layer,block_name))],\n            )\n            row.append(r)\n        table.append(torch.stack(row))\n    return torch.stack(table)\n","metadata":{"id":"Nasw8InWktng","execution":{"iopub.status.busy":"2023-08-21T14:27:59.429692Z","iopub.execute_input":"2023-08-21T14:27:59.430073Z","iopub.status.idle":"2023-08-21T14:27:59.438370Z","shell.execute_reply.started":"2023-08-21T14:27:59.430044Z","shell.execute_reply":"2023-08-21T14:27:59.437302Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def calculate_hidden_flow(mt,new_model,image,question,block_name,kind=None,expect=None):\n     tup=make_inputs(mt,new_model,image=image,question=question)\n     output=predict_from_input(new_model,tup)\n     pred_prob=result_gen(output)\n     new_image_embed_tensor=noisy_embedding(tup[0])\n     pred_ans_tensor=pred_prob[0][1]\n\n     predicted_ans=decoding(mt,pred_prob)\n     low_score = trace_with_patch(\n        mt,new_model, image,question,pred_ans_tensor, []\n    ).item()\n\n     if block_name=='text_encoder' and kind==None:\n        differences = trace_important_states(\n            mt,new_model,0,\n            12,block_name,\n            image,question,\n            pred_ans_tensor\n        )\n     elif block_name=='text_decoder' and kind==None:\n        differences = trace_important_states(\n            mt,new_model,0,\n            12,block_name,\n            image,question,\n            pred_ans_tensor,1\n        )\n\n     differences = differences.detach().cpu()\n     return dict(\n        scores=differences,\n        low_score=low_score,\n        high_score=pred_prob[1],\n        question=question,\n        answer=predicted_ans,\n        correct_prediction=True,\n        block_name=block_name\n    )\n\n\n\n\n\n\n\n","metadata":{"id":"Jcry6iZtq99d","execution":{"iopub.status.busy":"2023-08-21T14:28:01.934099Z","iopub.execute_input":"2023-08-21T14:28:01.934455Z","iopub.status.idle":"2023-08-21T14:28:01.944082Z","shell.execute_reply.started":"2023-08-21T14:28:01.934427Z","shell.execute_reply":"2023-08-21T14:28:01.942876Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def plot_hidden_flow(\n    mt,\n    new_model,\n    image,question,\n    block_name,\n    savepdf=None,\n):\n    result = calculate_hidden_flow(mt,new_model,image,question,block_name)\n    return result\n\ntemp_diff=[]\ntemp_lows=[]\ndef plot_trace_heatmap(result, savepdf=None, title=None, xlabel=None, modelname=None):\n    differences = result[\"scores\"]\n    low_score = result[\"low_score\"]\n    answer = result[\"answer\"]\n    block_name=(str(result[\"block_name\"]))\n    #print(differences)\n    #print(low_score)\n    #temp_diff.append(differences)\n    #temp_lows.append(low_score)\n   #kind = (\n    #    None\n     #   if (not result[\"kind\"] or result[\"kind\"] == \"None\")\n      #  else str(result[\"kind\"])\n    #)\n    #window = result.get(\"window\", 10)\n   #labels = list(result[\"input_tokens\"])\n    #for i in range(*result[\"subject_range\"]):\n     #   labels[i] = labels[i] + \"*\"\n    labels = list(question.split())\n    labels.insert(0,'[Encode]')\n    labels.append('[End]')\n    labels.append(['[Decode]'])\n    with plt.rc_context(rc={\"font.family\": \"times new roman\"}):\n        fig, ax = plt.subplots(figsize=(3.5, 2), dpi=200)\n        h = ax.pcolor(\n            differences,\n            cmap={ \"text_encoder\": \"Purples\", \"text_decoder\": \"Reds\"}[block_name\n            ],\n            vmin=low_score,\n        )\n        print(differences.shape)\n        ax.invert_yaxis()\n        ax.set_yticks([0.5 + i for i in range(len(differences))])\n        ax.set_xticks([0.5 + i for i in range(0, differences.shape[1] - 1, 1)])\n        ax.set_xticklabels(list(range(0, differences.shape[1] - 1, 1)))\n        if not modelname:\n            modelname = \"BLIP\"\n        if block_name!=None:\n            if block_name=='text_encoder':\n              ax.set_yticklabels(labels)\n              blockname='text_encoder'\n              ax.set_title(f\"Impact of restoring {blockname} after corrupted input\")\n            else:\n              blockname='text_decoder'\n              ax.set_yticklabels(labels_news)\n              ax.set_title(f\"Impact of restoring {blockname} after corrupted input\")\n\n            #ax.set_xlabel(f\"center of interval of {window} restored {kindname} layers\")\n        cb = plt.colorbar(h)\n        if title is not None:\n            ax.set_title(title)\n        if xlabel is not None:\n            ax.set_xlabel(xlabel)\n        elif answer is not None:\n            # The following should be cb.ax.set_xlabel, but this is broken in matplotlib 3.5.1.\n            cb.ax.set_title(f\"p({str(answer).strip()})\", y=-0.16, fontsize=10)\n        if savepdf:\n            os.makedirs(os.path.dirname(savepdf), exist_ok=True)\n            plt.savefig(savepdf, bbox_inches=\"tight\")\n            plt.close()\n        else:\n            plt.show()\n\n\ndef plot_all_flow(mt,new_model, image,question,savepdf=None,subject=None):\n    for block_name in ['text_encoder']:\n        plot_hidden_flow(mt,new_model,image,question,block_name,savepdf)","metadata":{"id":"wBDq_Jd4QFVv","execution":{"iopub.status.busy":"2023-08-21T14:28:04.604838Z","iopub.execute_input":"2023-08-21T14:28:04.605193Z","iopub.status.idle":"2023-08-21T14:28:04.622774Z","shell.execute_reply.started":"2023-08-21T14:28:04.605166Z","shell.execute_reply":"2023-08-21T14:28:04.621755Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"#Test on Pre-trained Model","metadata":{"id":"mNjtkRBTdTyz"}},{"cell_type":"code","source":"import matplotlib.font_manager as font_manager\n\n# Add every font at the specified location\nfont_dir = ['/kaggle/input/timesnew']\nfor font in font_manager.findSystemFonts(font_dir):\n    font_manager.fontManager.addfont(font)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-17T06:58:35.822633Z","iopub.execute_input":"2023-07-17T06:58:35.823492Z","iopub.status.idle":"2023-07-17T06:58:35.831439Z","shell.execute_reply.started":"2023-07-17T06:58:35.823458Z","shell.execute_reply":"2023-07-17T06:58:35.830070Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"import matplotlib.font_manager as fm\n\nfont_list = fm.findSystemFonts()\nfont_names = [fm.get_font(font).family_name for font in font_list]\nprint(font_names)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jiNrfp06VbUn","outputId":"11be5f35-e2bd-4fe9-ec4e-083318a1a1bc","execution":{"iopub.status.busy":"2023-07-17T06:58:38.107432Z","iopub.execute_input":"2023-07-17T06:58:38.108211Z","iopub.status.idle":"2023-07-17T06:58:38.122471Z","shell.execute_reply.started":"2023-07-17T06:58:38.108161Z","shell.execute_reply":"2023-07-17T06:58:38.121240Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"['Ubuntu Mono', 'DejaVu Sans', 'Liberation Mono', 'Ubuntu', 'Source Code Pro', 'Liberation Serif', 'Liberation Sans Narrow', 'DejaVu Sans Mono', 'Liberation Sans Narrow', 'Inconsolata', 'Liberation Sans', 'Ubuntu Mono', 'Liberation Sans Narrow', 'DejaVu Serif', 'Ubuntu Condensed', 'Ubuntu', 'Liberation Mono', 'DejaVu Sans', 'Ubuntu', 'Ubuntu Mono', 'Source Code Pro', 'Ubuntu', 'Liberation Serif', 'Source Code Pro', 'Liberation Sans', 'Liberation Mono', 'Source Code Pro', 'Liberation Serif', 'Source Code Pro', 'Source Code Pro', 'Liberation Sans', 'Ubuntu', 'DejaVu Sans Mono', 'Liberation Mono', 'Ubuntu', 'Source Code Pro', 'Ubuntu', 'Source Code Pro', 'DejaVu Sans', 'DejaVu Serif', 'Source Code Pro', 'Source Code Pro', 'Source Code Pro', 'Source Code Pro', 'Inconsolata', 'Ubuntu', 'Liberation Sans', 'Source Code Pro', 'Liberation Sans Narrow', 'Ubuntu Mono', 'Ubuntu', 'Source Code Pro', 'Liberation Serif']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id=color_df['final_image_id'][602]\nurl=f\"http://images.cocodataset.org/train2017/{image_id}.jpg\"\nimage=Image.open(requests.get(url, stream=True).raw)\nquestion=color_df['question_count'][602]","metadata":{"id":"seLTFWiy1QgB","execution":{"iopub.status.busy":"2023-08-21T12:47:21.471307Z","iopub.execute_input":"2023-08-21T12:47:21.471708Z","iopub.status.idle":"2023-08-21T12:47:21.972562Z","shell.execute_reply.started":"2023-08-21T12:47:21.471677Z","shell.execute_reply":"2023-08-21T12:47:21.971366Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"print(question)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:47:23.712239Z","iopub.execute_input":"2023-08-21T12:47:23.712627Z","iopub.status.idle":"2023-08-21T12:47:23.718076Z","shell.execute_reply.started":"2023-08-21T12:47:23.712596Z","shell.execute_reply":"2023-08-21T12:47:23.717122Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"what is the color of the animal\n","output_type":"stream"}]},{"cell_type":"code","source":"s_new=torch.zeros([1,12])\nfor i in range(5):\n    results_dec=calculate_hidden_flow(mt,new_model,image,question,'text_decoder')\n    differences_dec=results_dec['scores']\n    high_scores_dec=results_dec['high_score'].detach().cpu().numpy()\n    low_scores_dec=results_dec['low_score']\n    answer_dec=results_dec['answer']\n    differences= (differences_dec-low_scores_dec) / (high_scores_dec[0] - low_scores_dec)\n    s_new+=differences\ns_new=s_new/5","metadata":{"id":"Ffe8j6XhT8m2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"177e53b4-c2a1-49d3-9ac3-e831168d69b1","execution":{"iopub.status.busy":"2023-08-21T12:49:51.490527Z","iopub.execute_input":"2023-08-21T12:49:51.490902Z","iopub.status.idle":"2023-08-21T12:50:02.622380Z","shell.execute_reply.started":"2023-08-21T12:49:51.490872Z","shell.execute_reply":"2023-08-21T12:50:02.621228Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"s=torch.zeros([9,12])\nfor i in range(5):\n    results_enc=calculate_hidden_flow(mt,new_model,image,question,'text_encoder')\n    differences_enc=results_enc['scores']\n    high_scores_enc=results_enc['high_score'].detach().cpu().numpy()\n    low_scores_enc=results_enc['low_score']\n    answer_enc=results_enc['answer']\n    differences= (differences_enc-low_scores_enc) / (high_scores_enc[0] - low_scores_enc)\n    s+=differences\ns=s/5","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:47:28.620079Z","iopub.execute_input":"2023-08-21T12:47:28.620640Z","iopub.status.idle":"2023-08-21T12:48:51.490955Z","shell.execute_reply.started":"2023-08-21T12:47:28.620600Z","shell.execute_reply":"2023-08-21T12:48:51.489728Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"differences_enc_norm=s\nanswers_enc=results_enc['answer']","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:49:10.680698Z","iopub.execute_input":"2023-08-21T12:49:10.681079Z","iopub.status.idle":"2023-08-21T12:49:10.686055Z","shell.execute_reply.started":"2023-08-21T12:49:10.681047Z","shell.execute_reply":"2023-08-21T12:49:10.684301Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"differences_dec_norm=s_new\nanswers_dec=results_dec['answer']","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:50:13.346307Z","iopub.execute_input":"2023-08-21T12:50:13.346879Z","iopub.status.idle":"2023-08-21T12:50:13.355404Z","shell.execute_reply.started":"2023-08-21T12:50:13.346837Z","shell.execute_reply":"2023-08-21T12:50:13.354362Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"differences_enc=results_enc['scores']\nhigh_scores_enc=results_enc['high_score'].detach().cpu().numpy()\nlow_scores_enc=results_enc['low_score']\nanswer_enc = results_enc[\"answer\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-21T11:22:43.146639Z","iopub.execute_input":"2023-08-21T11:22:43.147009Z","iopub.status.idle":"2023-08-21T11:22:43.153064Z","shell.execute_reply.started":"2023-08-21T11:22:43.146980Z","shell.execute_reply":"2023-08-21T11:22:43.152160Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"differences_dec=results_dec['scores']\nhigh_scores_dec=results_dec['high_score'].detach().cpu().numpy()\nlow_scores_dec=results_dec['low_score']\nanswer_dec = results_dec[\"answer\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-21T11:23:10.046308Z","iopub.execute_input":"2023-08-21T11:23:10.046716Z","iopub.status.idle":"2023-08-21T11:23:10.052429Z","shell.execute_reply.started":"2023-08-21T11:23:10.046681Z","shell.execute_reply":"2023-08-21T11:23:10.051209Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"answer_enc","metadata":{"execution":{"iopub.status.busy":"2023-08-21T11:22:51.564757Z","iopub.execute_input":"2023-08-21T11:22:51.565107Z","iopub.status.idle":"2023-08-21T11:22:51.571027Z","shell.execute_reply.started":"2023-08-21T11:22:51.565080Z","shell.execute_reply":"2023-08-21T11:22:51.570161Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'purple'"},"metadata":{}}]},{"cell_type":"code","source":"differences_dec_norm=\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T11:23:13.355109Z","iopub.execute_input":"2023-08-21T11:23:13.355502Z","iopub.status.idle":"2023-08-21T11:23:13.361965Z","shell.execute_reply.started":"2023-08-21T11:23:13.355452Z","shell.execute_reply":"2023-08-21T11:23:13.360549Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"differences_enc_norm.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-17T07:29:11.546511Z","iopub.execute_input":"2023-07-17T07:29:11.546903Z","iopub.status.idle":"2023-07-17T07:29:11.557386Z","shell.execute_reply.started":"2023-07-17T07:29:11.546875Z","shell.execute_reply":"2023-07-17T07:29:11.556027Z"},"trusted":true},"execution_count":146,"outputs":[{"execution_count":146,"output_type":"execute_result","data":{"text/plain":"torch.Size([9, 12])"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-07-17T06:41:12.094328Z","iopub.execute_input":"2023-07-17T06:41:12.094723Z","iopub.status.idle":"2023-07-17T06:41:12.101323Z","shell.execute_reply.started":"2023-07-17T06:41:12.094694Z","shell.execute_reply":"2023-07-17T06:41:12.098932Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"differences_new_norm=np.append(differences_enc_norm,differences_dec_norm,axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T06:41:37.375875Z","iopub.execute_input":"2023-07-17T06:41:37.376247Z","iopub.status.idle":"2023-07-17T06:41:37.382107Z","shell.execute_reply.started":"2023-07-17T06:41:37.376218Z","shell.execute_reply":"2023-07-17T06:41:37.380793Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"differences_new_norm.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-17T06:41:45.137382Z","iopub.execute_input":"2023-07-17T06:41:45.137753Z","iopub.status.idle":"2023-07-17T06:41:45.144195Z","shell.execute_reply.started":"2023-07-17T06:41:45.137725Z","shell.execute_reply":"2023-07-17T06:41:45.143113Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"(10, 12)"},"metadata":{}}]},{"cell_type":"code","source":"differences_dec_norm=differences_new_norm[9,:]","metadata":{"execution":{"iopub.status.busy":"2023-07-17T07:08:58.223995Z","iopub.execute_input":"2023-07-17T07:08:58.224928Z","iopub.status.idle":"2023-07-17T07:08:58.230382Z","shell.execute_reply.started":"2023-07-17T07:08:58.224894Z","shell.execute_reply":"2023-07-17T07:08:58.228747Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"differences_enc_norm.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-17T07:13:37.109063Z","iopub.execute_input":"2023-07-17T07:13:37.109455Z","iopub.status.idle":"2023-07-17T07:13:37.116514Z","shell.execute_reply.started":"2023-07-17T07:13:37.109425Z","shell.execute_reply":"2023-07-17T07:13:37.115604Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"torch.Size([9, 12])"},"metadata":{}}]},{"cell_type":"code","source":"labels = list(question.split())\nlabels.insert(0,'[Encode]')\nlabels.append('[End]')\nlabels.append('[Decode]')","metadata":{"execution":{"iopub.status.busy":"2023-07-19T17:32:17.248064Z","iopub.execute_input":"2023-07-19T17:32:17.248430Z","iopub.status.idle":"2023-07-19T17:32:17.258544Z","shell.execute_reply.started":"2023-07-19T17:32:17.248399Z","shell.execute_reply":"2023-07-19T17:32:17.257377Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"labels = list(question.split())\nlabels.insert(0,'[Encode]')\nlabels.append('[End]')","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:50:20.515162Z","iopub.execute_input":"2023-08-21T12:50:20.515659Z","iopub.status.idle":"2023-08-21T12:50:20.525359Z","shell.execute_reply.started":"2023-08-21T12:50:20.515615Z","shell.execute_reply":"2023-08-21T12:50:20.524231Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2023-08-21T11:23:56.917239Z","iopub.execute_input":"2023-08-21T11:23:56.917641Z","iopub.status.idle":"2023-08-21T11:23:56.924979Z","shell.execute_reply.started":"2023-08-21T11:23:56.917612Z","shell.execute_reply":"2023-08-21T11:23:56.923775Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"['[Encode]', 'what', 'is', 'the', 'color', 'of', 'the', 'character', '[End]']"},"metadata":{}}]},{"cell_type":"code","source":"labels=['[Decode]']","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:53:01.140391Z","iopub.execute_input":"2023-08-21T12:53:01.141094Z","iopub.status.idle":"2023-08-21T12:53:01.145836Z","shell.execute_reply.started":"2023-08-21T12:53:01.141059Z","shell.execute_reply":"2023-08-21T12:53:01.144539Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def avgnormal_heatmap(differences_new_norm,labels,answer_dec, savepdf=None, title=None, xlabel=None, modelname=None):\n  #if block_name=='Question Encoder':\n    #avg_differences=result['differences_TE']\n    #avg_low_score=result['low_score_TE']\n    #answer = \"QE\"\n    #labels=['[Encode]','Q_token_1','Q_token_2','Q_token_3','Q_token_4','Q_token_5','Q_token_6','Q_token_7','[End]']\n    #block_name='text_encoder'\n  #elif block_name=='Answer Decoder':\n    #avg_differences=result['differences_DE']\n    #avg_low_score=result['low_score_DE']\n    #answer = \"ANS\"\n    #labels=['Decode']\n    #block_name='text_decoder'\n  normalize_diffs=differences_new_norm\n  block_name='text_encoder'\n  labels=labels\n  answer=answer_dec\n\n  with plt.rc_context(rc={\"font.family\": \"Liberation Serif\"}):\n        fig, ax = plt.subplots(figsize=(3.5, 0.5), dpi=200)\n        h = ax.pcolor(\n            normalize_diffs,\n            cmap={ \"text_encoder\": \"Greens\"}[block_name\n            ],\n            vmin=0.0,\n        )\n        ax.invert_yaxis()\n        ax.set_yticks([0.5 + i for i in range(len(normalize_diffs))])\n        ax.set_xticks([0.5 + i for i in range(0, normalize_diffs.shape[1] - 1, 1)])\n        ax.set_xticklabels(list(range(0, normalize_diffs.shape[1] - 1, 1)))\n        if not modelname:\n            modelname = \"BLIP\"\n        if block_name!=None:\n              ax.set_yticklabels(labels)\n              #ax.set_title(f\"Average Impact of restoring after corrupted input over {count} samples\")\n            #ax.set_xlabel(f\"center of interval of {window} restored {kindname} layers\")\n        cb = plt.colorbar(h)\n        if title is not None:\n            ax.set_title(title)\n        if xlabel is not None:\n            ax.set_xlabel(xlabel)\n        if answer is not None:\n            # The following should be cb.ax.set_xlabel, but this is broken in matplotlib 3.5.1.\n            cb.ax.set_title(f\"p({answer})\", y=-0.6, fontsize=10)\n        if savepdf:\n            #os.makedirs(os.path.dirname(savepdf), exist_ok=True)\n            plt.savefig(savepdf, bbox_inches=\"tight\")\n            plt.close()\n        else:\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:53:24.510269Z","iopub.execute_input":"2023-08-21T12:53:24.510661Z","iopub.status.idle":"2023-08-21T12:53:24.524226Z","shell.execute_reply.started":"2023-08-21T12:53:24.510630Z","shell.execute_reply":"2023-08-21T12:53:24.522511Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"avgnormal_heatmap(differences_dec_norm,labels,answer_dec,'/kaggle/working/patch_animal_decoder.pdf',xlabel='Layers')","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:53:36.136285Z","iopub.execute_input":"2023-08-21T12:53:36.136663Z","iopub.status.idle":"2023-08-21T12:53:36.494924Z","shell.execute_reply.started":"2023-08-21T12:53:36.136631Z","shell.execute_reply":"2023-08-21T12:53:36.493603Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def plot_average_hidden_flow(\n    mt,\n    new_model,\n    image,question,\n    block_name,\n    savepdf=None,\n):\n    result = calculate_hidden_flow(mt,new_model,image,question,block_name)\n    return result","metadata":{"id":"L-4CMzubVSZF","execution":{"iopub.status.busy":"2023-08-21T14:28:31.024325Z","iopub.execute_input":"2023-08-21T14:28:31.024674Z","iopub.status.idle":"2023-08-21T14:28:31.030296Z","shell.execute_reply.started":"2023-08-21T14:28:31.024647Z","shell.execute_reply":"2023-08-21T14:28:31.029407Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"color_df=pd.read_csv('/kaggle/input/coca-qa/color_coco_qa.csv')","metadata":{"id":"NLC1_oSxXi9P","execution":{"iopub.status.busy":"2023-08-21T14:28:26.560693Z","iopub.execute_input":"2023-08-21T14:28:26.561087Z","iopub.status.idle":"2023-08-21T14:28:26.616798Z","shell.execute_reply.started":"2023-08-21T14:28:26.561060Z","shell.execute_reply":"2023-08-21T14:28:26.615883Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def convert_to_id(df):\n  temp=df['train_image_id_count']\n  df.drop(['Unnamed: 0'],axis=1)\n  image_id=[]\n  for i in temp:\n    str_i=str(i)\n    num_of_zeros=12-len(str_i)\n    temp_s=\"\"\n    for j in range(num_of_zeros):\n      temp_s+=\"0\"\n    temp_s+=str_i\n    image_id.append(temp_s)\n  df.insert(loc=1,column = 'final_image_id',\n          value = image_id)\n  return df","metadata":{"id":"KqXcf9QcX-Tv","execution":{"iopub.status.busy":"2023-08-21T14:28:28.188027Z","iopub.execute_input":"2023-08-21T14:28:28.188381Z","iopub.status.idle":"2023-08-21T14:28:28.194987Z","shell.execute_reply.started":"2023-08-21T14:28:28.188354Z","shell.execute_reply":"2023-08-21T14:28:28.194068Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"color_df=convert_to_id(color_df)","metadata":{"id":"RHy5TfwoX_Gg","execution":{"iopub.status.busy":"2023-08-21T14:28:33.402228Z","iopub.execute_input":"2023-08-21T14:28:33.402660Z","iopub.status.idle":"2023-08-21T14:28:33.453886Z","shell.execute_reply.started":"2023-08-21T14:28:33.402626Z","shell.execute_reply":"2023-08-21T14:28:33.452938Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"color_df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"HTAxCXV1qhh9","outputId":"6d6e386d-5dce-4ad9-d674-3db9494a173f","execution":{"iopub.status.busy":"2023-08-21T12:40:01.070870Z","iopub.execute_input":"2023-08-21T12:40:01.071221Z","iopub.status.idle":"2023-08-21T12:40:01.091212Z","shell.execute_reply.started":"2023-08-21T12:40:01.071194Z","shell.execute_reply":"2023-08-21T12:40:01.090049Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0 final_image_id  train_image_id_count  \\\n0               0   000000023004                 23004   \n1               1   000000220218                220218   \n2               2   000000491525                491525   \n3               3   000000256565                256565   \n4               4   000000351203                351203   \n...           ...            ...                   ...   \n13108       13108   000000463172                463172   \n13109       13109   000000138368                138368   \n13110       13110   000000381027                381027   \n13111       13111   000000411815                411815   \n13112       13112   000000530479                530479   \n\n                           question_count answer_count  \n0         what is the color of the horses        brown  \n1      what is the color of the character       purple  \n2            what is the color of the dog        black  \n3           what is the color of the sign          red  \n4          what is the color of the leash       orange  \n...                                   ...          ...  \n13108       what is the color of the bird        white  \n13109      what is the color of the court         blue  \n13110     what is the color of the inside       purple  \n13111      what is the color of the field        green  \n13112        what is the color of the sky         blue  \n\n[13113 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>final_image_id</th>\n      <th>train_image_id_count</th>\n      <th>question_count</th>\n      <th>answer_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>000000023004</td>\n      <td>23004</td>\n      <td>what is the color of the horses</td>\n      <td>brown</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>000000220218</td>\n      <td>220218</td>\n      <td>what is the color of the character</td>\n      <td>purple</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>000000491525</td>\n      <td>491525</td>\n      <td>what is the color of the dog</td>\n      <td>black</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>000000256565</td>\n      <td>256565</td>\n      <td>what is the color of the sign</td>\n      <td>red</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>000000351203</td>\n      <td>351203</td>\n      <td>what is the color of the leash</td>\n      <td>orange</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13108</th>\n      <td>13108</td>\n      <td>000000463172</td>\n      <td>463172</td>\n      <td>what is the color of the bird</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>13109</th>\n      <td>13109</td>\n      <td>000000138368</td>\n      <td>138368</td>\n      <td>what is the color of the court</td>\n      <td>blue</td>\n    </tr>\n    <tr>\n      <th>13110</th>\n      <td>13110</td>\n      <td>000000381027</td>\n      <td>381027</td>\n      <td>what is the color of the inside</td>\n      <td>purple</td>\n    </tr>\n    <tr>\n      <th>13111</th>\n      <td>13111</td>\n      <td>000000411815</td>\n      <td>411815</td>\n      <td>what is the color of the field</td>\n      <td>green</td>\n    </tr>\n    <tr>\n      <th>13112</th>\n      <td>13112</td>\n      <td>000000530479</td>\n      <td>530479</td>\n      <td>what is the color of the sky</td>\n      <td>blue</td>\n    </tr>\n  </tbody>\n</table>\n<p>13113 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"img_id_arr=[]\nanswer_arr=[]\nquestion_arr=[]\nfor i in range(len(color_df['question_count'])):\n  f_i_i=color_df['final_image_id'][i]\n  answer=color_df['answer_count'][i]\n  ques=color_df['question_count'][i]\n  if len(ques.split())==7:\n    question_arr.append(ques)\n    answer_arr.append(answer)\n    img_id_arr.append(f_i_i)\n\n\n","metadata":{"id":"pDOb6RKvqRRm","execution":{"iopub.status.busy":"2023-08-21T14:28:35.426792Z","iopub.execute_input":"2023-08-21T14:28:35.427272Z","iopub.status.idle":"2023-08-21T14:28:35.938437Z","shell.execute_reply.started":"2023-08-21T14:28:35.427234Z","shell.execute_reply":"2023-08-21T14:28:35.937292Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"color_df=pd.DataFrame()","metadata":{"id":"ilm-MV8MrHZ4","execution":{"iopub.status.busy":"2023-08-21T14:28:39.584260Z","iopub.execute_input":"2023-08-21T14:28:39.584637Z","iopub.status.idle":"2023-08-21T14:28:39.590091Z","shell.execute_reply.started":"2023-08-21T14:28:39.584596Z","shell.execute_reply":"2023-08-21T14:28:39.589104Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"color_df['final_image_id']=img_id_arr\ncolor_df['question_count']=question_arr\ncolor_df['answer_count']=answer_arr","metadata":{"id":"P6PS9_qVrLZV","execution":{"iopub.status.busy":"2023-08-21T14:28:41.764231Z","iopub.execute_input":"2023-08-21T14:28:41.764822Z","iopub.status.idle":"2023-08-21T14:28:41.783994Z","shell.execute_reply.started":"2023-08-21T14:28:41.764784Z","shell.execute_reply":"2023-08-21T14:28:41.783104Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"color_df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"G9xsUexbrVXW","outputId":"089568db-47bd-4fab-b439-6bed6477ec73","execution":{"iopub.status.busy":"2023-08-21T14:28:44.290539Z","iopub.execute_input":"2023-08-21T14:28:44.290953Z","iopub.status.idle":"2023-08-21T14:28:44.309867Z","shell.execute_reply.started":"2023-08-21T14:28:44.290921Z","shell.execute_reply":"2023-08-21T14:28:44.308800Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"      final_image_id                      question_count answer_count\n0       000000023004     what is the color of the horses        brown\n1       000000220218  what is the color of the character       purple\n2       000000491525        what is the color of the dog        black\n3       000000256565       what is the color of the sign          red\n4       000000351203      what is the color of the leash       orange\n...              ...                                 ...          ...\n13057   000000463172       what is the color of the bird        white\n13058   000000138368      what is the color of the court         blue\n13059   000000381027     what is the color of the inside       purple\n13060   000000411815      what is the color of the field        green\n13061   000000530479        what is the color of the sky         blue\n\n[13062 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>final_image_id</th>\n      <th>question_count</th>\n      <th>answer_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000023004</td>\n      <td>what is the color of the horses</td>\n      <td>brown</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000000220218</td>\n      <td>what is the color of the character</td>\n      <td>purple</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000000491525</td>\n      <td>what is the color of the dog</td>\n      <td>black</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000000256565</td>\n      <td>what is the color of the sign</td>\n      <td>red</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000000351203</td>\n      <td>what is the color of the leash</td>\n      <td>orange</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13057</th>\n      <td>000000463172</td>\n      <td>what is the color of the bird</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>13058</th>\n      <td>000000138368</td>\n      <td>what is the color of the court</td>\n      <td>blue</td>\n    </tr>\n    <tr>\n      <th>13059</th>\n      <td>000000381027</td>\n      <td>what is the color of the inside</td>\n      <td>purple</td>\n    </tr>\n    <tr>\n      <th>13060</th>\n      <td>000000411815</td>\n      <td>what is the color of the field</td>\n      <td>green</td>\n    </tr>\n    <tr>\n      <th>13061</th>\n      <td>000000530479</td>\n      <td>what is the color of the sky</td>\n      <td>blue</td>\n    </tr>\n  </tbody>\n</table>\n<p>13062 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"diff_text_enc=0\nlow_s_text_enc=0\ndiff_text_dec=0\nlow_s_text_dec=0\nhigh_s_text_enc=0\nhigh_s_text_dec=0\ncount=0\nc1=0\nc2=0\nfor i in range(len(color_df['final_image_id'])):\n  count+=1\n  image_id=color_df['final_image_id'][i]\n  url=f\"http://images.cocodataset.org/train2017/{image_id}.jpg\"\n  image=Image.open(requests.get(url, stream=True).raw)\n  question=color_df['question_count'][i]\n  #question=question.rstrip()\n  result_temp=plot_average_hidden_flow(mt,new_model,image,question,'text_encoder')\n  #print(result_temp['scores'])\n  try:\n    diff_text_enc+=result_temp['scores']\n    low_s_text_enc+=result_temp['low_score']\n    high_s_text_enc+=result_temp['high_score'].detach().cpu().numpy()\n    \n  except:\n    c1+=1\n    count=count-1\n    continue\n\n  result_temp_1=plot_average_hidden_flow(mt,new_model,image,question,'text_decoder')\n  try:\n    diff_text_dec+=result_temp_1['scores']\n    low_s_text_dec+=result_temp_1['low_score']\n    high_s_text_dec+=result_temp_1['high_score'].detach().cpu().numpy()\n  except:\n    c2+=1\n    count=count-1\n    continue\n  print(count)\n  if count==200:\n    break","metadata":{"id":"UiaknrzUXpM9","execution":{"iopub.status.busy":"2023-08-21T14:28:57.823070Z","iopub.execute_input":"2023-08-21T14:28:57.823437Z","iopub.status.idle":"2023-08-21T15:35:30.626505Z","shell.execute_reply.started":"2023-08-21T14:28:57.823408Z","shell.execute_reply":"2023-08-21T15:35:30.625526Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n","output_type":"stream"}]},{"cell_type":"code","source":"c1","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:36:11.844158Z","iopub.execute_input":"2023-08-21T15:36:11.847037Z","iopub.status.idle":"2023-08-21T15:36:11.857221Z","shell.execute_reply.started":"2023-08-21T15:36:11.846996Z","shell.execute_reply":"2023-08-21T15:36:11.856311Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"8"},"metadata":{}}]},{"cell_type":"code","source":"diff_text_enc=diff_text_enc/(count)\nlow_s_text_enc=low_s_text_enc/(count)\nhigh_s_text_enc=high_s_text_enc/(count)\ndiff_text_dec=diff_text_dec/(count)\nlow_s_text_dec=low_s_text_dec/(count)\nhigh_s_text_dec=high_s_text_dec/(count)","metadata":{"id":"39GJcG8P0IRZ","execution":{"iopub.status.busy":"2023-08-21T15:36:48.198825Z","iopub.execute_input":"2023-08-21T15:36:48.199186Z","iopub.status.idle":"2023-08-21T15:36:48.205686Z","shell.execute_reply.started":"2023-08-21T15:36:48.199159Z","shell.execute_reply":"2023-08-21T15:36:48.204631Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"high_s_text_dec","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:37:53.568288Z","iopub.execute_input":"2023-08-21T15:37:53.568709Z","iopub.status.idle":"2023-08-21T15:37:53.581090Z","shell.execute_reply.started":"2023-08-21T15:37:53.568677Z","shell.execute_reply":"2023-08-21T15:37:53.580062Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"array([0.72906446, 0.72906446], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"result={'differences_TE':diff_text_enc,'low_score_TE':low_s_text_enc,'high_score_TE':high_s_text_dec,'differences_DE':diff_text_dec,'low_score_DE':low_s_text_dec,'high_score_DE':high_s_text_dec}","metadata":{"id":"jqFyLPdgrub5","execution":{"iopub.status.busy":"2023-08-21T15:37:34.848481Z","iopub.execute_input":"2023-08-21T15:37:34.848874Z","iopub.status.idle":"2023-08-21T15:37:34.854043Z","shell.execute_reply.started":"2023-08-21T15:37:34.848844Z","shell.execute_reply":"2023-08-21T15:37:34.852987Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print(result)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:47:21.800446Z","iopub.execute_input":"2023-08-21T15:47:21.800846Z","iopub.status.idle":"2023-08-21T15:47:21.832190Z","shell.execute_reply.started":"2023-08-21T15:47:21.800816Z","shell.execute_reply":"2023-08-21T15:47:21.831029Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"{'differences_TE': tensor([[0.0029, 0.0025, 0.0022, 0.0041, 0.0034, 0.0022, 0.0022, 0.0055, 0.0028,\n         0.0032, 0.0058, 0.1755],\n        [0.0033, 0.0037, 0.0032, 0.0043, 0.0034, 0.0035, 0.0035, 0.0030, 0.0037,\n         0.0024, 0.0037, 0.1695],\n        [0.0035, 0.0021, 0.0026, 0.0045, 0.0030, 0.0017, 0.0031, 0.0032, 0.0017,\n         0.0036, 0.0060, 0.1987],\n        [0.0056, 0.0035, 0.0028, 0.0033, 0.0069, 0.0033, 0.0047, 0.0036, 0.0040,\n         0.0036, 0.0044, 0.1837],\n        [0.0038, 0.0021, 0.0032, 0.0022, 0.0029, 0.0038, 0.0033, 0.0024, 0.0028,\n         0.0032, 0.0051, 0.1446],\n        [0.0031, 0.0029, 0.0038, 0.0035, 0.0022, 0.0032, 0.0044, 0.0032, 0.0042,\n         0.0033, 0.0030, 0.1495],\n        [0.0040, 0.0025, 0.0041, 0.0058, 0.0022, 0.0018, 0.0024, 0.0026, 0.0031,\n         0.0041, 0.0032, 0.1861],\n        [0.0029, 0.0038, 0.0022, 0.0045, 0.0039, 0.0035, 0.0031, 0.0036, 0.0055,\n         0.0039, 0.0036, 0.0924],\n        [0.0036, 0.0036, 0.0041, 0.0034, 0.0031, 0.0034, 0.0027, 0.0030, 0.0024,\n         0.0028, 0.0039, 0.0074]]), 'low_score_TE': 0.003713574256241543, 'high_score_TE': array([0.72906446, 0.72906446], dtype=float32), 'differences_DE': tensor([[0.0030, 0.0022, 0.0033, 0.0035, 0.0019, 0.0021, 0.0029, 0.0024, 0.0153,\n         0.2498, 0.6180, 0.7291]]), 'low_score_DE': 0.0030076911519289953, 'high_score_DE': array([0.72906446, 0.72906446], dtype=float32)}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:47:04.824266Z","iopub.execute_input":"2023-08-21T15:47:04.824674Z","iopub.status.idle":"2023-08-21T15:47:05.009949Z","shell.execute_reply.started":"2023-08-21T15:47:04.824641Z","shell.execute_reply":"2023-08-21T15:47:05.008645Z"},"trusted":true},"execution_count":49,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"],"ename":"TypeError","evalue":"Object of type Tensor is not JSON serializable","output_type":"error"}]},{"cell_type":"code","source":"normalized_text_dec=(result['differences_DE']-result['low_score_DE'])/(result['high_score_DE'][0]-result['low_score_DE'])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:38:27.041531Z","iopub.execute_input":"2023-08-21T15:38:27.041922Z","iopub.status.idle":"2023-08-21T15:38:27.048811Z","shell.execute_reply.started":"2023-08-21T15:38:27.041891Z","shell.execute_reply":"2023-08-21T15:38:27.047804Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"normalized_text_enc=result['differences_TE']-result['low_score_TE']/(result['high_score_TE'][0]-result['low_score_TE'])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:38:29.511781Z","iopub.execute_input":"2023-08-21T15:38:29.512207Z","iopub.status.idle":"2023-08-21T15:38:29.521855Z","shell.execute_reply.started":"2023-08-21T15:38:29.512171Z","shell.execute_reply":"2023-08-21T15:38:29.520644Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"mean_enc = torch.mean(normalized_text_enc)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:03:28.928057Z","iopub.execute_input":"2023-07-19T14:03:28.928782Z","iopub.status.idle":"2023-07-19T14:03:28.943196Z","shell.execute_reply.started":"2023-07-19T14:03:28.928748Z","shell.execute_reply":"2023-07-19T14:03:28.942278Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"mean_enc","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:03:30.618631Z","iopub.execute_input":"2023-07-19T14:03:30.619096Z","iopub.status.idle":"2023-07-19T14:03:30.676946Z","shell.execute_reply.started":"2023-07-19T14:03:30.619057Z","shell.execute_reply":"2023-07-19T14:03:30.669808Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"tensor(5.9605e-08)"},"metadata":{}}]},{"cell_type":"code","source":"mean_dec = torch.mean(normalized_text_dec)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:03:56.462506Z","iopub.execute_input":"2023-07-19T14:03:56.462967Z","iopub.status.idle":"2023-07-19T14:03:56.471312Z","shell.execute_reply.started":"2023-07-19T14:03:56.462928Z","shell.execute_reply":"2023-07-19T14:03:56.470105Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"mean_dec","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:03:58.708183Z","iopub.execute_input":"2023-07-19T14:03:58.709307Z","iopub.status.idle":"2023-07-19T14:03:58.717892Z","shell.execute_reply.started":"2023-07-19T14:03:58.709264Z","shell.execute_reply":"2023-07-19T14:03:58.716667Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"tensor(5.9605e-08)"},"metadata":{}}]},{"cell_type":"code","source":"x = .detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T10:44:44.043289Z","iopub.execute_input":"2023-07-17T10:44:44.043676Z","iopub.status.idle":"2023-07-17T10:44:44.050249Z","shell.execute_reply.started":"2023-07-17T10:44:44.043643Z","shell.execute_reply":"2023-07-17T10:44:44.049279Z"},"trusted":true},"execution_count":183,"outputs":[{"execution_count":183,"output_type":"execute_result","data":{"text/plain":"torch.Tensor"},"metadata":{}}]},{"cell_type":"code","source":"def avgnormal_heatmap(differences_new_norm, savepdf=None, title=None, xlabel=None, modelname=None):\n  #if block_name=='Question Encoder':\n    #avg_differences=result['differences_TE']\n    #avg_low_score=result['low_score_TE']\n    #answer = \"QE\"\n    #labels=['[Encode]','Q_token_1','Q_token_2','Q_token_3','Q_token_4','Q_token_5','Q_token_6','Q_token_7','[End]']\n    #block_name='text_encoder'\n  #elif block_name=='Answer Decoder':\n    #avg_differences=result['differences_DE']\n    #avg_low_score=result['low_score_DE']\n    #answer = \"ANS\"\n    #labels=['Decode']\n    #block_name='text_decoder'\n  normalize_diffs=differences_new_norm\n  block_name='text_encoder'\n  #labels=['[Encode]','Q_token_1','Q_token_2','Q_token_3','Q_token_4','Q_token_5','Q_token_6','Q_token_7','[End]']\n  labels=['[Decode]']\n  answer=\"Answer\"\n\n  with plt.rc_context(rc={\"font.family\": \"Liberation Serif\"}):\n        fig, ax = plt.subplots(figsize=(3.5, 0.5), dpi=200)\n        h = ax.pcolor(\n            normalize_diffs,\n            cmap={ \"text_encoder\": \"Blues\"}[block_name\n            ],\n            vmin=0.0,\n        )\n        ax.invert_yaxis()\n        ax.set_yticks([0.5 + i for i in range(len(normalize_diffs))])\n        ax.set_xticks([0.5 + i for i in range(0, normalize_diffs.shape[1] - 1, 1)])\n        ax.set_xticklabels(list(range(0, normalize_diffs.shape[1] - 1, 1)))\n        if not modelname:\n            modelname = \"BLIP\"\n        if block_name!=None:\n              ax.set_yticklabels(labels)\n              #ax.set_title(f\"Average Impact of restoring after corrupted input over {count} samples\")\n            #ax.set_xlabel(f\"center of interval of {window} restored {kindname} layers\")\n        cb = plt.colorbar(h)\n        if title is not None:\n            ax.set_title(title)\n        if xlabel is not None:\n            ax.set_xlabel(xlabel)\n        if answer is not None:\n            # The following should be cb.ax.set_xlabel, but this is broken in matplotlib 3.5.1.\n            cb.ax.set_title(f\"p({answer})\", y=-0.6, fontsize=10)\n        if savepdf:\n            #os.makedirs(os.path.dirname(savepdf), exist_ok=True)\n            plt.savefig(savepdf, bbox_inches=\"tight\")\n            plt.close()\n        else:\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:40:16.532423Z","iopub.execute_input":"2023-08-21T15:40:16.532836Z","iopub.status.idle":"2023-08-21T15:40:16.546114Z","shell.execute_reply.started":"2023-08-21T15:40:16.532803Z","shell.execute_reply":"2023-08-21T15:40:16.545007Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"avgnormal_heatmap(normalized_text_enc,'/kaggle/working/causal_trace_200samp_encoder.pdf')","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:39:36.247372Z","iopub.execute_input":"2023-08-21T15:39:36.247745Z","iopub.status.idle":"2023-08-21T15:39:37.008416Z","shell.execute_reply.started":"2023-08-21T15:39:36.247700Z","shell.execute_reply":"2023-08-21T15:39:37.006913Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"avgnormal_heatmap(normalized_text_dec,'/kaggle/working/causal_trace_200samp_decoder.pdf',xlabel='Layers')","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:40:19.828677Z","iopub.execute_input":"2023-08-21T15:40:19.829077Z","iopub.status.idle":"2023-08-21T15:40:20.193131Z","shell.execute_reply.started":"2023-08-21T15:40:19.829047Z","shell.execute_reply":"2023-08-21T15:40:20.191778Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"last_a = len(normalized_text_enc) - 1\navg_object_score=normalized_text_enc[last_a]","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:04:17.351706Z","iopub.execute_input":"2023-07-19T14:04:17.352057Z","iopub.status.idle":"2023-07-19T14:04:17.356679Z","shell.execute_reply.started":"2023-07-19T14:04:17.352027Z","shell.execute_reply":"2023-07-19T14:04:17.355755Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"print(\n        \"Best average indirect effect on object token in Question Encoder block\", avg_object_score.mean().max()\n    )","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:04:18.828746Z","iopub.execute_input":"2023-07-19T14:04:18.829139Z","iopub.status.idle":"2023-07-19T14:04:18.835996Z","shell.execute_reply.started":"2023-07-19T14:04:18.829106Z","shell.execute_reply":"2023-07-19T14:04:18.834895Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Best average indirect effect on object token in Question Encoder block tensor(5.9605e-08)\n","output_type":"stream"}]},{"cell_type":"code","source":"last_a = len(normalized_text_dec) - 1\navg_object_score=normalized_text_dec[last_a]","metadata":{"execution":{"iopub.status.busy":"2023-07-19T11:21:30.178627Z","iopub.execute_input":"2023-07-19T11:21:30.179034Z","iopub.status.idle":"2023-07-19T11:21:30.184578Z","shell.execute_reply.started":"2023-07-19T11:21:30.179000Z","shell.execute_reply":"2023-07-19T11:21:30.183486Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"print(\n        \"Best average indirect effect on object token in Answer Decoder block\", avg_object_score.mean().max()\n    )","metadata":{"execution":{"iopub.status.busy":"2023-07-19T11:21:32.078071Z","iopub.execute_input":"2023-07-19T11:21:32.078447Z","iopub.status.idle":"2023-07-19T11:21:32.085408Z","shell.execute_reply.started":"2023-07-19T11:21:32.078416Z","shell.execute_reply":"2023-07-19T11:21:32.084261Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"Best average indirect effect on object token in Answer Decoder block tensor(0.0043)\n","output_type":"stream"}]},{"cell_type":"code","source":"def avg_heatmap(result,block_name, savepdf=None, title=None, xlabel=None, modelname=None):\n  if block_name=='Question Encoder':\n    avg_differences=result['differences_TE']\n    avg_low_score=result['low_score_TE']\n    answer = \"QE\"\n    labels=['[Encode]','Q_token_1','Q_token_2','Q_token_3','Q_token_4','Q_token_5','Q_token_6','Q_token_7','[End]']\n    block_name='text_encoder'\n  elif block_name=='Answer Decoder':\n    avg_differences=result['differences_DE']\n    avg_low_score=result['low_score_DE']\n    answer = \"ANS\"\n    labels=['Decode']\n    block_name='text_decoder'\n\n  with plt.rc_context(rc={\"font.family\": \"Liberation Serif\"}):\n        fig, ax = plt.subplots(figsize=(3.5, 2), dpi=200)\n        h = ax.pcolor(\n            avg_differences,\n            cmap={ \"text_encoder\": \"Purples\",'text_decoder':\"Reds\"}[block_name\n            ],\n            vmin=avg_low_score,\n        )\n        ax.invert_yaxis()\n        ax.set_yticks([0.5 + i for i in range(len(avg_differences))])\n        ax.set_xticks([0.5 + i for i in range(0, avg_differences.shape[1] - 1, 1)])\n        ax.set_xticklabels(list(range(0, avg_differences.shape[1] - 1, 1)))\n        if not modelname:\n            modelname = \"BLIP\"\n        if block_name!=None:\n              ax.set_yticklabels(labels)\n              ax.set_title(f\"Average Impact of restoring {block_name} after corrupted input over {count} samples\")\n            #ax.set_xlabel(f\"center of interval of {window} restored {kindname} layers\")\n        cb = plt.colorbar(h)\n        if title is not None:\n            ax.set_title(title)\n        if xlabel is not None:\n            ax.set_xlabel(xlabel)\n        elif answer is not None:\n            # The following should be cb.ax.set_xlabel, but this is broken in matplotlib 3.5.1.\n            cb.ax.set_title(f\"p({answer})\", y=-0.16, fontsize=10)\n        if savepdf:\n            os.makedirs(os.path.dirname(savepdf), exist_ok=True)\n            plt.savefig(savepdf, bbox_inches=\"tight\")\n            plt.close()\n        else:\n            plt.show()","metadata":{"id":"nwM0kpOBI046","execution":{"iopub.status.busy":"2023-07-06T13:28:05.591023Z","iopub.execute_input":"2023-07-06T13:28:05.591373Z","iopub.status.idle":"2023-07-06T13:28:05.605257Z","shell.execute_reply.started":"2023-07-06T13:28:05.591344Z","shell.execute_reply":"2023-07-06T13:28:05.603850Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"avgnormal_heatmap(result,'Question Encoder','/kaggle/working/Question Encoder_Normalized_causal_trace_200 samples.pdf')","metadata":{"id":"w0ub4Sh2GzET","execution":{"iopub.status.busy":"2023-07-06T13:28:09.491668Z","iopub.execute_input":"2023-07-06T13:28:09.492393Z","iopub.status.idle":"2023-07-06T13:28:10.385591Z","shell.execute_reply.started":"2023-07-06T13:28:09.492359Z","shell.execute_reply":"2023-07-06T13:28:10.384092Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"avgnormal_heatmap(normalized_text_enc,'/kaggle/working/Blip_Normalized_causal_trace_500samples.pdf',xlabel='Layers')","metadata":{"id":"pjhlg3_XG-uc","execution":{"iopub.status.busy":"2023-07-06T13:28:20.842544Z","iopub.execute_input":"2023-07-06T13:28:20.844003Z","iopub.status.idle":"2023-07-06T13:28:21.628576Z","shell.execute_reply.started":"2023-07-06T13:28:20.843962Z","shell.execute_reply":"2023-07-06T13:28:21.627162Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"avg_heatmap(result,'Question Encoder','/kaggle/working/Question Encoder_causal_trace_200 samples.pdf')","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:28:24.891297Z","iopub.execute_input":"2023-07-06T13:28:24.891649Z","iopub.status.idle":"2023-07-06T13:28:25.415003Z","shell.execute_reply.started":"2023-07-06T13:28:24.891619Z","shell.execute_reply":"2023-07-06T13:28:25.413424Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"avg_heatmap(result,'Answer Decoder','/kaggle/working/Answer Decoder_causal_trace_200 samples.pdf')","metadata":{"execution":{"iopub.status.busy":"2023-07-06T13:28:27.673413Z","iopub.execute_input":"2023-07-06T13:28:27.673773Z","iopub.status.idle":"2023-07-06T13:28:28.074613Z","shell.execute_reply.started":"2023-07-06T13:28:27.673736Z","shell.execute_reply":"2023-07-06T13:28:28.073275Z"},"trusted":true},"execution_count":89,"outputs":[]}]}