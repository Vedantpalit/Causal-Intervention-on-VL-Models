{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXtHYmPQgwWp"
      },
      "source": [
        "#Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DOkPIcefzV-T"
      },
      "outputs": [],
      "source": [
        "import contextlib\n",
        "import copy\n",
        "import inspect\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ffzJfBeGzi1u"
      },
      "outputs": [],
      "source": [
        "def get_module(model, name):\n",
        "    \"\"\"\n",
        "    Finds the named module within the given model.\n",
        "    \"\"\"\n",
        "    for n, m in model.named_modules():\n",
        "        if n == name:\n",
        "            return m\n",
        "    raise LookupError(name)\n",
        "\n",
        "def replace_module(model, name, new_module):\n",
        "    \"\"\"\n",
        "    Replaces the named module within the given model.\n",
        "    \"\"\"\n",
        "    if \".\" in name:\n",
        "        parent_name, attr_name = name.rsplit(\".\", 1)\n",
        "        model = get_module(model, parent_name)\n",
        "    # original_module = getattr(model, attr_name)\n",
        "    setattr(model, attr_name, new_module)\n",
        "\n",
        "class StopForward(Exception):\n",
        "    \"\"\"\n",
        "    If the only output needed from running a network is the retained\n",
        "    submodule then Trace(submodule, stop=True) will stop execution\n",
        "    immediately after the retained submodule by raising the StopForward()\n",
        "    exception.  When Trace is used as context manager, it catches that\n",
        "    exception and can be used as follows:\n",
        "\n",
        "    with Trace(net, layername, stop=True) as tr:\n",
        "        net(inp) # Only runs the network up to layername\n",
        "    print(tr.output)\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "def recursive_copy(x, clone=None, detach=None, retain_grad=None):\n",
        "    \"\"\"\n",
        "    Copies a reference to a tensor, or an object that contains tensors,\n",
        "    optionally detaching and cloning the tensor(s).  If retain_grad is\n",
        "    true, the original tensors are marked to have grads retained.\n",
        "    \"\"\"\n",
        "    if not clone and not detach and not retain_grad:\n",
        "        return x\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        if retain_grad:\n",
        "            if not x.requires_grad:\n",
        "                x.requires_grad = True\n",
        "            x.retain_grad()\n",
        "        elif detach:\n",
        "            x = x.detach()\n",
        "        if clone:\n",
        "            x = x.clone()\n",
        "        return x\n",
        "    # Only dicts, lists, and tuples (and subclasses) can be copied.\n",
        "    if isinstance(x, dict):\n",
        "        return type(x)({k: recursive_copy(v) for k, v in x.items()})\n",
        "    elif isinstance(x, (list, tuple)):\n",
        "        return type(x)([recursive_copy(v) for v in x])\n",
        "    else:\n",
        "        assert False, f\"Unknown type {type(x)} cannot be broken into tensors.\"\n",
        "\n",
        "def invoke_with_optional_args(fn, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Invokes a function with only the arguments that it\n",
        "    is written to accept, giving priority to arguments\n",
        "    that match by-name, using the following rules.\n",
        "    (1) arguments with matching names are passed by name.\n",
        "    (2) remaining non-name-matched args are passed by order.\n",
        "    (3) extra caller arguments that the function cannot\n",
        "        accept are not passed.\n",
        "    (4) extra required function arguments that the caller\n",
        "        cannot provide cause a TypeError to be raised.\n",
        "    Ordinary python calling conventions are helpful for\n",
        "    supporting a function that might be revised to accept\n",
        "    extra arguments in a newer version, without requiring the\n",
        "    caller to pass those new arguments.  This function helps\n",
        "    support function callers that might be revised to supply\n",
        "    extra arguments, without requiring the callee to accept\n",
        "    those new arguments.\n",
        "    \"\"\"\n",
        "    argspec = inspect.getfullargspec(fn)\n",
        "    pass_args = []\n",
        "    used_kw = set()\n",
        "    unmatched_pos = []\n",
        "    used_pos = 0\n",
        "    defaulted_pos = len(argspec.args) - (\n",
        "        0 if not argspec.defaults else len(argspec.defaults)\n",
        "    )\n",
        "    # Pass positional args that match name first, then by position.\n",
        "    for i, n in enumerate(argspec.args):\n",
        "        if n in kwargs:\n",
        "            pass_args.append(kwargs[n])\n",
        "            used_kw.add(n)\n",
        "        elif used_pos < len(args):\n",
        "            pass_args.append(args[used_pos])\n",
        "            used_pos += 1\n",
        "        else:\n",
        "            unmatched_pos.append(len(pass_args))\n",
        "            pass_args.append(\n",
        "                None if i < defaulted_pos else argspec.defaults[i - defaulted_pos]\n",
        "            )\n",
        "    # Fill unmatched positional args with unmatched keyword args in order.\n",
        "    if len(unmatched_pos):\n",
        "        for k, v in kwargs.items():\n",
        "            if k in used_kw or k in argspec.kwonlyargs:\n",
        "                continue\n",
        "            pass_args[unmatched_pos[0]] = v\n",
        "            used_kw.add(k)\n",
        "            unmatched_pos = unmatched_pos[1:]\n",
        "            if len(unmatched_pos) == 0:\n",
        "                break\n",
        "        else:\n",
        "            if unmatched_pos[0] < defaulted_pos:\n",
        "                unpassed = \", \".join(\n",
        "                    argspec.args[u] for u in unmatched_pos if u < defaulted_pos\n",
        "                )\n",
        "                raise TypeError(f\"{fn.__name__}() cannot be passed {unpassed}.\")\n",
        "    # Pass remaining kw args if they can be accepted.\n",
        "    pass_kw = {\n",
        "        k: v\n",
        "        for k, v in kwargs.items()\n",
        "        if k not in used_kw and (k in argspec.kwonlyargs or argspec.varargs is not None)\n",
        "    }\n",
        "    # Pass remaining positional args if they can be accepted.\n",
        "    if argspec.varargs is not None:\n",
        "        pass_args += list(args[used_pos:])\n",
        "    return fn(*pass_args, **pass_kw)\n",
        "\n",
        "\n",
        "\n",
        "def set_requires_grad(requires_grad, *models):\n",
        "    \"\"\"\n",
        "    Sets requires_grad true or false for all parameters within the\n",
        "    models passed.\n",
        "    \"\"\"\n",
        "    for model in models:\n",
        "        if isinstance(model, torch.nn.Module):\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = requires_grad\n",
        "        elif isinstance(model, (torch.nn.Parameter, torch.Tensor)):\n",
        "            model.requires_grad = requires_grad\n",
        "        else:\n",
        "            assert False, \"unknown type %r\" % type(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trace(contextlib.AbstractContextManager):\n",
        "    \"\"\"\n",
        "    To retain the output of the named layer during the computation of\n",
        "    the given network:\n",
        "\n",
        "        with Trace(net, 'layer.name') as ret:\n",
        "            _ = net(inp)\n",
        "            representation = ret.output\n",
        "\n",
        "    A layer module can be passed directly without a layer name, and\n",
        "    its output will be retained.  By default, a direct reference to\n",
        "    the output object is returned, but options can control this:\n",
        "\n",
        "        clone=True  - retains a copy of the output, which can be\n",
        "            useful if you want to see the output before it might\n",
        "            be modified by the network in-place later.\n",
        "        detach=True - retains a detached reference or copy.  (By\n",
        "            default the value would be left attached to the graph.)\n",
        "        retain_grad=True - request gradient to be retained on the\n",
        "            output.  After backward(), ret.output.grad is populated.\n",
        "\n",
        "        retain_input=True - also retains the input.\n",
        "        retain_output=False - can disable retaining the output.\n",
        "        edit_output=fn - calls the function to modify the output\n",
        "            of the layer before passing it the rest of the model.\n",
        "            fn can optionally accept (output, layer) arguments\n",
        "            for the original output and the layer name.\n",
        "        stop=True - throws a StopForward exception after the layer\n",
        "            is run, which allows running just a portion of a model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        module,\n",
        "        layer=None,\n",
        "        retain_output=True,\n",
        "        retain_input=False,\n",
        "        clone=False,\n",
        "        detach=False,\n",
        "        retain_grad=False,\n",
        "        edit_output=None,\n",
        "        stop=False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Method to replace a forward method with a closure that\n",
        "        intercepts the call, and tracks the hook so that it can be reverted.\n",
        "        \"\"\"\n",
        "        retainer = self\n",
        "        self.layer = layer\n",
        "        if layer is not None:\n",
        "            module = get_module(module, layer)\n",
        "\n",
        "        def retain_hook(m, inputs, output):\n",
        "            if retain_input:\n",
        "                retainer.input = recursive_copy(\n",
        "                    inputs[0] if len(inputs) == 1 else inputs,\n",
        "                    clone=clone,\n",
        "                    detach=detach,\n",
        "                    retain_grad=False,\n",
        "                )  # retain_grad applies to output only.\n",
        "            if edit_output:\n",
        "                output = invoke_with_optional_args(\n",
        "                    edit_output, output=output, layer=self.layer\n",
        "                )\n",
        "            if retain_output:\n",
        "                retainer.output = recursive_copy(\n",
        "                    output, clone=clone, detach=detach, retain_grad=retain_grad\n",
        "                )\n",
        "                # When retain_grad is set, also insert a trivial\n",
        "                # copy operation.  That allows in-place operations\n",
        "                # to follow without error.\n",
        "                if retain_grad:\n",
        "                    output = recursive_copy(retainer.output, clone=True, detach=False)\n",
        "            if stop:\n",
        "                raise StopForward()\n",
        "            return output\n",
        "\n",
        "        self.registered_hook = module.register_forward_hook(retain_hook)\n",
        "        self.stop = stop\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self.close()\n",
        "        if self.stop and issubclass(type, StopForward):\n",
        "            return True\n",
        "\n",
        "    def close(self):\n",
        "        self.registered_hook.remove()\n",
        "\n"
      ],
      "metadata": {
        "id": "ww9ZayOd9AK3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7p-Ce9Vagu0g"
      },
      "outputs": [],
      "source": [
        "class TraceDict(OrderedDict, contextlib.AbstractContextManager):\n",
        "    \"\"\"\n",
        "    To retain the output of multiple named layers during the computation\n",
        "    of the given network:\n",
        "\n",
        "        with TraceDict(net, ['layer1.name1', 'layer2.name2']) as ret:\n",
        "            _ = net(inp)\n",
        "            representation = ret['layer1.name1'].output\n",
        "\n",
        "    If edit_output is provided, it should be a function that takes\n",
        "    two arguments: output, and the layer name; and then it returns the\n",
        "    modified output.\n",
        "\n",
        "    Other arguments are the same as Trace.  If stop is True, then the\n",
        "    execution of the network will be stopped after the last layer\n",
        "    listed (even if it would not have been the last to be executed).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        layers=None,\n",
        "        retain_output=True,\n",
        "        retain_input=False,\n",
        "        clone=False,\n",
        "        detach=False,\n",
        "        retain_grad=False,\n",
        "        edit_output=None,\n",
        "        stop=False,\n",
        "    ):\n",
        "        self.stop = stop\n",
        "\n",
        "        def flag_last_unseen(it):\n",
        "            try:\n",
        "                it = iter(it)\n",
        "                prev = next(it)\n",
        "                seen = set([prev])\n",
        "            except StopIteration:\n",
        "                return\n",
        "            for item in it:\n",
        "                if item not in seen:\n",
        "                    yield False, prev\n",
        "                    seen.add(item)\n",
        "                    prev = item\n",
        "            yield True, prev\n",
        "\n",
        "        for is_last, layer in flag_last_unseen(layers):\n",
        "            self[layer] = Trace(\n",
        "                module=model,\n",
        "                layer=layer,\n",
        "                retain_output=retain_output,\n",
        "                retain_input=retain_input,\n",
        "                clone=clone,\n",
        "                detach=detach,\n",
        "                retain_grad=retain_grad,\n",
        "                edit_output=edit_output,\n",
        "                stop=stop and is_last,\n",
        "            )\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self.close()\n",
        "        if self.stop and issubclass(type, StopForward):\n",
        "            return True\n",
        "\n",
        "    def close(self):\n",
        "        for layer, trace in reversed(self.items()):\n",
        "            trace.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKrG9--ug0NO"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAWOrNpWb7Fp",
        "outputId": "36e1e2fb-cee7-4909-8727-9215d88925d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/7.2 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.2-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.2 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkl05QQWfvJJ",
        "outputId": "44e23cd1-a447-4d28-a94b-03c1886da32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/802.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji (from stanza)\n",
            "  Downloading emoji-2.6.0.tar.gz (356 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.6/356.6 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.22.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from stanza) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (16.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.6.0-py2.py3-none-any.whl size=351311 sha256=c7ed2c912bfa937c12e31e3f6be7eaed5cc8d2c614c6255c256b93f7c0132d10\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/0b/64/114bc939d0083621aa41521e21be246c888260b8aa21e6c1ad\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-2.6.0 stanza-1.5.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.13.1 dill-0.3.6 multiprocess-0.70.14 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stanza\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r2fGwjUubrdI"
      },
      "outputs": [],
      "source": [
        "import os, re, json\n",
        "import torch, numpy\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import itertools\n",
        "import nltk\n",
        "import random\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "from tqdm.notebook import tqdm\n",
        "import stanza\n",
        "import datasets\n",
        "import scipy\n",
        "import csv\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from typing import Any, Optional, Tuple, Union,OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jXAeGLtebW98"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ee7d14350133412b92fc464b329f9275",
            "f39949aef8104e7dafed796bde527340",
            "ee5986fba3a742f98364f43a32400b0a",
            "abdcbc6a21bb43d28e9443cc74cd7676",
            "d2acc88d963f40789280f701b4550f09",
            "06714d99338646e69e3fdc5c51303c94",
            "423fa9219baf42b1b0e31a32e45b1281",
            "d8aa95b9b75f4bef914a7dbec26c9c36",
            "e1ddad43a3514706b86f159238283d0e",
            "d221549547f040ff88bb0edc706c4a14",
            "ce9182d06a0e47719a7e117786d9a6fb",
            "5c34884da39144f6a854f08d28b23a9f",
            "5edde8fe35ae4429974d07fba4ae1765",
            "f63683e22477407d95a195da783b677a",
            "5a1b7cdf08924d839d9b440470b0780b",
            "e4e498eaf37440f08e8b555e7ef83130",
            "9b7f34d47b2c4967a6a91f421240dab8",
            "8ae8cbdebd884a948b065a7a867369ef",
            "852f8b6a03754f77a870859cf0963b21",
            "ec76613eb2ef42ba8a61ef1ad13550b0",
            "a4e78dbd61614505ab4505cc4341d51f",
            "039c3f7e66c143c2b156bc6c3a982841",
            "e66584cfb582485194e4ed49d7405c09",
            "67c677af122d4c9581602d9d77f0e15d",
            "60b8c7b7d96342118ebe8637b65843ce",
            "a0a1a43774bd4da297431931208364df",
            "ed7d25cde7834863a22b4b0b42037f70",
            "b58ecfb5319d49269e5d0b7dc7d54d81",
            "c7f26d15f15540a9be13573c00b80698",
            "fe56a0ef0700406e9714b3f3e47a866e",
            "095baa47eee747af9941ce5ae7134ae3",
            "ce1214d307004c80a7b885988ae86e91",
            "6f1b1859a5ea4147b40f1eea235711a7",
            "08236d74993343e48d06c38b3dd687c0",
            "9ad59209073847b2858e077658039b6e",
            "5f8648beb3554107b6d02d060d594ec6",
            "b21876a4470145a899fee0d6bc5e2045",
            "d3b073e48e48490788c738b1fd7fec2d",
            "5a5f0fe0b0a44d24a51c96b0e1e855e0",
            "06a724ebe01b4a87a97381ab2a751f3f",
            "1b6d4822552042ccbbbe8a1ba99d1072",
            "5973f9b8f8a04533a1a965c6e4a1d580",
            "31ca8ce9bc554491b329159ad644d2ad",
            "0da61585c01147fdba8634bd03580761",
            "cb6ea4229eac4778b4539a46b01b6c11",
            "3e9290ed921e4586822ed7203b0b4b64",
            "b438cca2e9164a21add660eb7e739c60",
            "8e6f1c7cd33849edb7aba612002761c0",
            "cd6edcee3cb7452c8cac2cff310f9d68",
            "a2522e804b594955ae2f075e829cdf6f",
            "d6ceee2b5f354a7686de8a427508bbdd",
            "f97b24eaa3cd49c09f6ddb2990bd4052",
            "ca408accadb04ec6b9a43b43a9c7cb8d",
            "41c09b0389804c5ebf92eb692d590c14",
            "855f9b54d0a846b6868e6f9023cdb53e",
            "08ab3de0be8641a69f222dbf07dc5981",
            "fc05cbe399eb46c9a8f640141df4bb97",
            "285ba71b925744c2a73a9451f811e45d",
            "6629aa2847c2460baefb3252d94ac867",
            "20e2cd80d37f4720882e2cf4ac931421",
            "652260c874e64865a0117b4d3ef86f75",
            "4983de7a45fd47c7a9f948609c21dfc6",
            "a9a2e0b7320c4250b9566d4f192b93e3",
            "234ee6846c754ea59f4d4a790b226a70",
            "3c5665c488064990ab9abdc3ab3a184c",
            "a9707de4d54948e2998612badf92f8bf",
            "66fc35372b7e4779a1303dd5f0883b99",
            "ce2f6bd9744644af993962ab60bab080",
            "6f8aa8a7243742c8abd96d314955d1cc",
            "94cbfbfc0a4147e2ad42a5af590e119c",
            "d4d541d190c4407bb25a2a1ae1b900f2",
            "ac2e736803104edc9a52a89427f37f08",
            "081d63f8e29448eda0e47308c40b461b",
            "b23c72a38b76458399d055f75c2884a3",
            "ccac5fea901a41b692f694c8063428c1",
            "ad44210478b341b2b98d14525d394b4f",
            "219f039042574af480bedb0a47e2c662"
          ]
        },
        "id": "pGO1D03-b9cs",
        "outputId": "15c19c9e-254c-4178-e66f-f1e1fa8af8db"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee7d14350133412b92fc464b329f9275"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c34884da39144f6a854f08d28b23a9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)rocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e66584cfb582485194e4ed49d7405c09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08236d74993343e48d06c38b3dd687c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb6ea4229eac4778b4539a46b01b6c11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08ab3de0be8641a69f222dbf07dc5981"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66fc35372b7e4779a1303dd5f0883b99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BlipForQuestionAnswering(\n",
              "  (vision_model): BlipVisionModel(\n",
              "    (embeddings): BlipVisionEmbeddings(\n",
              "      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    )\n",
              "    (encoder): BlipEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BlipEncoderLayer(\n",
              "          (self_attn): BlipAttention(\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): BlipMLP(\n",
              "            (activation_fn): GELUActivation()\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (text_encoder): BlipTextModel(\n",
              "    (embeddings): BlipTextEmbeddings(\n",
              "      (word_embeddings): Embedding(30524, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): BlipTextEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BlipTextLayer(\n",
              "          (attention): BlipTextAttention(\n",
              "            (self): BlipTextSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): BlipTextSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BlipTextAttention(\n",
              "            (self): BlipTextSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): BlipTextSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BlipTextIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BlipTextOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (text_decoder): BlipTextLMHeadModel(\n",
              "    (bert): BlipTextModel(\n",
              "      (embeddings): BlipTextEmbeddings(\n",
              "        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (encoder): BlipTextEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-11): 12 x BlipTextLayer(\n",
              "            (attention): BlipTextAttention(\n",
              "              (self): BlipTextSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (output): BlipTextSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BlipTextAttention(\n",
              "              (self): BlipTextSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (output): BlipTextSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BlipTextIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BlipTextOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (cls): BlipTextOnlyMLMHead(\n",
              "      (predictions): BlipTextLMPredictionHead(\n",
              "        (transform): BlipTextPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from transformers import BlipForQuestionAnswering,BlipProcessor\n",
        "model= BlipForQuestionAnswering.from_pretrained('Salesforce/blip-vqa-base')\n",
        "processor=BlipProcessor.from_pretrained('Salesforce/blip-vqa-base')\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zRntPp3PeEKe"
      },
      "outputs": [],
      "source": [
        "model_name='Salesforce/blip-vqa-base'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JFc-lGt3JdDP"
      },
      "outputs": [],
      "source": [
        "class ModelandProcessor:\n",
        "  def __init__(\n",
        "        self,\n",
        "        model_name=None,\n",
        "        model=None,\n",
        "        processor=None,\n",
        "        low_cpu_mem_usage=False,\n",
        "        torch_dtype=None,\n",
        "    ):\n",
        "        if  processor is None:\n",
        "            assert model_name is not None\n",
        "            processor = BlipProcessor.from_pretrained(model_name)\n",
        "        if model is None:\n",
        "            assert model_name is not None\n",
        "            model = BlipForQuestionAnswering.from_pretrained(\n",
        "                model_name, low_cpu_mem_usage=low_cpu_mem_usage, torch_dtype=torch_dtype\n",
        "            )\n",
        "            set_requires_grad(False, model)\n",
        "            model.eval().cuda()\n",
        "        self.processor = processor\n",
        "        self.model = model\n",
        "        self.layer_names = [\n",
        "            n\n",
        "            for n, m in model.named_modules()\n",
        "            if (re.match(r\"^(vision_model|text_encoder|text_decoder.bert|text_decoder.cls)\\.(embeddings|encoder.layers|encoder.layer|predictions)\\.(\\d+$)\", n))\n",
        "        ]\n",
        "        self.num_layers = (len(self.layer_names)//3)\n",
        "\n",
        "  def __repr__(self):\n",
        "        return (\n",
        "            f\"ModelAndTokenizer(model: {type(self.model).__name__} \"\n",
        "            f\"[{self.num_layers} layers], \"\n",
        "            f\"tokenizer: {type(self.tokenizer).__name__})\"\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "G5IWRTJ5gGQk"
      },
      "outputs": [],
      "source": [
        "mt=ModelandProcessor(model_name,model,processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKgHieKjg-Bn",
        "outputId": "b01deeb5-8d23-4cb8-e3ce-e309069dec1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(mt.num_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MyuS_oNSc8Fl"
      },
      "outputs": [],
      "source": [
        "def layername(model, num,block_name, kind=None):\n",
        "  if block_name==\"text_encoder\":\n",
        "    if hasattr(model,\"model_text_enc\"):\n",
        "        if kind == \"embed\":\n",
        "            return \"model_text_enc.embeddings\"\n",
        "        return f'model_text_enc.encoder.layer.{num}{\"\" if kind is None else \".\" + kind}'\n",
        "  elif block_name==\"text_decoder\":\n",
        "    if hasattr(model,\"model_text_dec\"):\n",
        "        if kind == \"embed\":\n",
        "            return f'model_text_dec.bert.embeddings'\n",
        "        elif kind==\"cls.decoder\":\n",
        "            return f'text_decoder.cls.predictions.decoder'\n",
        "        return f'model_text_dec.bert.encoder.layer.{num}{\"\" if kind is None else \".\" + kind}'\n",
        "    assert False, \"unknown transformer structure\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbJsX0AhpZEw"
      },
      "outputs": [],
      "source": [
        "_from transformers import BlipConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ps1tubNklWFe"
      },
      "outputs": [],
      "source": [
        "class ModelOutput(OrderedDict):\n",
        "    \"\"\"\n",
        "    Base class for all model outputs as dataclass. Has a `__getitem__` that allows indexing by integer or slice (like a\n",
        "    tuple) or strings (like a dictionary) that will ignore the `None` attributes. Otherwise behaves like a regular\n",
        "    python dictionary.\n",
        "\n",
        "    <Tip warning={true}>\n",
        "\n",
        "    You can't unpack a `ModelOutput` directly. Use the [`~utils.ModelOutput.to_tuple`] method to convert it to a tuple\n",
        "    before.\n",
        "\n",
        "    </Tip>\n",
        "    \"\"\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        class_fields = fields(self)\n",
        "\n",
        "        # Safety and consistency checks\n",
        "        if not len(class_fields):\n",
        "            raise ValueError(f\"{self.__class__.__name__} has no fields.\")\n",
        "        if not all(field.default is None for field in class_fields[1:]):\n",
        "            raise ValueError(f\"{self.__class__.__name__} should not have more than one required field.\")\n",
        "\n",
        "        first_field = getattr(self, class_fields[0].name)\n",
        "        other_fields_are_none = all(getattr(self, field.name) is None for field in class_fields[1:])\n",
        "\n",
        "        if other_fields_are_none and not is_tensor(first_field):\n",
        "            if isinstance(first_field, dict):\n",
        "                iterator = first_field.items()\n",
        "                first_field_iterator = True\n",
        "            else:\n",
        "                try:\n",
        "                    iterator = iter(first_field)\n",
        "                    first_field_iterator = True\n",
        "                except TypeError:\n",
        "                    first_field_iterator = False\n",
        "\n",
        "            # if we provided an iterator as first field and the iterator is a (key, value) iterator\n",
        "            # set the associated fields\n",
        "            if first_field_iterator:\n",
        "                for idx, element in enumerate(iterator):\n",
        "                    if (\n",
        "                        not isinstance(element, (list, tuple))\n",
        "                        or not len(element) == 2\n",
        "                        or not isinstance(element[0], str)\n",
        "                    ):\n",
        "                        if idx == 0:\n",
        "                            # If we do not have an iterator of key/values, set it as attribute\n",
        "                            self[class_fields[0].name] = first_field\n",
        "                        else:\n",
        "                            # If we have a mixed iterator, raise an error\n",
        "                            raise ValueError(\n",
        "                                f\"Cannot set key/value for {element}. It needs to be a tuple (key, value).\"\n",
        "                            )\n",
        "                        break\n",
        "                    setattr(self, element[0], element[1])\n",
        "                    if element[1] is not None:\n",
        "                        self[element[0]] = element[1]\n",
        "            elif first_field is not None:\n",
        "                self[class_fields[0].name] = first_field\n",
        "        else:\n",
        "            for field in class_fields:\n",
        "                v = getattr(self, field.name)\n",
        "                if v is not None:\n",
        "                    self[field.name] = v\n",
        "\n",
        "    def __delitem__(self, *args, **kwargs):\n",
        "        raise Exception(f\"You cannot use ``__delitem__`` on a {self.__class__.__name__} instance.\")\n",
        "\n",
        "    def setdefault(self, *args, **kwargs):\n",
        "        raise Exception(f\"You cannot use ``setdefault`` on a {self.__class__.__name__} instance.\")\n",
        "\n",
        "    def pop(self, *args, **kwargs):\n",
        "        raise Exception(f\"You cannot use ``pop`` on a {self.__class__.__name__} instance.\")\n",
        "\n",
        "    def update(self, *args, **kwargs):\n",
        "        raise Exception(f\"You cannot use ``update`` on a {self.__class__.__name__} instance.\")\n",
        "\n",
        "    def __getitem__(self, k):\n",
        "        if isinstance(k, str):\n",
        "            inner_dict = dict(self.items())\n",
        "            return inner_dict[k]\n",
        "        else:\n",
        "            return self.to_tuple()[k]\n",
        "\n",
        "    def __setattr__(self, name, value):\n",
        "        if name in self.keys() and value is not None:\n",
        "            # Don't call self.__setitem__ to avoid recursion errors\n",
        "            super().__setitem__(name, value)\n",
        "        super().__setattr__(name, value)\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        # Will raise a KeyException if needed\n",
        "        super().__setitem__(key, value)\n",
        "        # Don't call self.__setattr__ to avoid recursion errors\n",
        "        super().__setattr__(key, value)\n",
        "\n",
        "    def to_tuple(self) -> Tuple[Any]:\n",
        "        \"\"\"\n",
        "        Convert self to a tuple containing all the attributes/keys that are not `None`.\n",
        "        \"\"\"\n",
        "        return tuple(self[k] for k in self.keys())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BlipVQAOutput(ModelOutput):\n",
        "    \"\"\"\n",
        "    Adapted from the base class for vision model's outputs that also contains image embeddings of the pooling of the\n",
        "    last hidden states. This class also adds the loss term from the text decoder.\n",
        "\n",
        "    Args:\n",
        "        loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided):\n",
        "            Languge modeling loss from the text decoder.\n",
        "        image_embeds (`torch.FloatTensor` of shape `(batch_size, output_dim)` *optional* returned when model is initialized with `with_projection=True`):\n",
        "            The image embeddings obtained by applying the projection layer to the pooler_output.\n",
        "        last_hidden_state (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):\n",
        "            Sequence of hidden-states at the output of the last layer of the model.\n",
        "        hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n",
        "            Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
        "            one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
        "\n",
        "            Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n",
        "        attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n",
        "            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
        "            sequence_length)`.\n",
        "\n",
        "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
        "            heads.\n",
        "    \"\"\"\n",
        "    decoder_logits:Optional[Tuple[torch.FloatTensor]] = None\n",
        "    image_embeds: Optional[torch.FloatTensor] = None\n",
        "    vision_last_hidden_state: torch.FloatTensor=None\n",
        "    encoder_last_hidden_state: torch.FloatTensor = None\n",
        "    encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
        "    decoder_last_hidden_state: torch.FloatTensor = None\n",
        "    decoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q9Myryuw9nJi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class customblip_temp(torch.nn.Module):\n",
        "  def __init__(self,model):\n",
        "        super(customblip_temp, self).__init__()\n",
        "        self.model_vis = model.vision_model\n",
        "        self.model_text_enc = model.text_encoder\n",
        "        self.model_text_dec = model.text_decoder\n",
        "        self.decoder_pad_token_id = model.decoder_pad_token_id\n",
        "        self.decoder_start_token_id = model.decoder_start_token_id\n",
        "        self.eos_token_id=model.config.text_config.sep_token_id,\n",
        "        self.pad_token_id=model.config.text_config.pad_token_id\n",
        "        self.output_attentions=model.config.output_attentions\n",
        "        self.use_return_dict=model.config.use_return_dict\n",
        "        self.output_hidden_states=model.config.output_hidden_states\n",
        "\n",
        "  def image_embed(\n",
        "      self,\n",
        "        list_pixel_values: torch.FloatTensor,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "    ):\n",
        "    image_embeds_tensor=torch.zeros(size=(len(list_pixel_values),577,768))\n",
        "    for i in range(len(list_pixel_values)):\n",
        "      vision_outputs = self.model_vis(\n",
        "              pixel_values=list_pixel_values[i],\n",
        "              output_attentions=output_attentions,\n",
        "              output_hidden_states=output_hidden_states,\n",
        "          )\n",
        "      image_embeds = vision_outputs[0]\n",
        "      image_embeds_tensor[i,:,:]=image_embeds[0]\n",
        "\n",
        "    return image_embeds_tensor\n",
        "  def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        image_embeds: Optional[torch.FloatTensor]=None,\n",
        "        attention_mask: Optional[torch.LongTensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, BlipVQAOutput]:\n",
        "\n",
        "        return_dict = return_dict if return_dict is not None else self.use_return_dict\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.output_hidden_states\n",
        "        )\n",
        "\n",
        "        if image_embeds!=None:\n",
        "          image_embeds=image_embeds.to(device)\n",
        "          image_embeds_w=image_embeds\n",
        "          image_attention_mask = torch.ones(image_embeds_w.size()[:-1], dtype=torch.long)\n",
        "\n",
        "        input_ids=input_ids.to(device)\n",
        "        question_embeds = self.model_text_enc(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            encoder_hidden_states=image_embeds_w,\n",
        "            encoder_attention_mask=image_attention_mask,\n",
        "            output_hidden_states=True,\n",
        "        )\n",
        "\n",
        "        question_embeds_w = question_embeds[0] if not return_dict else question_embeds.last_hidden_state\n",
        "\n",
        "        bos_ids = torch.full(\n",
        "            (question_embeds_w.size(0), 1), fill_value=self.decoder_start_token_id, device=(device)\n",
        "        )\n",
        "\n",
        "        answer_output = self.model_text_dec(\n",
        "            input_ids=bos_ids,\n",
        "            encoder_hidden_states=question_embeds_w,\n",
        "            encoder_attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "            reduction=\"mean\"\n",
        "        )\n",
        "\n",
        "\n",
        "        return BlipVQAOutput(\n",
        "            decoder_logits=answer_output.logits,\n",
        "            image_embeds=image_embeds_w,\n",
        "            encoder_last_hidden_state=question_embeds.last_hidden_state,\n",
        "            encoder_hidden_states=question_embeds.hidden_states,\n",
        "            decoder_hidden_states=answer_output.hidden_states,\n",
        "        )"
      ],
      "metadata": {
        "id": "8y9ImDlj8st_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RLBBM7Rcj5lb"
      },
      "outputs": [],
      "source": [
        "new_model=customblip_temp(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPa5RXThyEuR",
        "outputId": "28961fac-0abc-418d-8013-be344ddcf50f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customblip_temp(\n",
              "  (model_vis): BlipVisionModel(\n",
              "    (embeddings): BlipVisionEmbeddings(\n",
              "      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    )\n",
              "    (encoder): BlipEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BlipEncoderLayer(\n",
              "          (self_attn): BlipAttention(\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): BlipMLP(\n",
              "            (activation_fn): GELUActivation()\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (model_text_enc): BlipTextModel(\n",
              "    (embeddings): BlipTextEmbeddings(\n",
              "      (word_embeddings): Embedding(30524, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): BlipTextEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BlipTextLayer(\n",
              "          (attention): BlipTextAttention(\n",
              "            (self): BlipTextSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): BlipTextSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BlipTextAttention(\n",
              "            (self): BlipTextSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): BlipTextSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BlipTextIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BlipTextOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (model_text_dec): BlipTextLMHeadModel(\n",
              "    (bert): BlipTextModel(\n",
              "      (embeddings): BlipTextEmbeddings(\n",
              "        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (encoder): BlipTextEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-11): 12 x BlipTextLayer(\n",
              "            (attention): BlipTextAttention(\n",
              "              (self): BlipTextSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (output): BlipTextSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BlipTextAttention(\n",
              "              (self): BlipTextSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (output): BlipTextSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BlipTextIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BlipTextOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (cls): BlipTextOnlyMLMHead(\n",
              "      (predictions): BlipTextLMPredictionHead(\n",
              "        (transform): BlipTextPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n,m in new_model.named_modules():\n",
        "  print(n)"
      ],
      "metadata": {
        "id": "TV3RKLvd1SN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8678e054-e541-44e5-f41f-14d26cae687f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "model_vis\n",
            "model_vis.embeddings\n",
            "model_vis.embeddings.patch_embedding\n",
            "model_vis.encoder\n",
            "model_vis.encoder.layers\n",
            "model_vis.encoder.layers.0\n",
            "model_vis.encoder.layers.0.self_attn\n",
            "model_vis.encoder.layers.0.self_attn.dropout\n",
            "model_vis.encoder.layers.0.self_attn.qkv\n",
            "model_vis.encoder.layers.0.self_attn.projection\n",
            "model_vis.encoder.layers.0.layer_norm1\n",
            "model_vis.encoder.layers.0.mlp\n",
            "model_vis.encoder.layers.0.mlp.activation_fn\n",
            "model_vis.encoder.layers.0.mlp.fc1\n",
            "model_vis.encoder.layers.0.mlp.fc2\n",
            "model_vis.encoder.layers.0.layer_norm2\n",
            "model_vis.encoder.layers.1\n",
            "model_vis.encoder.layers.1.self_attn\n",
            "model_vis.encoder.layers.1.self_attn.dropout\n",
            "model_vis.encoder.layers.1.self_attn.qkv\n",
            "model_vis.encoder.layers.1.self_attn.projection\n",
            "model_vis.encoder.layers.1.layer_norm1\n",
            "model_vis.encoder.layers.1.mlp\n",
            "model_vis.encoder.layers.1.mlp.activation_fn\n",
            "model_vis.encoder.layers.1.mlp.fc1\n",
            "model_vis.encoder.layers.1.mlp.fc2\n",
            "model_vis.encoder.layers.1.layer_norm2\n",
            "model_vis.encoder.layers.2\n",
            "model_vis.encoder.layers.2.self_attn\n",
            "model_vis.encoder.layers.2.self_attn.dropout\n",
            "model_vis.encoder.layers.2.self_attn.qkv\n",
            "model_vis.encoder.layers.2.self_attn.projection\n",
            "model_vis.encoder.layers.2.layer_norm1\n",
            "model_vis.encoder.layers.2.mlp\n",
            "model_vis.encoder.layers.2.mlp.activation_fn\n",
            "model_vis.encoder.layers.2.mlp.fc1\n",
            "model_vis.encoder.layers.2.mlp.fc2\n",
            "model_vis.encoder.layers.2.layer_norm2\n",
            "model_vis.encoder.layers.3\n",
            "model_vis.encoder.layers.3.self_attn\n",
            "model_vis.encoder.layers.3.self_attn.dropout\n",
            "model_vis.encoder.layers.3.self_attn.qkv\n",
            "model_vis.encoder.layers.3.self_attn.projection\n",
            "model_vis.encoder.layers.3.layer_norm1\n",
            "model_vis.encoder.layers.3.mlp\n",
            "model_vis.encoder.layers.3.mlp.activation_fn\n",
            "model_vis.encoder.layers.3.mlp.fc1\n",
            "model_vis.encoder.layers.3.mlp.fc2\n",
            "model_vis.encoder.layers.3.layer_norm2\n",
            "model_vis.encoder.layers.4\n",
            "model_vis.encoder.layers.4.self_attn\n",
            "model_vis.encoder.layers.4.self_attn.dropout\n",
            "model_vis.encoder.layers.4.self_attn.qkv\n",
            "model_vis.encoder.layers.4.self_attn.projection\n",
            "model_vis.encoder.layers.4.layer_norm1\n",
            "model_vis.encoder.layers.4.mlp\n",
            "model_vis.encoder.layers.4.mlp.activation_fn\n",
            "model_vis.encoder.layers.4.mlp.fc1\n",
            "model_vis.encoder.layers.4.mlp.fc2\n",
            "model_vis.encoder.layers.4.layer_norm2\n",
            "model_vis.encoder.layers.5\n",
            "model_vis.encoder.layers.5.self_attn\n",
            "model_vis.encoder.layers.5.self_attn.dropout\n",
            "model_vis.encoder.layers.5.self_attn.qkv\n",
            "model_vis.encoder.layers.5.self_attn.projection\n",
            "model_vis.encoder.layers.5.layer_norm1\n",
            "model_vis.encoder.layers.5.mlp\n",
            "model_vis.encoder.layers.5.mlp.activation_fn\n",
            "model_vis.encoder.layers.5.mlp.fc1\n",
            "model_vis.encoder.layers.5.mlp.fc2\n",
            "model_vis.encoder.layers.5.layer_norm2\n",
            "model_vis.encoder.layers.6\n",
            "model_vis.encoder.layers.6.self_attn\n",
            "model_vis.encoder.layers.6.self_attn.dropout\n",
            "model_vis.encoder.layers.6.self_attn.qkv\n",
            "model_vis.encoder.layers.6.self_attn.projection\n",
            "model_vis.encoder.layers.6.layer_norm1\n",
            "model_vis.encoder.layers.6.mlp\n",
            "model_vis.encoder.layers.6.mlp.activation_fn\n",
            "model_vis.encoder.layers.6.mlp.fc1\n",
            "model_vis.encoder.layers.6.mlp.fc2\n",
            "model_vis.encoder.layers.6.layer_norm2\n",
            "model_vis.encoder.layers.7\n",
            "model_vis.encoder.layers.7.self_attn\n",
            "model_vis.encoder.layers.7.self_attn.dropout\n",
            "model_vis.encoder.layers.7.self_attn.qkv\n",
            "model_vis.encoder.layers.7.self_attn.projection\n",
            "model_vis.encoder.layers.7.layer_norm1\n",
            "model_vis.encoder.layers.7.mlp\n",
            "model_vis.encoder.layers.7.mlp.activation_fn\n",
            "model_vis.encoder.layers.7.mlp.fc1\n",
            "model_vis.encoder.layers.7.mlp.fc2\n",
            "model_vis.encoder.layers.7.layer_norm2\n",
            "model_vis.encoder.layers.8\n",
            "model_vis.encoder.layers.8.self_attn\n",
            "model_vis.encoder.layers.8.self_attn.dropout\n",
            "model_vis.encoder.layers.8.self_attn.qkv\n",
            "model_vis.encoder.layers.8.self_attn.projection\n",
            "model_vis.encoder.layers.8.layer_norm1\n",
            "model_vis.encoder.layers.8.mlp\n",
            "model_vis.encoder.layers.8.mlp.activation_fn\n",
            "model_vis.encoder.layers.8.mlp.fc1\n",
            "model_vis.encoder.layers.8.mlp.fc2\n",
            "model_vis.encoder.layers.8.layer_norm2\n",
            "model_vis.encoder.layers.9\n",
            "model_vis.encoder.layers.9.self_attn\n",
            "model_vis.encoder.layers.9.self_attn.dropout\n",
            "model_vis.encoder.layers.9.self_attn.qkv\n",
            "model_vis.encoder.layers.9.self_attn.projection\n",
            "model_vis.encoder.layers.9.layer_norm1\n",
            "model_vis.encoder.layers.9.mlp\n",
            "model_vis.encoder.layers.9.mlp.activation_fn\n",
            "model_vis.encoder.layers.9.mlp.fc1\n",
            "model_vis.encoder.layers.9.mlp.fc2\n",
            "model_vis.encoder.layers.9.layer_norm2\n",
            "model_vis.encoder.layers.10\n",
            "model_vis.encoder.layers.10.self_attn\n",
            "model_vis.encoder.layers.10.self_attn.dropout\n",
            "model_vis.encoder.layers.10.self_attn.qkv\n",
            "model_vis.encoder.layers.10.self_attn.projection\n",
            "model_vis.encoder.layers.10.layer_norm1\n",
            "model_vis.encoder.layers.10.mlp\n",
            "model_vis.encoder.layers.10.mlp.activation_fn\n",
            "model_vis.encoder.layers.10.mlp.fc1\n",
            "model_vis.encoder.layers.10.mlp.fc2\n",
            "model_vis.encoder.layers.10.layer_norm2\n",
            "model_vis.encoder.layers.11\n",
            "model_vis.encoder.layers.11.self_attn\n",
            "model_vis.encoder.layers.11.self_attn.dropout\n",
            "model_vis.encoder.layers.11.self_attn.qkv\n",
            "model_vis.encoder.layers.11.self_attn.projection\n",
            "model_vis.encoder.layers.11.layer_norm1\n",
            "model_vis.encoder.layers.11.mlp\n",
            "model_vis.encoder.layers.11.mlp.activation_fn\n",
            "model_vis.encoder.layers.11.mlp.fc1\n",
            "model_vis.encoder.layers.11.mlp.fc2\n",
            "model_vis.encoder.layers.11.layer_norm2\n",
            "model_vis.post_layernorm\n",
            "model_text_enc\n",
            "model_text_enc.embeddings\n",
            "model_text_enc.embeddings.word_embeddings\n",
            "model_text_enc.embeddings.position_embeddings\n",
            "model_text_enc.embeddings.LayerNorm\n",
            "model_text_enc.embeddings.dropout\n",
            "model_text_enc.encoder\n",
            "model_text_enc.encoder.layer\n",
            "model_text_enc.encoder.layer.0\n",
            "model_text_enc.encoder.layer.0.attention\n",
            "model_text_enc.encoder.layer.0.attention.self\n",
            "model_text_enc.encoder.layer.0.attention.self.query\n",
            "model_text_enc.encoder.layer.0.attention.self.key\n",
            "model_text_enc.encoder.layer.0.attention.self.value\n",
            "model_text_enc.encoder.layer.0.attention.self.dropout\n",
            "model_text_enc.encoder.layer.0.attention.output\n",
            "model_text_enc.encoder.layer.0.attention.output.dense\n",
            "model_text_enc.encoder.layer.0.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.0.attention.output.dropout\n",
            "model_text_enc.encoder.layer.0.crossattention\n",
            "model_text_enc.encoder.layer.0.crossattention.self\n",
            "model_text_enc.encoder.layer.0.crossattention.self.query\n",
            "model_text_enc.encoder.layer.0.crossattention.self.key\n",
            "model_text_enc.encoder.layer.0.crossattention.self.value\n",
            "model_text_enc.encoder.layer.0.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.0.crossattention.output\n",
            "model_text_enc.encoder.layer.0.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.0.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.0.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.0.intermediate\n",
            "model_text_enc.encoder.layer.0.intermediate.dense\n",
            "model_text_enc.encoder.layer.0.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.0.output\n",
            "model_text_enc.encoder.layer.0.output.dense\n",
            "model_text_enc.encoder.layer.0.output.LayerNorm\n",
            "model_text_enc.encoder.layer.0.output.dropout\n",
            "model_text_enc.encoder.layer.1\n",
            "model_text_enc.encoder.layer.1.attention\n",
            "model_text_enc.encoder.layer.1.attention.self\n",
            "model_text_enc.encoder.layer.1.attention.self.query\n",
            "model_text_enc.encoder.layer.1.attention.self.key\n",
            "model_text_enc.encoder.layer.1.attention.self.value\n",
            "model_text_enc.encoder.layer.1.attention.self.dropout\n",
            "model_text_enc.encoder.layer.1.attention.output\n",
            "model_text_enc.encoder.layer.1.attention.output.dense\n",
            "model_text_enc.encoder.layer.1.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.1.attention.output.dropout\n",
            "model_text_enc.encoder.layer.1.crossattention\n",
            "model_text_enc.encoder.layer.1.crossattention.self\n",
            "model_text_enc.encoder.layer.1.crossattention.self.query\n",
            "model_text_enc.encoder.layer.1.crossattention.self.key\n",
            "model_text_enc.encoder.layer.1.crossattention.self.value\n",
            "model_text_enc.encoder.layer.1.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.1.crossattention.output\n",
            "model_text_enc.encoder.layer.1.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.1.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.1.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.1.intermediate\n",
            "model_text_enc.encoder.layer.1.intermediate.dense\n",
            "model_text_enc.encoder.layer.1.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.1.output\n",
            "model_text_enc.encoder.layer.1.output.dense\n",
            "model_text_enc.encoder.layer.1.output.LayerNorm\n",
            "model_text_enc.encoder.layer.1.output.dropout\n",
            "model_text_enc.encoder.layer.2\n",
            "model_text_enc.encoder.layer.2.attention\n",
            "model_text_enc.encoder.layer.2.attention.self\n",
            "model_text_enc.encoder.layer.2.attention.self.query\n",
            "model_text_enc.encoder.layer.2.attention.self.key\n",
            "model_text_enc.encoder.layer.2.attention.self.value\n",
            "model_text_enc.encoder.layer.2.attention.self.dropout\n",
            "model_text_enc.encoder.layer.2.attention.output\n",
            "model_text_enc.encoder.layer.2.attention.output.dense\n",
            "model_text_enc.encoder.layer.2.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.2.attention.output.dropout\n",
            "model_text_enc.encoder.layer.2.crossattention\n",
            "model_text_enc.encoder.layer.2.crossattention.self\n",
            "model_text_enc.encoder.layer.2.crossattention.self.query\n",
            "model_text_enc.encoder.layer.2.crossattention.self.key\n",
            "model_text_enc.encoder.layer.2.crossattention.self.value\n",
            "model_text_enc.encoder.layer.2.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.2.crossattention.output\n",
            "model_text_enc.encoder.layer.2.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.2.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.2.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.2.intermediate\n",
            "model_text_enc.encoder.layer.2.intermediate.dense\n",
            "model_text_enc.encoder.layer.2.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.2.output\n",
            "model_text_enc.encoder.layer.2.output.dense\n",
            "model_text_enc.encoder.layer.2.output.LayerNorm\n",
            "model_text_enc.encoder.layer.2.output.dropout\n",
            "model_text_enc.encoder.layer.3\n",
            "model_text_enc.encoder.layer.3.attention\n",
            "model_text_enc.encoder.layer.3.attention.self\n",
            "model_text_enc.encoder.layer.3.attention.self.query\n",
            "model_text_enc.encoder.layer.3.attention.self.key\n",
            "model_text_enc.encoder.layer.3.attention.self.value\n",
            "model_text_enc.encoder.layer.3.attention.self.dropout\n",
            "model_text_enc.encoder.layer.3.attention.output\n",
            "model_text_enc.encoder.layer.3.attention.output.dense\n",
            "model_text_enc.encoder.layer.3.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.3.attention.output.dropout\n",
            "model_text_enc.encoder.layer.3.crossattention\n",
            "model_text_enc.encoder.layer.3.crossattention.self\n",
            "model_text_enc.encoder.layer.3.crossattention.self.query\n",
            "model_text_enc.encoder.layer.3.crossattention.self.key\n",
            "model_text_enc.encoder.layer.3.crossattention.self.value\n",
            "model_text_enc.encoder.layer.3.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.3.crossattention.output\n",
            "model_text_enc.encoder.layer.3.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.3.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.3.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.3.intermediate\n",
            "model_text_enc.encoder.layer.3.intermediate.dense\n",
            "model_text_enc.encoder.layer.3.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.3.output\n",
            "model_text_enc.encoder.layer.3.output.dense\n",
            "model_text_enc.encoder.layer.3.output.LayerNorm\n",
            "model_text_enc.encoder.layer.3.output.dropout\n",
            "model_text_enc.encoder.layer.4\n",
            "model_text_enc.encoder.layer.4.attention\n",
            "model_text_enc.encoder.layer.4.attention.self\n",
            "model_text_enc.encoder.layer.4.attention.self.query\n",
            "model_text_enc.encoder.layer.4.attention.self.key\n",
            "model_text_enc.encoder.layer.4.attention.self.value\n",
            "model_text_enc.encoder.layer.4.attention.self.dropout\n",
            "model_text_enc.encoder.layer.4.attention.output\n",
            "model_text_enc.encoder.layer.4.attention.output.dense\n",
            "model_text_enc.encoder.layer.4.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.4.attention.output.dropout\n",
            "model_text_enc.encoder.layer.4.crossattention\n",
            "model_text_enc.encoder.layer.4.crossattention.self\n",
            "model_text_enc.encoder.layer.4.crossattention.self.query\n",
            "model_text_enc.encoder.layer.4.crossattention.self.key\n",
            "model_text_enc.encoder.layer.4.crossattention.self.value\n",
            "model_text_enc.encoder.layer.4.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.4.crossattention.output\n",
            "model_text_enc.encoder.layer.4.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.4.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.4.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.4.intermediate\n",
            "model_text_enc.encoder.layer.4.intermediate.dense\n",
            "model_text_enc.encoder.layer.4.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.4.output\n",
            "model_text_enc.encoder.layer.4.output.dense\n",
            "model_text_enc.encoder.layer.4.output.LayerNorm\n",
            "model_text_enc.encoder.layer.4.output.dropout\n",
            "model_text_enc.encoder.layer.5\n",
            "model_text_enc.encoder.layer.5.attention\n",
            "model_text_enc.encoder.layer.5.attention.self\n",
            "model_text_enc.encoder.layer.5.attention.self.query\n",
            "model_text_enc.encoder.layer.5.attention.self.key\n",
            "model_text_enc.encoder.layer.5.attention.self.value\n",
            "model_text_enc.encoder.layer.5.attention.self.dropout\n",
            "model_text_enc.encoder.layer.5.attention.output\n",
            "model_text_enc.encoder.layer.5.attention.output.dense\n",
            "model_text_enc.encoder.layer.5.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.5.attention.output.dropout\n",
            "model_text_enc.encoder.layer.5.crossattention\n",
            "model_text_enc.encoder.layer.5.crossattention.self\n",
            "model_text_enc.encoder.layer.5.crossattention.self.query\n",
            "model_text_enc.encoder.layer.5.crossattention.self.key\n",
            "model_text_enc.encoder.layer.5.crossattention.self.value\n",
            "model_text_enc.encoder.layer.5.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.5.crossattention.output\n",
            "model_text_enc.encoder.layer.5.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.5.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.5.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.5.intermediate\n",
            "model_text_enc.encoder.layer.5.intermediate.dense\n",
            "model_text_enc.encoder.layer.5.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.5.output\n",
            "model_text_enc.encoder.layer.5.output.dense\n",
            "model_text_enc.encoder.layer.5.output.LayerNorm\n",
            "model_text_enc.encoder.layer.5.output.dropout\n",
            "model_text_enc.encoder.layer.6\n",
            "model_text_enc.encoder.layer.6.attention\n",
            "model_text_enc.encoder.layer.6.attention.self\n",
            "model_text_enc.encoder.layer.6.attention.self.query\n",
            "model_text_enc.encoder.layer.6.attention.self.key\n",
            "model_text_enc.encoder.layer.6.attention.self.value\n",
            "model_text_enc.encoder.layer.6.attention.self.dropout\n",
            "model_text_enc.encoder.layer.6.attention.output\n",
            "model_text_enc.encoder.layer.6.attention.output.dense\n",
            "model_text_enc.encoder.layer.6.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.6.attention.output.dropout\n",
            "model_text_enc.encoder.layer.6.crossattention\n",
            "model_text_enc.encoder.layer.6.crossattention.self\n",
            "model_text_enc.encoder.layer.6.crossattention.self.query\n",
            "model_text_enc.encoder.layer.6.crossattention.self.key\n",
            "model_text_enc.encoder.layer.6.crossattention.self.value\n",
            "model_text_enc.encoder.layer.6.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.6.crossattention.output\n",
            "model_text_enc.encoder.layer.6.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.6.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.6.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.6.intermediate\n",
            "model_text_enc.encoder.layer.6.intermediate.dense\n",
            "model_text_enc.encoder.layer.6.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.6.output\n",
            "model_text_enc.encoder.layer.6.output.dense\n",
            "model_text_enc.encoder.layer.6.output.LayerNorm\n",
            "model_text_enc.encoder.layer.6.output.dropout\n",
            "model_text_enc.encoder.layer.7\n",
            "model_text_enc.encoder.layer.7.attention\n",
            "model_text_enc.encoder.layer.7.attention.self\n",
            "model_text_enc.encoder.layer.7.attention.self.query\n",
            "model_text_enc.encoder.layer.7.attention.self.key\n",
            "model_text_enc.encoder.layer.7.attention.self.value\n",
            "model_text_enc.encoder.layer.7.attention.self.dropout\n",
            "model_text_enc.encoder.layer.7.attention.output\n",
            "model_text_enc.encoder.layer.7.attention.output.dense\n",
            "model_text_enc.encoder.layer.7.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.7.attention.output.dropout\n",
            "model_text_enc.encoder.layer.7.crossattention\n",
            "model_text_enc.encoder.layer.7.crossattention.self\n",
            "model_text_enc.encoder.layer.7.crossattention.self.query\n",
            "model_text_enc.encoder.layer.7.crossattention.self.key\n",
            "model_text_enc.encoder.layer.7.crossattention.self.value\n",
            "model_text_enc.encoder.layer.7.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.7.crossattention.output\n",
            "model_text_enc.encoder.layer.7.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.7.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.7.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.7.intermediate\n",
            "model_text_enc.encoder.layer.7.intermediate.dense\n",
            "model_text_enc.encoder.layer.7.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.7.output\n",
            "model_text_enc.encoder.layer.7.output.dense\n",
            "model_text_enc.encoder.layer.7.output.LayerNorm\n",
            "model_text_enc.encoder.layer.7.output.dropout\n",
            "model_text_enc.encoder.layer.8\n",
            "model_text_enc.encoder.layer.8.attention\n",
            "model_text_enc.encoder.layer.8.attention.self\n",
            "model_text_enc.encoder.layer.8.attention.self.query\n",
            "model_text_enc.encoder.layer.8.attention.self.key\n",
            "model_text_enc.encoder.layer.8.attention.self.value\n",
            "model_text_enc.encoder.layer.8.attention.self.dropout\n",
            "model_text_enc.encoder.layer.8.attention.output\n",
            "model_text_enc.encoder.layer.8.attention.output.dense\n",
            "model_text_enc.encoder.layer.8.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.8.attention.output.dropout\n",
            "model_text_enc.encoder.layer.8.crossattention\n",
            "model_text_enc.encoder.layer.8.crossattention.self\n",
            "model_text_enc.encoder.layer.8.crossattention.self.query\n",
            "model_text_enc.encoder.layer.8.crossattention.self.key\n",
            "model_text_enc.encoder.layer.8.crossattention.self.value\n",
            "model_text_enc.encoder.layer.8.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.8.crossattention.output\n",
            "model_text_enc.encoder.layer.8.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.8.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.8.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.8.intermediate\n",
            "model_text_enc.encoder.layer.8.intermediate.dense\n",
            "model_text_enc.encoder.layer.8.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.8.output\n",
            "model_text_enc.encoder.layer.8.output.dense\n",
            "model_text_enc.encoder.layer.8.output.LayerNorm\n",
            "model_text_enc.encoder.layer.8.output.dropout\n",
            "model_text_enc.encoder.layer.9\n",
            "model_text_enc.encoder.layer.9.attention\n",
            "model_text_enc.encoder.layer.9.attention.self\n",
            "model_text_enc.encoder.layer.9.attention.self.query\n",
            "model_text_enc.encoder.layer.9.attention.self.key\n",
            "model_text_enc.encoder.layer.9.attention.self.value\n",
            "model_text_enc.encoder.layer.9.attention.self.dropout\n",
            "model_text_enc.encoder.layer.9.attention.output\n",
            "model_text_enc.encoder.layer.9.attention.output.dense\n",
            "model_text_enc.encoder.layer.9.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.9.attention.output.dropout\n",
            "model_text_enc.encoder.layer.9.crossattention\n",
            "model_text_enc.encoder.layer.9.crossattention.self\n",
            "model_text_enc.encoder.layer.9.crossattention.self.query\n",
            "model_text_enc.encoder.layer.9.crossattention.self.key\n",
            "model_text_enc.encoder.layer.9.crossattention.self.value\n",
            "model_text_enc.encoder.layer.9.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.9.crossattention.output\n",
            "model_text_enc.encoder.layer.9.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.9.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.9.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.9.intermediate\n",
            "model_text_enc.encoder.layer.9.intermediate.dense\n",
            "model_text_enc.encoder.layer.9.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.9.output\n",
            "model_text_enc.encoder.layer.9.output.dense\n",
            "model_text_enc.encoder.layer.9.output.LayerNorm\n",
            "model_text_enc.encoder.layer.9.output.dropout\n",
            "model_text_enc.encoder.layer.10\n",
            "model_text_enc.encoder.layer.10.attention\n",
            "model_text_enc.encoder.layer.10.attention.self\n",
            "model_text_enc.encoder.layer.10.attention.self.query\n",
            "model_text_enc.encoder.layer.10.attention.self.key\n",
            "model_text_enc.encoder.layer.10.attention.self.value\n",
            "model_text_enc.encoder.layer.10.attention.self.dropout\n",
            "model_text_enc.encoder.layer.10.attention.output\n",
            "model_text_enc.encoder.layer.10.attention.output.dense\n",
            "model_text_enc.encoder.layer.10.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.10.attention.output.dropout\n",
            "model_text_enc.encoder.layer.10.crossattention\n",
            "model_text_enc.encoder.layer.10.crossattention.self\n",
            "model_text_enc.encoder.layer.10.crossattention.self.query\n",
            "model_text_enc.encoder.layer.10.crossattention.self.key\n",
            "model_text_enc.encoder.layer.10.crossattention.self.value\n",
            "model_text_enc.encoder.layer.10.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.10.crossattention.output\n",
            "model_text_enc.encoder.layer.10.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.10.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.10.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.10.intermediate\n",
            "model_text_enc.encoder.layer.10.intermediate.dense\n",
            "model_text_enc.encoder.layer.10.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.10.output\n",
            "model_text_enc.encoder.layer.10.output.dense\n",
            "model_text_enc.encoder.layer.10.output.LayerNorm\n",
            "model_text_enc.encoder.layer.10.output.dropout\n",
            "model_text_enc.encoder.layer.11\n",
            "model_text_enc.encoder.layer.11.attention\n",
            "model_text_enc.encoder.layer.11.attention.self\n",
            "model_text_enc.encoder.layer.11.attention.self.query\n",
            "model_text_enc.encoder.layer.11.attention.self.key\n",
            "model_text_enc.encoder.layer.11.attention.self.value\n",
            "model_text_enc.encoder.layer.11.attention.self.dropout\n",
            "model_text_enc.encoder.layer.11.attention.output\n",
            "model_text_enc.encoder.layer.11.attention.output.dense\n",
            "model_text_enc.encoder.layer.11.attention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.11.attention.output.dropout\n",
            "model_text_enc.encoder.layer.11.crossattention\n",
            "model_text_enc.encoder.layer.11.crossattention.self\n",
            "model_text_enc.encoder.layer.11.crossattention.self.query\n",
            "model_text_enc.encoder.layer.11.crossattention.self.key\n",
            "model_text_enc.encoder.layer.11.crossattention.self.value\n",
            "model_text_enc.encoder.layer.11.crossattention.self.dropout\n",
            "model_text_enc.encoder.layer.11.crossattention.output\n",
            "model_text_enc.encoder.layer.11.crossattention.output.dense\n",
            "model_text_enc.encoder.layer.11.crossattention.output.LayerNorm\n",
            "model_text_enc.encoder.layer.11.crossattention.output.dropout\n",
            "model_text_enc.encoder.layer.11.intermediate\n",
            "model_text_enc.encoder.layer.11.intermediate.dense\n",
            "model_text_enc.encoder.layer.11.intermediate.intermediate_act_fn\n",
            "model_text_enc.encoder.layer.11.output\n",
            "model_text_enc.encoder.layer.11.output.dense\n",
            "model_text_enc.encoder.layer.11.output.LayerNorm\n",
            "model_text_enc.encoder.layer.11.output.dropout\n",
            "model_text_dec\n",
            "model_text_dec.bert\n",
            "model_text_dec.bert.embeddings\n",
            "model_text_dec.bert.embeddings.word_embeddings\n",
            "model_text_dec.bert.embeddings.position_embeddings\n",
            "model_text_dec.bert.embeddings.LayerNorm\n",
            "model_text_dec.bert.embeddings.dropout\n",
            "model_text_dec.bert.encoder\n",
            "model_text_dec.bert.encoder.layer\n",
            "model_text_dec.bert.encoder.layer.0\n",
            "model_text_dec.bert.encoder.layer.0.attention\n",
            "model_text_dec.bert.encoder.layer.0.attention.self\n",
            "model_text_dec.bert.encoder.layer.0.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.0.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.0.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.0.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.0.attention.output\n",
            "model_text_dec.bert.encoder.layer.0.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.0.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.0.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.0.crossattention\n",
            "model_text_dec.bert.encoder.layer.0.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.0.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.0.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.0.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.0.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.0.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.0.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.0.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.0.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.0.intermediate\n",
            "model_text_dec.bert.encoder.layer.0.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.0.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.0.output\n",
            "model_text_dec.bert.encoder.layer.0.output.dense\n",
            "model_text_dec.bert.encoder.layer.0.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.0.output.dropout\n",
            "model_text_dec.bert.encoder.layer.1\n",
            "model_text_dec.bert.encoder.layer.1.attention\n",
            "model_text_dec.bert.encoder.layer.1.attention.self\n",
            "model_text_dec.bert.encoder.layer.1.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.1.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.1.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.1.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.1.attention.output\n",
            "model_text_dec.bert.encoder.layer.1.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.1.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.1.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.1.crossattention\n",
            "model_text_dec.bert.encoder.layer.1.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.1.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.1.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.1.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.1.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.1.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.1.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.1.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.1.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.1.intermediate\n",
            "model_text_dec.bert.encoder.layer.1.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.1.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.1.output\n",
            "model_text_dec.bert.encoder.layer.1.output.dense\n",
            "model_text_dec.bert.encoder.layer.1.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.1.output.dropout\n",
            "model_text_dec.bert.encoder.layer.2\n",
            "model_text_dec.bert.encoder.layer.2.attention\n",
            "model_text_dec.bert.encoder.layer.2.attention.self\n",
            "model_text_dec.bert.encoder.layer.2.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.2.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.2.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.2.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.2.attention.output\n",
            "model_text_dec.bert.encoder.layer.2.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.2.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.2.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.2.crossattention\n",
            "model_text_dec.bert.encoder.layer.2.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.2.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.2.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.2.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.2.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.2.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.2.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.2.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.2.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.2.intermediate\n",
            "model_text_dec.bert.encoder.layer.2.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.2.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.2.output\n",
            "model_text_dec.bert.encoder.layer.2.output.dense\n",
            "model_text_dec.bert.encoder.layer.2.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.2.output.dropout\n",
            "model_text_dec.bert.encoder.layer.3\n",
            "model_text_dec.bert.encoder.layer.3.attention\n",
            "model_text_dec.bert.encoder.layer.3.attention.self\n",
            "model_text_dec.bert.encoder.layer.3.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.3.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.3.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.3.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.3.attention.output\n",
            "model_text_dec.bert.encoder.layer.3.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.3.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.3.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.3.crossattention\n",
            "model_text_dec.bert.encoder.layer.3.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.3.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.3.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.3.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.3.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.3.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.3.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.3.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.3.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.3.intermediate\n",
            "model_text_dec.bert.encoder.layer.3.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.3.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.3.output\n",
            "model_text_dec.bert.encoder.layer.3.output.dense\n",
            "model_text_dec.bert.encoder.layer.3.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.3.output.dropout\n",
            "model_text_dec.bert.encoder.layer.4\n",
            "model_text_dec.bert.encoder.layer.4.attention\n",
            "model_text_dec.bert.encoder.layer.4.attention.self\n",
            "model_text_dec.bert.encoder.layer.4.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.4.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.4.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.4.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.4.attention.output\n",
            "model_text_dec.bert.encoder.layer.4.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.4.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.4.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.4.crossattention\n",
            "model_text_dec.bert.encoder.layer.4.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.4.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.4.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.4.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.4.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.4.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.4.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.4.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.4.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.4.intermediate\n",
            "model_text_dec.bert.encoder.layer.4.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.4.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.4.output\n",
            "model_text_dec.bert.encoder.layer.4.output.dense\n",
            "model_text_dec.bert.encoder.layer.4.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.4.output.dropout\n",
            "model_text_dec.bert.encoder.layer.5\n",
            "model_text_dec.bert.encoder.layer.5.attention\n",
            "model_text_dec.bert.encoder.layer.5.attention.self\n",
            "model_text_dec.bert.encoder.layer.5.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.5.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.5.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.5.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.5.attention.output\n",
            "model_text_dec.bert.encoder.layer.5.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.5.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.5.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.5.crossattention\n",
            "model_text_dec.bert.encoder.layer.5.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.5.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.5.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.5.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.5.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.5.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.5.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.5.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.5.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.5.intermediate\n",
            "model_text_dec.bert.encoder.layer.5.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.5.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.5.output\n",
            "model_text_dec.bert.encoder.layer.5.output.dense\n",
            "model_text_dec.bert.encoder.layer.5.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.5.output.dropout\n",
            "model_text_dec.bert.encoder.layer.6\n",
            "model_text_dec.bert.encoder.layer.6.attention\n",
            "model_text_dec.bert.encoder.layer.6.attention.self\n",
            "model_text_dec.bert.encoder.layer.6.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.6.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.6.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.6.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.6.attention.output\n",
            "model_text_dec.bert.encoder.layer.6.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.6.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.6.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.6.crossattention\n",
            "model_text_dec.bert.encoder.layer.6.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.6.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.6.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.6.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.6.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.6.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.6.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.6.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.6.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.6.intermediate\n",
            "model_text_dec.bert.encoder.layer.6.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.6.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.6.output\n",
            "model_text_dec.bert.encoder.layer.6.output.dense\n",
            "model_text_dec.bert.encoder.layer.6.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.6.output.dropout\n",
            "model_text_dec.bert.encoder.layer.7\n",
            "model_text_dec.bert.encoder.layer.7.attention\n",
            "model_text_dec.bert.encoder.layer.7.attention.self\n",
            "model_text_dec.bert.encoder.layer.7.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.7.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.7.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.7.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.7.attention.output\n",
            "model_text_dec.bert.encoder.layer.7.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.7.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.7.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.7.crossattention\n",
            "model_text_dec.bert.encoder.layer.7.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.7.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.7.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.7.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.7.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.7.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.7.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.7.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.7.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.7.intermediate\n",
            "model_text_dec.bert.encoder.layer.7.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.7.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.7.output\n",
            "model_text_dec.bert.encoder.layer.7.output.dense\n",
            "model_text_dec.bert.encoder.layer.7.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.7.output.dropout\n",
            "model_text_dec.bert.encoder.layer.8\n",
            "model_text_dec.bert.encoder.layer.8.attention\n",
            "model_text_dec.bert.encoder.layer.8.attention.self\n",
            "model_text_dec.bert.encoder.layer.8.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.8.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.8.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.8.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.8.attention.output\n",
            "model_text_dec.bert.encoder.layer.8.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.8.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.8.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.8.crossattention\n",
            "model_text_dec.bert.encoder.layer.8.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.8.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.8.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.8.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.8.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.8.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.8.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.8.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.8.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.8.intermediate\n",
            "model_text_dec.bert.encoder.layer.8.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.8.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.8.output\n",
            "model_text_dec.bert.encoder.layer.8.output.dense\n",
            "model_text_dec.bert.encoder.layer.8.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.8.output.dropout\n",
            "model_text_dec.bert.encoder.layer.9\n",
            "model_text_dec.bert.encoder.layer.9.attention\n",
            "model_text_dec.bert.encoder.layer.9.attention.self\n",
            "model_text_dec.bert.encoder.layer.9.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.9.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.9.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.9.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.9.attention.output\n",
            "model_text_dec.bert.encoder.layer.9.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.9.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.9.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.9.crossattention\n",
            "model_text_dec.bert.encoder.layer.9.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.9.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.9.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.9.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.9.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.9.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.9.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.9.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.9.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.9.intermediate\n",
            "model_text_dec.bert.encoder.layer.9.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.9.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.9.output\n",
            "model_text_dec.bert.encoder.layer.9.output.dense\n",
            "model_text_dec.bert.encoder.layer.9.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.9.output.dropout\n",
            "model_text_dec.bert.encoder.layer.10\n",
            "model_text_dec.bert.encoder.layer.10.attention\n",
            "model_text_dec.bert.encoder.layer.10.attention.self\n",
            "model_text_dec.bert.encoder.layer.10.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.10.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.10.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.10.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.10.attention.output\n",
            "model_text_dec.bert.encoder.layer.10.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.10.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.10.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.10.crossattention\n",
            "model_text_dec.bert.encoder.layer.10.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.10.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.10.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.10.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.10.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.10.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.10.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.10.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.10.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.10.intermediate\n",
            "model_text_dec.bert.encoder.layer.10.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.10.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.10.output\n",
            "model_text_dec.bert.encoder.layer.10.output.dense\n",
            "model_text_dec.bert.encoder.layer.10.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.10.output.dropout\n",
            "model_text_dec.bert.encoder.layer.11\n",
            "model_text_dec.bert.encoder.layer.11.attention\n",
            "model_text_dec.bert.encoder.layer.11.attention.self\n",
            "model_text_dec.bert.encoder.layer.11.attention.self.query\n",
            "model_text_dec.bert.encoder.layer.11.attention.self.key\n",
            "model_text_dec.bert.encoder.layer.11.attention.self.value\n",
            "model_text_dec.bert.encoder.layer.11.attention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.11.attention.output\n",
            "model_text_dec.bert.encoder.layer.11.attention.output.dense\n",
            "model_text_dec.bert.encoder.layer.11.attention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.11.attention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.11.crossattention\n",
            "model_text_dec.bert.encoder.layer.11.crossattention.self\n",
            "model_text_dec.bert.encoder.layer.11.crossattention.self.query\n",
            "model_text_dec.bert.encoder.layer.11.crossattention.self.key\n",
            "model_text_dec.bert.encoder.layer.11.crossattention.self.value\n",
            "model_text_dec.bert.encoder.layer.11.crossattention.self.dropout\n",
            "model_text_dec.bert.encoder.layer.11.crossattention.output\n",
            "model_text_dec.bert.encoder.layer.11.crossattention.output.dense\n",
            "model_text_dec.bert.encoder.layer.11.crossattention.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.11.crossattention.output.dropout\n",
            "model_text_dec.bert.encoder.layer.11.intermediate\n",
            "model_text_dec.bert.encoder.layer.11.intermediate.dense\n",
            "model_text_dec.bert.encoder.layer.11.intermediate.intermediate_act_fn\n",
            "model_text_dec.bert.encoder.layer.11.output\n",
            "model_text_dec.bert.encoder.layer.11.output.dense\n",
            "model_text_dec.bert.encoder.layer.11.output.LayerNorm\n",
            "model_text_dec.bert.encoder.layer.11.output.dropout\n",
            "model_text_dec.cls\n",
            "model_text_dec.cls.predictions\n",
            "model_text_dec.cls.predictions.transform\n",
            "model_text_dec.cls.predictions.transform.dense\n",
            "model_text_dec.cls.predictions.transform.transform_act_fn\n",
            "model_text_dec.cls.predictions.transform.LayerNorm\n",
            "model_text_dec.cls.predictions.decoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "fIwKX35QSAaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "po0Tjaq7Zq74"
      },
      "outputs": [],
      "source": [
        "def make_inputs(ModelandProcessor,new_model,image,question, device=device):\n",
        "  d_temp={}\n",
        "  model=ModelandProcessor.model\n",
        "  processor=ModelandProcessor.processor\n",
        "\n",
        "  input_ids = processor(text=question, return_tensors='pt').input_ids.to(device)\n",
        "  #input_ids = (torch.tensor(input_ids).unsqueeze(0)).to(device)\n",
        "\n",
        "  pixel_values=processor(images=image,return_tensors=\"pt\")\n",
        "  pixel_values_1=pixel_values.pixel_values.to(device)\n",
        "  pixel_values_2=pixel_values.pixel_values.to(device)\n",
        "  l=[pixel_values_1,pixel_values_2]\n",
        "\n",
        "  image_embeds=new_model.image_embed(list_pixel_values=l)\n",
        "  image_embeds.to(device)\n",
        "\n",
        "  tup=(image_embeds,input_ids)\n",
        "  return tup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tup=make_inputs(mt,new_model,image,question)"
      ],
      "metadata": {
        "id": "Bd5cbdQ-J1v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tup[0]"
      ],
      "metadata": {
        "id": "vgZopUv7KSoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8Q0QZQLjtbYV"
      },
      "outputs": [],
      "source": [
        "def predict_from_input(new_model,tup):\n",
        "    image_embeds,input_ids=tup\n",
        "    output=new_model.forward(image_embeds=image_embeds.to(device),input_ids=input_ids.to(device))\n",
        "\n",
        "\n",
        "    #attention_mask=processor(text=text_input, add_special_tokens=False).attention_mask\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "g6lZyfxrnEVA"
      },
      "outputs": [],
      "source": [
        "def result_gen(output, return_p=False):\n",
        "    out=output['decoder_logits']\n",
        "    probs = torch.softmax(out[:, -1], dim=1)\n",
        "    p, preds = torch.max(probs, dim=1)\n",
        "    return preds, p"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decoding(mt,pred_prob):\n",
        "  preds=pred_prob[0]\n",
        "  ans=[]\n",
        "  for i in range(preds.size(0)):\n",
        "    single_pred=preds[i]\n",
        "    decoded_answer=processor.decode(single_pred, skip_special_tokens=True)\n",
        "    ans.append(decoded_answer)\n",
        "  return ans[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "tacMbhkasyZq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prng(shape: tuple, uniform_noise: bool = True) -> np.ndarray:\n",
        "      rs = np.random.RandomState(1)\n",
        "      if uniform_noise:\n",
        "        return rs.uniform(-1, 1, shape)\n",
        "      else:\n",
        "        return rs.randn(*shape)"
      ],
      "metadata": {
        "id": "Pq3Nun1Du5kW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noisy_embedding(image_embed_tensor,uniform_noise=True,noise=0.7691,percentage_dimensions=1):\n",
        "  #num_dimensions_to_corrupt=round(percentage_dimensions*(inp[0].shape[0]))\n",
        "  corrupt_indices = [i for i in range(0,image_embed_tensor.size(1))]\n",
        "  if isinstance(noise, float):\n",
        "        noise_fn = lambda inp: noise * inp\n",
        "  else:\n",
        "        noise_fn = noise\n",
        "\n",
        "\n",
        "  noise_data = torch.rand(size=[1,577,768])\n",
        "  corrupt_run=image_embed_tensor[1][:,:]\n",
        "  image_embed_tensor[1]=noise_fn(image_embed_tensor[1])\n",
        "  image_embed_tensor.to(device)\n",
        "  return image_embed_tensor"
      ],
      "metadata": {
        "id": "CvivHrZHoJ8x"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_added_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-Ak_vJIgdr4",
        "outputId": "43b7da62-018c-493f-cbcc-e67f832cfd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.8730, -0.1344,  0.1977,  ..., -0.2741,  0.2352,  0.7188],\n",
              "         [-0.2848,  0.2965, -0.2212,  ...,  0.1181,  0.0483, -0.0484],\n",
              "         [-0.2919,  0.1136, -0.6004,  ...,  1.0594,  0.1805,  0.2552],\n",
              "         ...,\n",
              "         [-0.5395,  0.2122, -0.0217,  ...,  0.8717,  0.0089,  0.3548],\n",
              "         [-0.3715, -0.3431,  0.4678,  ...,  0.1776, -0.3779,  0.0218],\n",
              "         [ 0.3669, -0.4727,  0.1220,  ..., -0.1135, -0.4058,  0.3387]],\n",
              "\n",
              "        [[ 0.7836, -0.1207,  0.1774,  ..., -0.2460,  0.2111,  0.6452],\n",
              "         [-0.2556,  0.2662, -0.1986,  ...,  0.1060,  0.0434, -0.0434],\n",
              "         [-0.2620,  0.1020, -0.5389,  ...,  0.9509,  0.1620,  0.2291],\n",
              "         ...,\n",
              "         [-0.4843,  0.1904, -0.0195,  ...,  0.7824,  0.0080,  0.3185],\n",
              "         [-0.3335, -0.3080,  0.4199,  ...,  0.1594, -0.3392,  0.0196],\n",
              "         [ 0.3293, -0.4243,  0.1095,  ..., -0.1019, -0.3642,  0.3040]]],\n",
              "       grad_fn=<CopySlices>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PxSrPNOG3qLr"
      },
      "outputs": [],
      "source": [
        "def trace_with_patch(\n",
        "    mt,new_model,  # The model\n",
        "    image,\n",
        "    question,  # A set of inputs # A list of (token index, layername) triples to restore\n",
        "    pred_ans,\n",
        "    patching_layers,  # Answer probabilities to collect\n",
        "    replace=False,  # True to replace with instead of add noise\n",
        "    trace_layers=None,  # List of traced outputs to return\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs a single causal trace.  Given a model and a batch input where\n",
        "    the batch size is at least two, runs the batch in inference, corrupting\n",
        "    a the set of runs [1...n] while also restoring a set of hidden states to\n",
        "    the values from an uncorrupted run [0] in the batch.\n",
        "\n",
        "    The convention used by this function is that the zeroth element of the\n",
        "    batch is the uncorrupted run, and the subsequent elements of the batch\n",
        "    are the corrupted runs.  The argument tokens_to_mix specifies an\n",
        "    be corrupted by adding Gaussian noise to the embedding for the batch\n",
        "    inputs other than the first element in the batch.  Alternately,\n",
        "    subsequent runs could be corrupted by simply providing different\n",
        "    input tokens via the passed input batch.\n",
        "\n",
        "    Then when running, a specified set of hidden states will be uncorrupted\n",
        "    by restoring their values to the same vector that they had in the\n",
        "    zeroth uncorrupted run.  This set of hidden states is listed in\n",
        "    states_to_patch, by listing [(token_index, layername), ...] pairs.\n",
        "    To trace the effect of just a single state, this can be just a single\n",
        "    token/layer pair.  To trace the effect of restoring a set of states,\n",
        "    any number of token indices and layers can be listed.\n",
        "    \"\"\"\n",
        "\n",
        "    #rs = numpy.random.RandomState(1)  # For reproducibility, use pseudorandom noise\n",
        "    image_embed_tensor,input_ids=make_inputs(mt,new_model,image=image,question=question)\n",
        "    new_image_embed_tensor=noisy_embedding(image_embed_tensor)\n",
        "\n",
        "    patch_spec = defaultdict(list)\n",
        "    for t, l in patching_layers:\n",
        "        patch_spec[l].append(t)\n",
        "\n",
        "    #clean_image_attention_mask = torch.ones(clean_inp.size()[:-1], dtype=torch.long)\n",
        "    #corrup_image_attention_mask=torch.ones(corrupt_inp.size()[:-1], dtype=torch.long)\n",
        "    def untuple(x):\n",
        "        return x[0] if isinstance(x, tuple) else x\n",
        "\n",
        "    def patch_rep(x,layer):\n",
        "      if layer not in patch_spec:\n",
        "        return x\n",
        "      else:\n",
        "        if untuple(x).size(0)==1:\n",
        "          return x\n",
        "        else:\n",
        "          for t in patch_spec[layer]:\n",
        "              h=untuple(x)\n",
        "              h[1:, t,:] = h[0,t,:]\n",
        "          return x\n",
        "\n",
        "\n",
        "    # With the patching rules defined, run the patched model in inference.\n",
        "    #additional_layers = [] if trace_layers is None else trace_layers\n",
        "    with torch.no_grad(), TraceDict(\n",
        "        new_model,\n",
        "        list(patch_spec.keys()),\n",
        "        edit_output=patch_rep,\n",
        "    ) as td:\n",
        "        outputs_exp = new_model.forward(image_embeds=new_image_embed_tensor,input_ids=input_ids)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # We report softmax probabilities for the answers_t token predictions of interest.\n",
        "    probs = torch.softmax(outputs_exp.decoder_logits[1:, -1, :], dim=1).mean(dim=0)[pred_ans]\n",
        "    # If tracing all layers, collect all activations together to return.\n",
        "    #if trace_layers is not None:\n",
        "        #all_traced = torch.stack(\n",
        "         #   [untuple(td[layer].output).detach().cpu() for layer in trace_layers], dim=2\n",
        "        #)\n",
        "\n",
        "    return probs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trace_important_states(\n",
        "    mt,new_model,start,\n",
        "    num_layers,block_name,\n",
        "    image,question,\n",
        "    pred_ans,num=None,\n",
        "    replace=False,\n",
        "):\n",
        "    table = []\n",
        "    image_embed_tensor,input_ids=make_inputs(mt,new_model,image=image,question=question)\n",
        "    if num==None:\n",
        "      num=input_ids.shape[1]\n",
        "    for tnum in range(num):\n",
        "        row = []\n",
        "        for layer in range(start,num_layers):\n",
        "            r = trace_with_patch(\n",
        "                mt,new_model,  # The model\n",
        "                image,\n",
        "                question,  # A set of inputs # A list of (token index, layername) triples to restore\n",
        "                pred_ans,\n",
        "                [(tnum, layername(new_model, layer,block_name))],\n",
        "            )\n",
        "            row.append(r)\n",
        "        table.append(torch.stack(row))\n",
        "    return torch.stack(table)\n"
      ],
      "metadata": {
        "id": "Nasw8InWktng"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trace_important_window(\n",
        "    mt,new_model,start,\n",
        "    num_layers,block_name,\n",
        "    image,question,pred_ans,\n",
        "    kind,\n",
        "    window=3,num=None,\n",
        "    replace=False\n",
        "):\n",
        "    table = []\n",
        "    image_embed_tensor,input_ids=make_inputs(mt,new_model,image=image,question=question)\n",
        "    if num==None:\n",
        "      num=input_ids.shape[1]\n",
        "    for tnum in range(num):\n",
        "        row = []\n",
        "        for layer in range(start,num_layers):\n",
        "            layerlist = [\n",
        "                (tnum, layername(new_model, L,block_name, kind))\n",
        "                for L in range(\n",
        "                    max(0, layer - window // 2), min(num_layers, layer - (-window // 2))\n",
        "                )\n",
        "            ]\n",
        "            r = trace_with_patch(\n",
        "                mt,new_model,  # The model\n",
        "                image,\n",
        "                question,  # A set of inputs # A list of (token index, layername) triples to restore\n",
        "                pred_ans,\n",
        "                layerlist,\n",
        "            )\n",
        "            row.append(r)\n",
        "        table.append(torch.stack(row))\n",
        "    return torch.stack(table)\n"
      ],
      "metadata": {
        "id": "bKUL3bTAl3Kl"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_hidden_flow(mt,new_model,image,question,block_name,kind=None,expect=None):\n",
        "     tup=make_inputs(mt,new_model,image=image,question=question)\n",
        "     output=predict_from_input(new_model,tup)\n",
        "     pred_prob=result_gen(output)\n",
        "     new_image_embed_tensor=noisy_embedding(tup[0])\n",
        "     pred_ans_tensor=pred_prob[0][1]\n",
        "\n",
        "     predicted_ans=decoding(mt,pred_prob)\n",
        "     low_score = trace_with_patch(\n",
        "        mt,new_model, image,question,pred_ans_tensor, []\n",
        "    ).item()\n",
        "\n",
        "     if block_name=='text_encoder' and kind==None:\n",
        "        differences = trace_important_states(\n",
        "            mt,new_model,0,\n",
        "            12,block_name,\n",
        "            image,question,\n",
        "            pred_ans_tensor\n",
        "        )\n",
        "     elif block_name=='text_decoder' and kind==None:\n",
        "        differences = trace_important_states(\n",
        "            mt,new_model,1,\n",
        "            12,block_name,\n",
        "            image,question,\n",
        "            pred_ans_tensor,1\n",
        "        )\n",
        "     elif block_name=='text_encoder' and kind=='attention':\n",
        "        differences = trace_important_window(\n",
        "            mt,new_model,0,\n",
        "            12,block_name,\n",
        "            image,question,\n",
        "            pred_ans_tensor,kind\n",
        "        )\n",
        "     elif block_name=='text_encoder' and kind=='crossattention':\n",
        "        differences = trace_important_window(\n",
        "            mt,new_model,0,\n",
        "            12,block_name,\n",
        "            image,question,\n",
        "            pred_ans_tensor,kind\n",
        "        )\n",
        "     differences = differences.detach().cpu()\n",
        "     return dict(\n",
        "        scores=differences,\n",
        "        low_score=low_score,\n",
        "        high_score=pred_prob[1],\n",
        "        question=question,\n",
        "        answer=predicted_ans,\n",
        "        correct_prediction=True,\n",
        "        block_name=block_name,kind=kind\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jcry6iZtq99d"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_hidden_flow(\n",
        "    mt,\n",
        "    new_model,\n",
        "    image,question,\n",
        "    block_name,\n",
        "    savepdf=None,\n",
        "):\n",
        "    result = calculate_hidden_flow(mt,new_model,image,question,block_name)\n",
        "    plot_trace_heatmap(result, savepdf)\n",
        "\n",
        "temp_diff=[]\n",
        "temp_lows=[]\n",
        "def plot_trace_heatmap(result, savepdf=None, title=None, xlabel=None, modelname=None):\n",
        "    differences = result[\"scores\"]\n",
        "    low_score = result[\"low_score\"]\n",
        "    answer = result[\"answer\"]\n",
        "    block_name=(str(result[\"block_name\"]))\n",
        "    #print(differences)\n",
        "    #print(low_score)\n",
        "    #temp_diff.append(differences)\n",
        "    #temp_lows.append(low_score)\n",
        "   #kind = (\n",
        "    #    None\n",
        "     #   if (not result[\"kind\"] or result[\"kind\"] == \"None\")\n",
        "      #  else str(result[\"kind\"])\n",
        "    #)\n",
        "    #window = result.get(\"window\", 10)\n",
        "   #labels = list(result[\"input_tokens\"])\n",
        "    #for i in range(*result[\"subject_range\"]):\n",
        "     #   labels[i] = labels[i] + \"*\"\n",
        "    labels = list(question.split())\n",
        "    labels.insert(0,'[start]')\n",
        "    labels.append('[end]')\n",
        "    labels_news=['[decode]']\n",
        "    with plt.rc_context(rc={\"font.family\": \"Liberation Serif\"}):\n",
        "        fig, ax = plt.subplots(figsize=(3.5, 2), dpi=200)\n",
        "        h = ax.pcolor(\n",
        "            differences,\n",
        "            cmap={ \"text_encoder\": \"Purples\", \"text_decoder\": \"Reds\"}[block_name\n",
        "            ],\n",
        "            vmin=low_score,\n",
        "        )\n",
        "        print(differences.shape)\n",
        "        ax.invert_yaxis()\n",
        "        ax.set_yticks([0.5 + i for i in range(len(differences))])\n",
        "        ax.set_xticks([0.5 + i for i in range(0, differences.shape[1] - 1, 1)])\n",
        "        ax.set_xticklabels(list(range(0, differences.shape[1] - 1, 1)))\n",
        "        if not modelname:\n",
        "            modelname = \"BLIP\"\n",
        "        if block_name!=None:\n",
        "            if block_name=='text_encoder':\n",
        "              ax.set_yticklabels(labels)\n",
        "              blockname='text_encoder'\n",
        "              ax.set_title(f\"Impact of restoring {blockname} after corrupted input\")\n",
        "            else:\n",
        "              blockname='text_decoder'\n",
        "              ax.set_yticklabels(labels_news)\n",
        "              ax.set_title(f\"Impact of restoring {blockname} after corrupted input\")\n",
        "\n",
        "            #ax.set_xlabel(f\"center of interval of {window} restored {kindname} layers\")\n",
        "        cb = plt.colorbar(h)\n",
        "        if title is not None:\n",
        "            ax.set_title(title)\n",
        "        if xlabel is not None:\n",
        "            ax.set_xlabel(xlabel)\n",
        "        elif answer is not None:\n",
        "            # The following should be cb.ax.set_xlabel, but this is broken in matplotlib 3.5.1.\n",
        "            cb.ax.set_title(f\"p({str(answer).strip()})\", y=-0.16, fontsize=10)\n",
        "        if savepdf:\n",
        "            os.makedirs(os.path.dirname(savepdf), exist_ok=True)\n",
        "            plt.savefig(savepdf, bbox_inches=\"tight\")\n",
        "            plt.close()\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "def plot_all_flow(mt,new_model, image,question,savepdf,subject=None):\n",
        "    for block_name in ['text_decoder']:\n",
        "        plot_hidden_flow(mt,new_model,image,question,block_name,savepdf)"
      ],
      "metadata": {
        "id": "wBDq_Jd4QFVv"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_kind_hidden_flow(\n",
        "    mt,\n",
        "    new_model,\n",
        "    image,question,\n",
        "    block_name,kind,\n",
        "    savepdf=None,\n",
        "):\n",
        "    result = calculate_hidden_flow(mt,new_model,image,question,block_name,kind)\n",
        "    plot_kindtrace_heatmap(result, savepdf)\n",
        "\n",
        "temp_diff=[]\n",
        "temp_lows=[]\n",
        "def plot_kindtrace_heatmap(result, savepdf=None, title=None, xlabel=None, modelname=None):\n",
        "    differences = result[\"scores\"]\n",
        "    low_score = result[\"low_score\"]\n",
        "    answer = result[\"answer\"]\n",
        "    block_name=(str(result[\"block_name\"]))\n",
        "    kind=(str(result['kind']))\n",
        "    #print(differences)\n",
        "    #print(low_score)\n",
        "    #temp_diff.append(differences)\n",
        "    #temp_lows.append(low_score)\n",
        "   #kind = (\n",
        "    #    None\n",
        "     #   if (not result[\"kind\"] or result[\"kind\"] == \"None\")\n",
        "      #  else str(result[\"kind\"])\n",
        "    #)\n",
        "    #window = result.get(\"window\", 10)\n",
        "   #labels = list(result[\"input_tokens\"])\n",
        "    #for i in range(*result[\"subject_range\"]):\n",
        "     #   labels[i] = labels[i] + \"*\"\n",
        "    labels = list(question.split())\n",
        "    labels.insert(0,'[start]')\n",
        "    labels.append('[end]')\n",
        "    labels_news=['[decode]']\n",
        "    with plt.rc_context(rc={\"font.family\": \"Liberation Serif\"}):\n",
        "        fig, ax = plt.subplots(figsize=(3.5, 2), dpi=200)\n",
        "        h = ax.pcolor(\n",
        "            differences,\n",
        "            cmap={ \"attention\": \"Greens\", \"crossattention\": \"Blues\"}[kind\n",
        "            ],\n",
        "            vmin=low_score,\n",
        "        )\n",
        "        print(differences.shape)\n",
        "        ax.invert_yaxis()\n",
        "        ax.set_yticks([0.5 + i for i in range(len(differences))])\n",
        "        ax.set_xticks([0.5 + i for i in range(0, differences.shape[1] - 1, 1)])\n",
        "        ax.set_xticklabels(list(range(0, differences.shape[1] - 1, 1)))\n",
        "        if not modelname:\n",
        "            modelname = \"BLIP\"\n",
        "        if block_name!=None and kind!=None:\n",
        "            if block_name=='text_encoder' and kind=='attention':\n",
        "              print(\"attention:\",differences)\n",
        "              ax.set_yticklabels(labels)\n",
        "              blockname='text_encoder'\n",
        "              ax.set_title(f\"Impact of restoring {kind} layers in {blockname} after corrupted input\")\n",
        "            else:\n",
        "              blockname='text_encoder'\n",
        "              kind=='crossattention'\n",
        "              print(\"crossattention:\",differences)\n",
        "              ax.set_yticklabels(labels)\n",
        "              ax.set_title(f\"Impact of restoring {kind} layers in {blockname} after corrupted input\")\n",
        "\n",
        "            #ax.set_xlabel(f\"center of interval of {window} restored {kindname} layers\")\n",
        "        cb = plt.colorbar(h)\n",
        "        if title is not None:\n",
        "            ax.set_title(title)\n",
        "        if xlabel is not None:\n",
        "            ax.set_xlabel(xlabel)\n",
        "        elif answer is not None:\n",
        "            # The following should be cb.ax.set_xlabel, but this is broken in matplotlib 3.5.1.\n",
        "            cb.ax.set_title(f\"p({str(answer).strip()})\", y=-0.16, fontsize=10)\n",
        "        if savepdf:\n",
        "            os.makedirs(os.path.dirname(savepdf), exist_ok=True)\n",
        "            plt.savefig(savepdf, bbox_inches=\"tight\")\n",
        "            plt.close()\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "def plotkind_all_flow(mt,new_model, image,question,savepdf=None,subject=None):\n",
        "    for kind in [('attention','/content/causal_trace_sampleexample2_Question Encoder_Attention Layers.pdf'),('crossattention','/content/causal_trace_sampleexample2_Question Encoder_CrossAttention Layers.pdf')]:\n",
        "        plot_kind_hidden_flow(mt,new_model,image,question,'text_encoder',kind[0],kind[1])"
      ],
      "metadata": {
        "id": "cQx2tRZxXWLF"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test on Pre-trained Model"
      ],
      "metadata": {
        "id": "mNjtkRBTdTyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y font-manager\n",
        "!cp times new roman.ttf /usr/share/fonts/truetype/\n",
        "!fc-cache -f -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhubOmbfVICg",
        "outputId": "2e0893a6-bccf-449c-dd00-927d8f5f9480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  font-manager-common font-viewer\n",
            "Suggested packages:\n",
            "  file-roller nautilus-font-manager nemo-font-manager yelp\n",
            "The following NEW packages will be installed:\n",
            "  font-manager font-manager-common font-viewer\n",
            "0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 1,740 kB of archives.\n",
            "After this operation, 9,394 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 font-manager-common amd64 0.7.7-0.3 [1,545 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 font-viewer amd64 0.7.7-0.3 [27.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 font-manager amd64 0.7.7-0.3 [168 kB]\n",
            "Fetched 1,740 kB in 1s (2,276 kB/s)\n",
            "Selecting previously unselected package font-manager-common:amd64.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../font-manager-common_0.7.7-0.3_amd64.deb ...\n",
            "Unpacking font-manager-common:amd64 (0.7.7-0.3) ...\n",
            "Selecting previously unselected package font-viewer.\n",
            "Preparing to unpack .../font-viewer_0.7.7-0.3_amd64.deb ...\n",
            "Unpacking font-viewer (0.7.7-0.3) ...\n",
            "Selecting previously unselected package font-manager.\n",
            "Preparing to unpack .../font-manager_0.7.7-0.3_amd64.deb ...\n",
            "Unpacking font-manager (0.7.7-0.3) ...\n",
            "Setting up font-manager-common:amd64 (0.7.7-0.3) ...\n",
            "Setting up font-viewer (0.7.7-0.3) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.64.6-1~ubuntu20.04.6) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Setting up font-manager (0.7.7-0.3) ...\n",
            "cp: cannot stat 'times': No such file or directory\n",
            "cp: cannot stat 'new': No such file or directory\n",
            "cp: cannot stat 'roman.ttf': No such file or directory\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 2 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.font_manager as fm\n",
        "\n",
        "font_list = fm.findSystemFonts()\n",
        "font_names = [fm.get_font(font).family_name for font in font_list]\n",
        "print(font_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiNrfp06VbUn",
        "outputId": "11be5f35-e2bd-4fe9-ec4e-083318a1a1bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Liberation Sans Narrow', 'Liberation Sans Narrow', 'Liberation Sans', 'Liberation Sans', 'Liberation Serif', 'Liberation Mono', 'Liberation Sans Narrow', 'Liberation Sans', 'Liberation Serif', 'Liberation Sans Narrow', 'Liberation Serif', 'Humor Sans', 'Liberation Mono', 'Liberation Mono', 'Liberation Mono', 'Liberation Serif', 'Liberation Sans']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_df=pd.read_csv('/content/clevr_vqa_dataset_3.csv')"
      ],
      "metadata": {
        "id": "uwiRPmdcdWEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1085
        },
        "id": "1WQ0SxD6RZIn",
        "outputId": "72a493d9-bcde-4ac9-ed0d-1d88ebd988ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0         Image_IDs  \\\n",
              "0           0  CLEVR_val_000145   \n",
              "1           1  CLEVR_val_000187   \n",
              "2           2  CLEVR_val_000194   \n",
              "3           3  CLEVR_val_000206   \n",
              "4           4  CLEVR_val_000233   \n",
              "\n",
              "                                   Questions_Answers  \n",
              "0  [{'question': 'Is the large red cylinder right...  \n",
              "1  [{'question': 'Is the large green cylinder rig...  \n",
              "2  [{'question': 'Is the small purple sphere righ...  \n",
              "3  [{'question': 'Is the large cyan cube right of...  \n",
              "4  [{'question': 'Is the small brown cylinder rig...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bafee037-3985-4a83-b233-754035d8a32b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Image_IDs</th>\n",
              "      <th>Questions_Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>CLEVR_val_000145</td>\n",
              "      <td>[{'question': 'Is the large red cylinder right...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CLEVR_val_000187</td>\n",
              "      <td>[{'question': 'Is the large green cylinder rig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CLEVR_val_000194</td>\n",
              "      <td>[{'question': 'Is the small purple sphere righ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CLEVR_val_000206</td>\n",
              "      <td>[{'question': 'Is the large cyan cube right of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CLEVR_val_000233</td>\n",
              "      <td>[{'question': 'Is the small brown cylinder rig...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bafee037-3985-4a83-b233-754035d8a32b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bafee037-3985-4a83-b233-754035d8a32b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bafee037-3985-4a83-b233-754035d8a32b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "color_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "g62jLO_pkaoo",
        "outputId": "b023feff-6aee-4959-ea72-7aa9b05d910a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0 final_image_id  train_image_id_count  \\\n",
              "0               0   000000023004                 23004   \n",
              "1               1   000000220218                220218   \n",
              "2               2   000000491525                491525   \n",
              "3               3   000000256565                256565   \n",
              "4               4   000000351203                351203   \n",
              "...           ...            ...                   ...   \n",
              "13108       13108   000000463172                463172   \n",
              "13109       13109   000000138368                138368   \n",
              "13110       13110   000000381027                381027   \n",
              "13111       13111   000000411815                411815   \n",
              "13112       13112   000000530479                530479   \n",
              "\n",
              "                           question_count answer_count  \n",
              "0         what is the color of the horses        brown  \n",
              "1      what is the color of the character       purple  \n",
              "2            what is the color of the dog        black  \n",
              "3           what is the color of the sign          red  \n",
              "4          what is the color of the leash       orange  \n",
              "...                                   ...          ...  \n",
              "13108       what is the color of the bird        white  \n",
              "13109      what is the color of the court         blue  \n",
              "13110     what is the color of the inside       purple  \n",
              "13111      what is the color of the field        green  \n",
              "13112        what is the color of the sky         blue  \n",
              "\n",
              "[13113 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64e93258-2549-4f80-9438-90e83be0e8cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>final_image_id</th>\n",
              "      <th>train_image_id_count</th>\n",
              "      <th>question_count</th>\n",
              "      <th>answer_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>000000023004</td>\n",
              "      <td>23004</td>\n",
              "      <td>what is the color of the horses</td>\n",
              "      <td>brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>000000220218</td>\n",
              "      <td>220218</td>\n",
              "      <td>what is the color of the character</td>\n",
              "      <td>purple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>000000491525</td>\n",
              "      <td>491525</td>\n",
              "      <td>what is the color of the dog</td>\n",
              "      <td>black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>000000256565</td>\n",
              "      <td>256565</td>\n",
              "      <td>what is the color of the sign</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>000000351203</td>\n",
              "      <td>351203</td>\n",
              "      <td>what is the color of the leash</td>\n",
              "      <td>orange</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13108</th>\n",
              "      <td>13108</td>\n",
              "      <td>000000463172</td>\n",
              "      <td>463172</td>\n",
              "      <td>what is the color of the bird</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13109</th>\n",
              "      <td>13109</td>\n",
              "      <td>000000138368</td>\n",
              "      <td>138368</td>\n",
              "      <td>what is the color of the court</td>\n",
              "      <td>blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13110</th>\n",
              "      <td>13110</td>\n",
              "      <td>000000381027</td>\n",
              "      <td>381027</td>\n",
              "      <td>what is the color of the inside</td>\n",
              "      <td>purple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13111</th>\n",
              "      <td>13111</td>\n",
              "      <td>000000411815</td>\n",
              "      <td>411815</td>\n",
              "      <td>what is the color of the field</td>\n",
              "      <td>green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13112</th>\n",
              "      <td>13112</td>\n",
              "      <td>000000530479</td>\n",
              "      <td>530479</td>\n",
              "      <td>what is the color of the sky</td>\n",
              "      <td>blue</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13113 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64e93258-2549-4f80-9438-90e83be0e8cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64e93258-2549-4f80-9438-90e83be0e8cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64e93258-2549-4f80-9438-90e83be0e8cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_id=color_df['final_image_id'][1]\n",
        "url=f\"http://images.cocodataset.org/train2017/{image_id}.jpg\"\n",
        "image=Image.open(requests.get(url, stream=True).raw)\n",
        "question=color_df['question_count'][1]"
      ],
      "metadata": {
        "id": "seLTFWiy1QgB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_diff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbDYM99BuP2V",
        "outputId": "64afeeaf-f9ea-4e98-8541-d410d82d11ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.8839, 0.8839, 0.8839, 0.8839, 0.8839, 0.8838, 0.8838, 0.8838, 0.8837,\n",
              "          0.8838, 0.8839, 0.8841],\n",
              "         [0.8839, 0.8840, 0.8840, 0.8840, 0.8840, 0.8839, 0.8838, 0.8838, 0.8838,\n",
              "          0.8838, 0.8839, 0.8841],\n",
              "         [0.8839, 0.8839, 0.8839, 0.8839, 0.8839, 0.8838, 0.8838, 0.8838, 0.8837,\n",
              "          0.8838, 0.8838, 0.8841],\n",
              "         [0.8839, 0.8839, 0.8839, 0.8839, 0.8838, 0.8838, 0.8838, 0.8838, 0.8837,\n",
              "          0.8838, 0.8838, 0.8841],\n",
              "         [0.8839, 0.8838, 0.8838, 0.8835, 0.8838, 0.8837, 0.8839, 0.8839, 0.8838,\n",
              "          0.8839, 0.8839, 0.8841],\n",
              "         [0.8839, 0.8839, 0.8840, 0.8840, 0.8840, 0.8838, 0.8838, 0.8838, 0.8838,\n",
              "          0.8838, 0.8839, 0.8841],\n",
              "         [0.8840, 0.8840, 0.8840, 0.8840, 0.8840, 0.8838, 0.8838, 0.8838, 0.8838,\n",
              "          0.8838, 0.8839, 0.8841],\n",
              "         [0.8839, 0.8836, 0.8837, 0.8840, 0.8847, 0.8844, 0.8842, 0.8838, 0.8839,\n",
              "          0.8840, 0.8842, 0.8842],\n",
              "         [0.8839, 0.8839, 0.8839, 0.8839, 0.8839, 0.8839, 0.8839, 0.8839, 0.8839,\n",
              "          0.8839, 0.8839, 0.8840]]),\n",
              " tensor([[0.8839, 0.8839, 0.8839, 0.8839, 0.8839, 0.8839, 0.8839, 0.8840, 0.8853,\n",
              "          0.8854, 0.8843]])]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotkind_all_flow(mt,new_model,image,question)"
      ],
      "metadata": {
        "id": "Ffe8j6XhT8m2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b5fd8a-7f8f-4455-ffa6-85d84dd27bb6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 12])\n",
            "attention: tensor([[0.7348, 0.7348, 0.7348, 0.7349, 0.7351, 0.7342, 0.7349, 0.7361, 0.7377,\n",
            "         0.7377, 0.7452, 0.7451],\n",
            "        [0.7347, 0.7350, 0.7349, 0.7354, 0.7359, 0.7353, 0.7350, 0.7355, 0.7369,\n",
            "         0.7369, 0.7448, 0.7446],\n",
            "        [0.7348, 0.7348, 0.7347, 0.7347, 0.7351, 0.7346, 0.7345, 0.7357, 0.7371,\n",
            "         0.7370, 0.7450, 0.7448],\n",
            "        [0.7347, 0.7347, 0.7347, 0.7348, 0.7351, 0.7348, 0.7349, 0.7364, 0.7378,\n",
            "         0.7378, 0.7456, 0.7455],\n",
            "        [0.7346, 0.7336, 0.7344, 0.7347, 0.7351, 0.7353, 0.7354, 0.7369, 0.7376,\n",
            "         0.7377, 0.7452, 0.7448],\n",
            "        [0.7347, 0.7346, 0.7347, 0.7349, 0.7350, 0.7344, 0.7346, 0.7361, 0.7374,\n",
            "         0.7376, 0.7456, 0.7456],\n",
            "        [0.7348, 0.7348, 0.7348, 0.7351, 0.7352, 0.7347, 0.7349, 0.7365, 0.7379,\n",
            "         0.7380, 0.7459, 0.7458],\n",
            "        [0.7349, 0.7371, 0.7381, 0.7358, 0.7354, 0.7364, 0.7376, 0.7389, 0.7382,\n",
            "         0.7368, 0.7430, 0.7426],\n",
            "        [0.7348, 0.7348, 0.7348, 0.7348, 0.7348, 0.7348, 0.7348, 0.7348, 0.7348,\n",
            "         0.7349, 0.7361, 0.7360]])\n",
            "torch.Size([9, 12])\n",
            "crossattention: tensor([[0.7348, 0.7348, 0.7348, 0.7350, 0.7344, 0.7345, 0.7356, 0.7374, 0.7376,\n",
            "         0.7446, 0.7497, 0.7497],\n",
            "        [0.7349, 0.7351, 0.7359, 0.7360, 0.7355, 0.7353, 0.7356, 0.7370, 0.7370,\n",
            "         0.7446, 0.7491, 0.7490],\n",
            "        [0.7348, 0.7348, 0.7351, 0.7351, 0.7348, 0.7345, 0.7353, 0.7372, 0.7372,\n",
            "         0.7447, 0.7494, 0.7493],\n",
            "        [0.7347, 0.7346, 0.7348, 0.7350, 0.7345, 0.7345, 0.7357, 0.7379, 0.7380,\n",
            "         0.7453, 0.7501, 0.7500],\n",
            "        [0.7340, 0.7343, 0.7341, 0.7344, 0.7345, 0.7356, 0.7369, 0.7387, 0.7385,\n",
            "         0.7457, 0.7498, 0.7494],\n",
            "        [0.7345, 0.7345, 0.7347, 0.7349, 0.7345, 0.7344, 0.7354, 0.7374, 0.7377,\n",
            "         0.7451, 0.7505, 0.7506],\n",
            "        [0.7347, 0.7347, 0.7349, 0.7350, 0.7347, 0.7347, 0.7359, 0.7379, 0.7380,\n",
            "         0.7452, 0.7507, 0.7507],\n",
            "        [0.7371, 0.7383, 0.7363, 0.7360, 0.7378, 0.7382, 0.7388, 0.7391, 0.7385,\n",
            "         0.7422, 0.7447, 0.7444],\n",
            "        [0.7348, 0.7348, 0.7348, 0.7348, 0.7348, 0.7347, 0.7347, 0.7347, 0.7346,\n",
            "         0.7357, 0.7361, 0.7362]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_all_flow(mt,new_model,image,question,'/content/causaltrace_sampleexample2_Answer Decoder.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eyyxa-3lNiM",
        "outputId": "08d523f1-bfa5-4909-cee4-3b543c2cec16"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
        "plt.rcParams[\"mathtext.fontset\"] = \"dejavuserif\""
      ],
      "metadata": {
        "id": "LQiiAlHesE9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_kindavg_hidden_flow(\n",
        "    mt,\n",
        "    new_model,\n",
        "    image,question,\n",
        "    block_name,kind,\n",
        "    savepdf=None,\n",
        "):\n",
        "    result = calculate_hidden_flow(mt,new_model,image,question,block_name,kind)\n",
        "    return result"
      ],
      "metadata": {
        "id": "L-4CMzubVSZF"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_df=pd.read_csv('/content/color_coco_qa.csv')"
      ],
      "metadata": {
        "id": "NLC1_oSxXi9P"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_id(df):\n",
        "  temp=df['train_image_id_count']\n",
        "  df.drop(['Unnamed: 0'],axis=1)\n",
        "  image_id=[]\n",
        "  for i in temp:\n",
        "    str_i=str(i)\n",
        "    num_of_zeros=12-len(str_i)\n",
        "    temp_s=\"\"\n",
        "    for j in range(num_of_zeros):\n",
        "      temp_s+=\"0\"\n",
        "    temp_s+=str_i\n",
        "    image_id.append(temp_s)\n",
        "  df.insert(loc=1,column = 'final_image_id',\n",
        "          value = image_id)\n",
        "  return df"
      ],
      "metadata": {
        "id": "KqXcf9QcX-Tv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_df=convert_to_id(color_df)"
      ],
      "metadata": {
        "id": "RHy5TfwoX_Gg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def element_wise_average(*tensors):\n",
        "    num_tensors = len(tensors)\n",
        "    # Create an empty tensor of the same size as the input tensors\n",
        "    average_tensor = np.zeros_like(tensors[0])\n",
        "\n",
        "    # Sum the corresponding elements of the input tensors\n",
        "    for tensor in tensors:\n",
        "        average_tensor += tensor\n",
        "\n",
        "    # Divide the summed tensor by the total number of input tensors\n",
        "    average_tensor /= num_tensors\n",
        "\n",
        "    return average_tensor"
      ],
      "metadata": {
        "id": "P7tngZttbiwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques=color_df['question_count'][25]"
      ],
      "metadata": {
        "id": "BmSEIsPam0Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "HTAxCXV1qhh9",
        "outputId": "5db1e4a5-9f70-4712-ca64-5f192692bcfa"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0 final_image_id  train_image_id_count  \\\n",
              "0               0   000000023004                 23004   \n",
              "1               1   000000220218                220218   \n",
              "2               2   000000491525                491525   \n",
              "3               3   000000256565                256565   \n",
              "4               4   000000351203                351203   \n",
              "...           ...            ...                   ...   \n",
              "13108       13108   000000463172                463172   \n",
              "13109       13109   000000138368                138368   \n",
              "13110       13110   000000381027                381027   \n",
              "13111       13111   000000411815                411815   \n",
              "13112       13112   000000530479                530479   \n",
              "\n",
              "                           question_count answer_count  \n",
              "0         what is the color of the horses        brown  \n",
              "1      what is the color of the character       purple  \n",
              "2            what is the color of the dog        black  \n",
              "3           what is the color of the sign          red  \n",
              "4          what is the color of the leash       orange  \n",
              "...                                   ...          ...  \n",
              "13108       what is the color of the bird        white  \n",
              "13109      what is the color of the court         blue  \n",
              "13110     what is the color of the inside       purple  \n",
              "13111      what is the color of the field        green  \n",
              "13112        what is the color of the sky         blue  \n",
              "\n",
              "[13113 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7f875a3-de29-44fa-89d9-dc5d9992e7e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>final_image_id</th>\n",
              "      <th>train_image_id_count</th>\n",
              "      <th>question_count</th>\n",
              "      <th>answer_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>000000023004</td>\n",
              "      <td>23004</td>\n",
              "      <td>what is the color of the horses</td>\n",
              "      <td>brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>000000220218</td>\n",
              "      <td>220218</td>\n",
              "      <td>what is the color of the character</td>\n",
              "      <td>purple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>000000491525</td>\n",
              "      <td>491525</td>\n",
              "      <td>what is the color of the dog</td>\n",
              "      <td>black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>000000256565</td>\n",
              "      <td>256565</td>\n",
              "      <td>what is the color of the sign</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>000000351203</td>\n",
              "      <td>351203</td>\n",
              "      <td>what is the color of the leash</td>\n",
              "      <td>orange</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13108</th>\n",
              "      <td>13108</td>\n",
              "      <td>000000463172</td>\n",
              "      <td>463172</td>\n",
              "      <td>what is the color of the bird</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13109</th>\n",
              "      <td>13109</td>\n",
              "      <td>000000138368</td>\n",
              "      <td>138368</td>\n",
              "      <td>what is the color of the court</td>\n",
              "      <td>blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13110</th>\n",
              "      <td>13110</td>\n",
              "      <td>000000381027</td>\n",
              "      <td>381027</td>\n",
              "      <td>what is the color of the inside</td>\n",
              "      <td>purple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13111</th>\n",
              "      <td>13111</td>\n",
              "      <td>000000411815</td>\n",
              "      <td>411815</td>\n",
              "      <td>what is the color of the field</td>\n",
              "      <td>green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13112</th>\n",
              "      <td>13112</td>\n",
              "      <td>000000530479</td>\n",
              "      <td>530479</td>\n",
              "      <td>what is the color of the sky</td>\n",
              "      <td>blue</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13113 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7f875a3-de29-44fa-89d9-dc5d9992e7e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7f875a3-de29-44fa-89d9-dc5d9992e7e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7f875a3-de29-44fa-89d9-dc5d9992e7e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_id_arr=[]\n",
        "answer_arr=[]\n",
        "question_arr=[]\n",
        "for i in range(len(color_df['question_count'])):\n",
        "  f_i_i=color_df['final_image_id'][i]\n",
        "  answer=color_df['answer_count'][i]\n",
        "  ques=color_df['question_count'][i]\n",
        "  if len(ques.split())==7:\n",
        "    question_arr.append(ques)\n",
        "    answer_arr.append(answer)\n",
        "    img_id_arr.append(f_i_i)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pDOb6RKvqRRm"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_df=pd.DataFrame()"
      ],
      "metadata": {
        "id": "ilm-MV8MrHZ4"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_df['final_image_id']=img_id_arr\n",
        "color_df['question_count']=question_arr\n",
        "color_df['answer_count']=answer_arr"
      ],
      "metadata": {
        "id": "P6PS9_qVrLZV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "G9xsUexbrVXW",
        "outputId": "ebbd1064-a844-417d-80c4-1667b14bc00a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      final_image_id                      question_count answer_count\n",
              "0       000000023004     what is the color of the horses        brown\n",
              "1       000000220218  what is the color of the character       purple\n",
              "2       000000491525        what is the color of the dog        black\n",
              "3       000000256565       what is the color of the sign          red\n",
              "4       000000351203      what is the color of the leash       orange\n",
              "...              ...                                 ...          ...\n",
              "13057   000000463172       what is the color of the bird        white\n",
              "13058   000000138368      what is the color of the court         blue\n",
              "13059   000000381027     what is the color of the inside       purple\n",
              "13060   000000411815      what is the color of the field        green\n",
              "13061   000000530479        what is the color of the sky         blue\n",
              "\n",
              "[13062 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6194b7e-21eb-408f-a3a6-77ce70f7a696\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>final_image_id</th>\n",
              "      <th>question_count</th>\n",
              "      <th>answer_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000023004</td>\n",
              "      <td>what is the color of the horses</td>\n",
              "      <td>brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000000220218</td>\n",
              "      <td>what is the color of the character</td>\n",
              "      <td>purple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000000491525</td>\n",
              "      <td>what is the color of the dog</td>\n",
              "      <td>black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000000256565</td>\n",
              "      <td>what is the color of the sign</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000000351203</td>\n",
              "      <td>what is the color of the leash</td>\n",
              "      <td>orange</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13057</th>\n",
              "      <td>000000463172</td>\n",
              "      <td>what is the color of the bird</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13058</th>\n",
              "      <td>000000138368</td>\n",
              "      <td>what is the color of the court</td>\n",
              "      <td>blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13059</th>\n",
              "      <td>000000381027</td>\n",
              "      <td>what is the color of the inside</td>\n",
              "      <td>purple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13060</th>\n",
              "      <td>000000411815</td>\n",
              "      <td>what is the color of the field</td>\n",
              "      <td>green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13061</th>\n",
              "      <td>000000530479</td>\n",
              "      <td>what is the color of the sky</td>\n",
              "      <td>blue</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13062 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6194b7e-21eb-408f-a3a6-77ce70f7a696')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6194b7e-21eb-408f-a3a6-77ce70f7a696 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6194b7e-21eb-408f-a3a6-77ce70f7a696');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff_text_enc=0\n",
        "low_s_text_enc=0\n",
        "diff_text_dec=0\n",
        "low_s_text_dec=0\n",
        "count=500\n",
        "c1=0\n",
        "c2=0\n",
        "for i in range(count):\n",
        "  image_id=color_df['final_image_id'][i]\n",
        "  url=f\"http://images.cocodataset.org/train2017/{image_id}.jpg\"\n",
        "  image=Image.open(requests.get(url, stream=True).raw)\n",
        "  question=color_df['question_count'][i]\n",
        "  #question=question.rstrip()\n",
        "  result_temp=plot_kindavg_hidden_flow(mt,new_model,image,question,'text_encoder','attention')\n",
        "  #print(result_temp['scores'])\n",
        "  try:\n",
        "    diff_text_enc+=result_temp['scores']\n",
        "    low_s_text_enc+=result_temp['low_score']\n",
        "  except:\n",
        "    c1+=1\n",
        "    continue\n",
        "\n",
        "  result_temp_1=plot_kindavg_hidden_flow(mt,new_model,image,question,'text_encoder','crossattention')\n",
        "  try:\n",
        "    diff_text_dec+=result_temp_1['scores']\n",
        "    low_s_text_dec+=result_temp_1['low_score']\n",
        "  except:\n",
        "    c2+=1\n",
        "    continue"
      ],
      "metadata": {
        "id": "UiaknrzUXpM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(c1,c2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4CR9FagnVb-",
        "outputId": "95396a15-8143-4346-afde-3319b8fb1403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LM5ED3nmvbr",
        "outputId": "e9a0a2f4-12d9-4f83-db53-2593c77efb9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff_text_dec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ1duulasZw4",
        "outputId": "8a04b6bb-9aac-430b-b3c1-9904da5b987f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8443, 0.8452,\n",
              "         0.8455, 0.8465]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff_text_enc=diff_text_enc/(count-34)\n",
        "low_s_text_enc=low_s_text_enc/(count-34)\n",
        "diff_text_dec=diff_text_dec/(count-34)\n",
        "low_s_text_dec=low_s_text_dec/(count-34)"
      ],
      "metadata": {
        "id": "39GJcG8P0IRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff_text_enc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnhLNFdNuo59",
        "outputId": "0c9cf65e-e5cc-4ea8-e070-8958ab1094f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8443, 0.8444, 0.8445,\n",
              "         0.8446, 0.8449, 0.8449],\n",
              "        [0.8442, 0.8442, 0.8442, 0.8443, 0.8443, 0.8442, 0.8442, 0.8443, 0.8444,\n",
              "         0.8444, 0.8448, 0.8447],\n",
              "        [0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8441, 0.8441, 0.8442, 0.8444,\n",
              "         0.8443, 0.8447, 0.8446],\n",
              "        [0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8441, 0.8442, 0.8443, 0.8444,\n",
              "         0.8444, 0.8448, 0.8447],\n",
              "        [0.8443, 0.8443, 0.8443, 0.8443, 0.8443, 0.8443, 0.8443, 0.8444, 0.8445,\n",
              "         0.8444, 0.8448, 0.8447],\n",
              "        [0.8442, 0.8442, 0.8442, 0.8442, 0.8443, 0.8441, 0.8442, 0.8443, 0.8444,\n",
              "         0.8445, 0.8448, 0.8448],\n",
              "        [0.8442, 0.8442, 0.8442, 0.8442, 0.8443, 0.8441, 0.8442, 0.8443, 0.8445,\n",
              "         0.8445, 0.8448, 0.8448],\n",
              "        [0.8441, 0.8443, 0.8443, 0.8441, 0.8446, 0.8445, 0.8442, 0.8455, 0.8452,\n",
              "         0.8451, 0.8453, 0.8450],\n",
              "        [0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8442, 0.8442,\n",
              "         0.8441, 0.8442, 0.8442]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result={'differences_TE':diff_text_enc,'low_score_TE':low_s_text_enc,'differences_DE':diff_text_dec,'low_score_DE':low_s_text_dec}"
      ],
      "metadata": {
        "id": "jqFyLPdgrub5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avgnormal_heatmap(result,block_name,kind, savepdf=None, title=None, xlabel=None, modelname=None):\n",
        "  if block_name=='Question Encoder' and kind=='Attention':\n",
        "    avg_differences=result['differences_TE']\n",
        "    avg_low_score=result['low_score_TE']\n",
        "    answer = \"QE\"\n",
        "    labels=['[Encode]','Q_token_1','Q_token_2','Q_token_3','Q_token_4','Q_token_5','Q_token_6','Q_token_7','[End]']\n",
        "    block_name='text_encoder'\n",
        "  elif block_name=='Question Encoder' and kind=='CrossAttention':\n",
        "    avg_differences=result['differences_DE']\n",
        "    avg_low_score=result['low_score_DE']\n",
        "    answer = \"ANS\"\n",
        "    labels=['Decode']\n",
        "    block_name='text_encoder'\n",
        "  normalize_diffs=avg_differences-avg_low_score\n",
        "\n",
        "  with plt.rc_context(rc={\"font.family\": \"Liberation Serif\"}):\n",
        "        fig, ax = plt.subplots(figsize=(3.5, 2), dpi=200)\n",
        "        h = ax.pcolor(\n",
        "            normalize_diffs,\n",
        "            cmap={ \"attention\": \"Greens\",'crossattention':\"Blues\"}[kind\n",
        "            ],\n",
        "            vmin=0.0,\n",
        "        )\n",
        "        ax.invert_yaxis()\n",
        "        ax.set_yticks([0.5 + i for i in range(len(normalize_diffs))])\n",
        "        ax.set_xticks([0.5 + i for i in range(0, normalize_diffs.shape[1] - 1, 1)])\n",
        "        ax.set_xticklabels(list(range(0, normalize_diffs.shape[1] - 1, 1)))\n",
        "        if not modelname:\n",
        "            modelname = \"BLIP\"\n",
        "        if block_name!=None:\n",
        "              ax.set_yticklabels(labels)\n",
        "              ax.set_title(f\"Impact of restoring {kind} layers in {block_name} after corrupted input\")\n",
        "            #ax.set_xlabel(f\"center of interval of {window} restored {kindname} layers\")\n",
        "        cb = plt.colorbar(h)\n",
        "        if title is not None:\n",
        "            ax.set_title(title)\n",
        "        if xlabel is not None:\n",
        "            ax.set_xlabel(xlabel)\n",
        "        elif answer is not None:\n",
        "            # The following should be cb.ax.set_xlabel, but this is broken in matplotlib 3.5.1.\n",
        "            cb.ax.set_title(f\"p({answer})\", y=-0.16, fontsize=10)\n",
        "        if savepdf:\n",
        "            #os.makedirs(os.path.dirname(savepdf), exist_ok=True)\n",
        "            plt.savefig(savepdf, bbox_inches=\"tight\")\n",
        "            plt.close()\n",
        "        else:\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "jqgusw7rZtOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avgnormal_heatmap(result,'Question Encoder','/content/466samples_normalized_causal_trace_Question_Encoder.pdf')"
      ],
      "metadata": {
        "id": "w0ub4Sh2GzET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avgnormal_heatmap(result,'Answer Decoder','/content/466samples_normalized_causal_trace_Answer_Decoder.pdf')"
      ],
      "metadata": {
        "id": "pjhlg3_XG-uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_score = None  # Scale all plots according to the y axis of the first plot\n",
        "\n",
        "for block_name in ['text_encoder','text_decoder']:\n",
        "    d = read_knowlege(6,block_name)\n",
        "    count = d[\"size\"]\n",
        "    what = {\n",
        "        \"text_encoder\": \"Indirect Effect in Question Encoder\",\n",
        "        \"text_decoder\": \"Indirect Effect in Answer Decoder\",\n",
        "    }[block_name]\n",
        "    title = f\"Avg {what} over {count} prompts\"\n",
        "    result = numpy.clip(d[\"result\"] - d[\"low_score\"], 0, None)\n",
        "    #kindcode = \"\" if kind is None else f\"_{kind}\"\n",
        "    if block_name not in [\"text_encoder\", \"text_decoder\"]:\n",
        "        high_score = result.max()\n",
        "    plot_array(\n",
        "        result,\n",
        "        block_name,\n",
        "        title=title,\n",
        "        low_score=0.0,\n",
        "        high_score=high_score\n",
        "    )"
      ],
      "metadata": {
        "id": "sL2xwA7kZ940"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee7d14350133412b92fc464b329f9275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f39949aef8104e7dafed796bde527340",
              "IPY_MODEL_ee5986fba3a742f98364f43a32400b0a",
              "IPY_MODEL_abdcbc6a21bb43d28e9443cc74cd7676"
            ],
            "layout": "IPY_MODEL_d2acc88d963f40789280f701b4550f09"
          }
        },
        "f39949aef8104e7dafed796bde527340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06714d99338646e69e3fdc5c51303c94",
            "placeholder": "​",
            "style": "IPY_MODEL_423fa9219baf42b1b0e31a32e45b1281",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ee5986fba3a742f98364f43a32400b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8aa95b9b75f4bef914a7dbec26c9c36",
            "max": 4559,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1ddad43a3514706b86f159238283d0e",
            "value": 4559
          }
        },
        "abdcbc6a21bb43d28e9443cc74cd7676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d221549547f040ff88bb0edc706c4a14",
            "placeholder": "​",
            "style": "IPY_MODEL_ce9182d06a0e47719a7e117786d9a6fb",
            "value": " 4.56k/4.56k [00:00&lt;00:00, 69.3kB/s]"
          }
        },
        "d2acc88d963f40789280f701b4550f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06714d99338646e69e3fdc5c51303c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423fa9219baf42b1b0e31a32e45b1281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8aa95b9b75f4bef914a7dbec26c9c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ddad43a3514706b86f159238283d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d221549547f040ff88bb0edc706c4a14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9182d06a0e47719a7e117786d9a6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c34884da39144f6a854f08d28b23a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5edde8fe35ae4429974d07fba4ae1765",
              "IPY_MODEL_f63683e22477407d95a195da783b677a",
              "IPY_MODEL_5a1b7cdf08924d839d9b440470b0780b"
            ],
            "layout": "IPY_MODEL_e4e498eaf37440f08e8b555e7ef83130"
          }
        },
        "5edde8fe35ae4429974d07fba4ae1765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b7f34d47b2c4967a6a91f421240dab8",
            "placeholder": "​",
            "style": "IPY_MODEL_8ae8cbdebd884a948b065a7a867369ef",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "f63683e22477407d95a195da783b677a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_852f8b6a03754f77a870859cf0963b21",
            "max": 1538966629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec76613eb2ef42ba8a61ef1ad13550b0",
            "value": 1538966629
          }
        },
        "5a1b7cdf08924d839d9b440470b0780b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4e78dbd61614505ab4505cc4341d51f",
            "placeholder": "​",
            "style": "IPY_MODEL_039c3f7e66c143c2b156bc6c3a982841",
            "value": " 1.54G/1.54G [00:14&lt;00:00, 148MB/s]"
          }
        },
        "e4e498eaf37440f08e8b555e7ef83130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b7f34d47b2c4967a6a91f421240dab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae8cbdebd884a948b065a7a867369ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "852f8b6a03754f77a870859cf0963b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec76613eb2ef42ba8a61ef1ad13550b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4e78dbd61614505ab4505cc4341d51f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "039c3f7e66c143c2b156bc6c3a982841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e66584cfb582485194e4ed49d7405c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67c677af122d4c9581602d9d77f0e15d",
              "IPY_MODEL_60b8c7b7d96342118ebe8637b65843ce",
              "IPY_MODEL_a0a1a43774bd4da297431931208364df"
            ],
            "layout": "IPY_MODEL_ed7d25cde7834863a22b4b0b42037f70"
          }
        },
        "67c677af122d4c9581602d9d77f0e15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b58ecfb5319d49269e5d0b7dc7d54d81",
            "placeholder": "​",
            "style": "IPY_MODEL_c7f26d15f15540a9be13573c00b80698",
            "value": "Downloading (…)rocessor_config.json: 100%"
          }
        },
        "60b8c7b7d96342118ebe8637b65843ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe56a0ef0700406e9714b3f3e47a866e",
            "max": 445,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_095baa47eee747af9941ce5ae7134ae3",
            "value": 445
          }
        },
        "a0a1a43774bd4da297431931208364df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce1214d307004c80a7b885988ae86e91",
            "placeholder": "​",
            "style": "IPY_MODEL_6f1b1859a5ea4147b40f1eea235711a7",
            "value": " 445/445 [00:00&lt;00:00, 25.0kB/s]"
          }
        },
        "ed7d25cde7834863a22b4b0b42037f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b58ecfb5319d49269e5d0b7dc7d54d81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f26d15f15540a9be13573c00b80698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe56a0ef0700406e9714b3f3e47a866e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095baa47eee747af9941ce5ae7134ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce1214d307004c80a7b885988ae86e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f1b1859a5ea4147b40f1eea235711a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08236d74993343e48d06c38b3dd687c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ad59209073847b2858e077658039b6e",
              "IPY_MODEL_5f8648beb3554107b6d02d060d594ec6",
              "IPY_MODEL_b21876a4470145a899fee0d6bc5e2045"
            ],
            "layout": "IPY_MODEL_d3b073e48e48490788c738b1fd7fec2d"
          }
        },
        "9ad59209073847b2858e077658039b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a5f0fe0b0a44d24a51c96b0e1e855e0",
            "placeholder": "​",
            "style": "IPY_MODEL_06a724ebe01b4a87a97381ab2a751f3f",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "5f8648beb3554107b6d02d060d594ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6d4822552042ccbbbe8a1ba99d1072",
            "max": 592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5973f9b8f8a04533a1a965c6e4a1d580",
            "value": 592
          }
        },
        "b21876a4470145a899fee0d6bc5e2045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31ca8ce9bc554491b329159ad644d2ad",
            "placeholder": "​",
            "style": "IPY_MODEL_0da61585c01147fdba8634bd03580761",
            "value": " 592/592 [00:00&lt;00:00, 39.4kB/s]"
          }
        },
        "d3b073e48e48490788c738b1fd7fec2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a5f0fe0b0a44d24a51c96b0e1e855e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06a724ebe01b4a87a97381ab2a751f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b6d4822552042ccbbbe8a1ba99d1072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5973f9b8f8a04533a1a965c6e4a1d580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31ca8ce9bc554491b329159ad644d2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0da61585c01147fdba8634bd03580761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb6ea4229eac4778b4539a46b01b6c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e9290ed921e4586822ed7203b0b4b64",
              "IPY_MODEL_b438cca2e9164a21add660eb7e739c60",
              "IPY_MODEL_8e6f1c7cd33849edb7aba612002761c0"
            ],
            "layout": "IPY_MODEL_cd6edcee3cb7452c8cac2cff310f9d68"
          }
        },
        "3e9290ed921e4586822ed7203b0b4b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2522e804b594955ae2f075e829cdf6f",
            "placeholder": "​",
            "style": "IPY_MODEL_d6ceee2b5f354a7686de8a427508bbdd",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "b438cca2e9164a21add660eb7e739c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f97b24eaa3cd49c09f6ddb2990bd4052",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca408accadb04ec6b9a43b43a9c7cb8d",
            "value": 231508
          }
        },
        "8e6f1c7cd33849edb7aba612002761c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41c09b0389804c5ebf92eb692d590c14",
            "placeholder": "​",
            "style": "IPY_MODEL_855f9b54d0a846b6868e6f9023cdb53e",
            "value": " 232k/232k [00:00&lt;00:00, 2.75MB/s]"
          }
        },
        "cd6edcee3cb7452c8cac2cff310f9d68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2522e804b594955ae2f075e829cdf6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ceee2b5f354a7686de8a427508bbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f97b24eaa3cd49c09f6ddb2990bd4052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca408accadb04ec6b9a43b43a9c7cb8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41c09b0389804c5ebf92eb692d590c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "855f9b54d0a846b6868e6f9023cdb53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08ab3de0be8641a69f222dbf07dc5981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc05cbe399eb46c9a8f640141df4bb97",
              "IPY_MODEL_285ba71b925744c2a73a9451f811e45d",
              "IPY_MODEL_6629aa2847c2460baefb3252d94ac867"
            ],
            "layout": "IPY_MODEL_20e2cd80d37f4720882e2cf4ac931421"
          }
        },
        "fc05cbe399eb46c9a8f640141df4bb97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_652260c874e64865a0117b4d3ef86f75",
            "placeholder": "​",
            "style": "IPY_MODEL_4983de7a45fd47c7a9f948609c21dfc6",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "285ba71b925744c2a73a9451f811e45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9a2e0b7320c4250b9566d4f192b93e3",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_234ee6846c754ea59f4d4a790b226a70",
            "value": 711396
          }
        },
        "6629aa2847c2460baefb3252d94ac867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c5665c488064990ab9abdc3ab3a184c",
            "placeholder": "​",
            "style": "IPY_MODEL_a9707de4d54948e2998612badf92f8bf",
            "value": " 711k/711k [00:00&lt;00:00, 2.94MB/s]"
          }
        },
        "20e2cd80d37f4720882e2cf4ac931421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "652260c874e64865a0117b4d3ef86f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4983de7a45fd47c7a9f948609c21dfc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9a2e0b7320c4250b9566d4f192b93e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234ee6846c754ea59f4d4a790b226a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c5665c488064990ab9abdc3ab3a184c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9707de4d54948e2998612badf92f8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66fc35372b7e4779a1303dd5f0883b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce2f6bd9744644af993962ab60bab080",
              "IPY_MODEL_6f8aa8a7243742c8abd96d314955d1cc",
              "IPY_MODEL_94cbfbfc0a4147e2ad42a5af590e119c"
            ],
            "layout": "IPY_MODEL_d4d541d190c4407bb25a2a1ae1b900f2"
          }
        },
        "ce2f6bd9744644af993962ab60bab080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac2e736803104edc9a52a89427f37f08",
            "placeholder": "​",
            "style": "IPY_MODEL_081d63f8e29448eda0e47308c40b461b",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "6f8aa8a7243742c8abd96d314955d1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b23c72a38b76458399d055f75c2884a3",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccac5fea901a41b692f694c8063428c1",
            "value": 125
          }
        },
        "94cbfbfc0a4147e2ad42a5af590e119c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad44210478b341b2b98d14525d394b4f",
            "placeholder": "​",
            "style": "IPY_MODEL_219f039042574af480bedb0a47e2c662",
            "value": " 125/125 [00:00&lt;00:00, 7.47kB/s]"
          }
        },
        "d4d541d190c4407bb25a2a1ae1b900f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac2e736803104edc9a52a89427f37f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "081d63f8e29448eda0e47308c40b461b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b23c72a38b76458399d055f75c2884a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccac5fea901a41b692f694c8063428c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad44210478b341b2b98d14525d394b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219f039042574af480bedb0a47e2c662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}